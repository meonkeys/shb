= Steadfast Self-Hosting: Rapid-Rise Personal Cloud
:author: Adam Monsen
:copyright: (C)2024 {author}
:license: Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)
:doctype: book
:docinfo:
:toc: macro
:toclevels: 3
:imagesdir: img
:front-cover-image: image:cover.png[]
:icons: font
:xrefstyle: full
:hide-uri-scheme:
:source-highlighter: pygments
// fixes alignment of line numbers with source in EPUB and HTML
:pygments-linenums-mode: inline
:!chapter-signifier:
// prevent unnecessary blocking fetch of fonts
:!webfonts:
:pdf-themesdir: pdf-theme
ifdef::shb-screenPDF[]
:pdf-theme: screen.yml
endif::[]
ifdef::shb-printPDF[]
:!front-cover-image:
:pdf-theme: print.yml
:media: prepress
endif::[]
// necessary for keyboard macro (kbd)
:experimental:
:keywords: linux, web, servers, sysadmin, computers, tech, self-hosting, FOSS
:description: Quickly learn the hows and whys of reliable self-hosted web services.
:revnumber: {build_git_tag}
:revdate: {build_date_time}
:revremark: {build_locale_lang}

[colophon%notitle%nonfacing]
== Colophon

--
_{doctitle}_
--

--
{copyright}
--

--
Some rights reserved.
See <<Copyright and license>>.
--

--
The beautiful cover art was created by my daughter using https://krita.org[Krita].
You'll find more of her excellent work throughout the book.
--

--
Technical editing by https://www.wondra.codes[Lenny Wondra].
--

--
First published in 2024 by https://sunrisedata.io[Sunrise Data Press].
--

--
Seattle, Washington, USA.
--

ifdef::shb-printPDF[]
--
Paperback ISBN FIXME.
--

--
[.text-center]
10 9 8 7 6 5 4 3 2 1
--
endif::[]

// "big" is perhaps deprecated, see https://docs.asciidoctor.org/asciidoc/latest/text/text-span-built-in-roles/#built-in
//
// ...or maybe it is only deprecated for HTML? See https://docs.asciidoctor.org/pdf-converter/latest/roles/

--
[.text-center]
image:sunrisedata-logo.svg[alt=Sunrise Data logo,width=49,height=97,fit=line] [.big]#Sunrise Data Press#
--

toc::[]

== Foreword

Before I started working in open source in 2006, I was working as a community organizer in Massachusetts. I was very well acquainted with how a lack of access to information or not having the "`real`" instruction manual keeps people from having a say in how they live their lives. As a community organizer, I taught people to lobby.
Our organization invited people to work with legislators to draft laws that would address their needs and make their lives better.
We taught people to fundraise and we taught them how to organize themselves and their neighbors.
And then everything started to move online and important conversations about how we should protect the vulnerable and empower the next generation started happening through our computers.

You can either lament progress or embrace it.
I chose to embrace it and decided that I wanted to empower people and help them feel a sense of control over the way they use computers and technology.
I started meeting all kinds of people from the free software movement, some were really interested in the way the code worked and others, like Adam, were the most interested in how freely available code could help people.

We met in 2009 at LFNW (LinuxFest Northwest), a free community conference in Bellingham, Washington.
A mutual friend had suggested that I should check out Seattle sometime when visiting Washington state for LFNW, which meant carpooling from Seattle to Bellingham.
We'd all meet for lunch in Seattle and then do the two hour car ride up to Bellingham together.
Those car rides are when we all really started talking about the lack of a free software event in Seattle.
We realized we needed some folks in Seattle who could get their companies to sponsor (like Adam and Rob Smith) and someone who could help get some speakers and promote the event to the free software community, which is how I (as a Massachusetts resident) ended up co-founding an annual Seattle event.

[#image-seagl-crew]
.Early SeaGL crew. From left to right: Salt, Deb, Patch (with french fry), Adam, Rob. Not pictured: Chris, Jesse, Bri, Lisa, and many more.
image::seagl-crew.jpg[align="center",scaledwidth=80%]

((SeaGL)) kicked off in 2013 at Seattle Central College and it was pretty scrappy.
No keynotes, lots of shared power strips and a few friends that had gotten roped in to help without a lot of idea of what they'd signed up for.
We had chosen a Friday to possibly attract students while the campus was open and a Saturday to make the second day easy for people whose jobs wouldn't support their attendance during the work week.
The event was and remains both free to attend and open to everyone.

Adam showed up to our first event with a small pile of "`print on demand`" hats and shirts with our brand new logo (a seagull of course.)
Talk selection was, "`if you want to do a talk, do a talk.`" Adam gave some great intro talks on Git and Hadoop and I gave a policy talk and community organizing talk.
We hadn't written it down yet, but SeaGL was destined to become a conference for beginners and experts, for coders and policy nerds and for talks about the ecosystem; the flaws, the potential and the opportunities for partnership with other efforts to empower people.

After that chaotic first edition, we solidified that we wanted ((SeaGL)) to be for everyone, but especially for people who were looking for a way into open source in the diverse, expensive, and tech-heavy Seattle area.
We wanted SeaGL to be a great first tech conference for attendees and a welcoming platform for aspiring speakers.
We later extended this to working towards finding lesser known speakers and offering them their first keynote opportunity.
The whole SeaGL crew (including Adam of course!) have always been passionate about welcoming in newcomers and fastidious about hosting a friendly, safe and curiosity positive environment.

Adam and I have known each other for a long time.
I've met his daughter, who is the talented illustrator for this book, and his wife who is also smart and relentlessly curious about how technology affects our lives.
I've even met some of the chickens, who are indeed squeaky clean, although sadly not all that smart.
Luckily, they are extremely well cared for so they don't need to be too bright.

In brief, Adam is very dedicated to both free software and empowering people.
He is also very, very nice!
Like truly one of the nicest people I have ever met.
If the idea of doing something hard with a patient and gentle mentor is appealing to you and you are curious about self-hosting, then this is the book for you.

Self-hosting is hard.
I've personally lurked on mailing lists that were going to make this easy, gone to talks, watched videos and read articles, but they've never quite managed to make it easy.
Some of those resources were starting at chapter 2, others were full of comments that made me feel like any random person of reasonable intelligence should be able to find the information that wasn't included.
Fortunately, Adam has included everything that a true beginner needs to get started while giving the reader plenty of options.

Self-hosting is also important.
Things change quickly in tech and in the wider world.
What you control and what you don't is constantly shifting.
Self-hosting gives you a chance to keep a few things to yourself and be in charge of your personal data, your media and the way you interact with your computing environment.
Self-hosting lets you decide what your needs are and choose how to address them, without asking for permission or getting locked into a contractual relationship with a company that doesn't care about you as an individual.

You should read this book, share it with other people, and maybe, once you're ready, contribute back to the self-hosting community.

--
Welcome to the world of hosting,
--

[.big]#Deb Nicholson#

--
Founder, Seattle GNU/Linux Conference +
Executive Director, Python Software Foundation
--

:sectnums:

== Introduction

(((data sovereignty)))
Data sovereignty means having full control of your data.
It brings the promise of privacy, liberty, and longevity.
Realizing data sovereignty is both fun and practical, and supports ((prosocial behavior)).
Self-hosting is an excellent path to data sovereignty.

This book will help you efficiently learn and practice self-hosting.
You'll gain confidence facing its challenges while enjoying its benefits first-hand.
The skills you will build are applicable at home, at work, and in your community.

=== Welcome

I am so glad you're here!

The self-hosting ecosystem is crowded and confusing, so I've taken care of a number of difficult choices with sensible, tested defaults.
I'll help you set up a server and your first several web services.
Bring along whatever ((sysadmin)) experience you've got, some willing users, and a desire to gain self-hosting competency.

The Internet is often a relentless cash-grab and attention vampire.
Our actions are infinitely measured; _we_ are the product.
The smog of surveillance stifles our freedom and erodes trust.
We will:
 
* Not settle for cheap ((cloud)) services.
* Reduce distractions.
* Cherish our attention, time, and freedom.
* Breathe the crisp, clear air of reduced surveillance by providing our own alternative to the chilling popular default of trading privacy for convenience.
* Save money by efficiently running lots of services on our own hardware with negligible incremental cost.
* Do well by our friends, families, and social groups.
* Do things we can't do with public services because we have full access to all our own raw data.
* Adapt and grow as software evolves, taking our data and ((metadata)) along with us.
* Share what and when it makes sense to share with whom we trust.

This is the book I wish I'd had when I was struggling to provide a safe online experience for my kids.

New self-hosters can use this book to get started.
Experienced self-hosters can compare my choices to theirs.

==== Prerequisites

(((router, network device)))
To get the most out of this book, the sysadmin experience you bring along should include the ability to configure your router and ((LAN)) (local area network), install Linux on a computer (hereafter referred to as your _server_), connect to your server with ((SSH)) (secure shell), edit text files and run commands on your server, and transfer files to and from your server.

If you're unfamiliar with any of these concepts, a quick trip to your favorite search engine or local user group should yield enough pointers to get started.

I recommend hosting on ((bare metal)) (tangible nearby computer hardware), and this comes with some prerequisites for the physical space where your server resides.
Read more about the ins and outs of bare metal in <<Prepare hardware>>.

Finally, some best practices to keep in mind as you read along:

Document everything you do, if only for your future self.
Recruit and train help, leveraging said documentation to share knowledge.
Focus, take breaks, be patient, and take care of your body.
Ask for help and ask for feedback.
Listen to users, gather data, and adapt accordingly.

=== Supporting the author

I wrote this book with my own resources after years of research with lots of help from awesome people.
See <<Acknowledgments>>.

Please https://selfhostbook.com/buy/[buy a copy] for yourself or someone else, especially if you'd like me to write more books in the future.

This book is a work in progress.
Please help me improve it.
See <<More resources>>.

=== Book version

This book was generated

* on *{build_date_time}*
* with `LANG` set to `*{build_locale_lang}*`
* from source `{docname}{docfilesuffix}`
* at commit `{build_git_commit}`, branch `{build_git_branch}`, tag `{build_git_tag}`
* using *{build_os_release}*

=== Copyright and license

_{doctitle}_ is {copyright}.

==== Copy this book

This book is distributed under the **{license}** license.

Please make copies and derivative works.
This book is meant to be enjoyed and shared.
The license explicitly encourages sharing.

===== You are free to...

Share::
  copy and redistribute the material in any medium or format
Adapt::
  remix, transform, and build upon the material

_The licensor cannot revoke these freedoms as long as you follow the license terms._

===== Under the following terms...

Attribution::
  You must give appropriate credit, provide a link to the license, and indicate if changes were made.
You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.
NonCommercial::
  You may not use the material for commercial purposes.
ShareAlike::
  If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.
No additional restrictions::
  You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.

===== Notices

You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation.

No warranties are given.
The license may not give you all of the permissions necessary for your intended use.
For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.

==== Copy this book's code, too

See <<More resources>>.
There are two original works for you to fork (copy, modify, and share).
First, the book itself, along with code to generate beautifully typeset versions.
Second, a learning tool called mario (see <<_mario>>).

The license for all original source code related to this book is the ((GNU)) ((AGPL)) (Affero General Public License) as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.
A copy of the ((AGPL)) is included in `mario/COPYING`.

=== Disclaimer

(((warranty, none offered)))
I offer no warranty and no guarantee.
Buying or reading this text is not an agreement for support.

While every precaution has been taken in the preparation of this book, I assume no responsibility for errors or omissions or for damages resulting from the use of its code or contents.

I am not professionally affiliated with the products or paid for by the companies mentioned in this book.
Their copyrights, trademarks and intellectual property are their own.

My opinions are my own.

I include direct references to many products and companies and add my specific, hard-won lessons on their comparative strengths and weaknesses.
My intent is to educate and inform.

I will take shortcuts.
I will not seek to deeply and exhaustively explore each topic.
I want you to get to the good stuff quickly, then decide if, when, and where you want to dive deeper.

If you find contradictions to these statements, please let me know.

I'm human and error-prone.
I'll make it easy to contact me about missing or incorrect information.
Please do.
When you do, include references or other supporting material.

=== Style

(((style conventions)))
(((typography)))
Text formatting:

[cols="2,3"]
|===
|Styled example |Used for

|`zpool status -t` |Inline command, filename, username, password, or variable.
Longer snippets of console text use language-specific syntax highlighting.
|kbd:[Ctrl+c] |Key(s) pressed on the keyboard.
|https://example.com |Bare (un-named) link.
https scheme is assumed and omitted.
|https://example.com[Example domain] |Named link.
Full URL appears in print version.
|`\https://cloud.example.com` |Non-working example link.
Replace `.example.com` with your actual domain name.
|<<System design>> |Cross-reference to another section or chapter.
|===

Admonitions:

NOTE: Admonitions like this note draw your attention to auxiliary information.

TIP: Here's a tip,

IMPORTANT: something of import,

CAUTION: a cautionary message, and

WARNING: a specific warning.

Sidebars:

****
Stand-alone or supplemental content may be visually separated using a sidebar like this one.
Sidebars may or may not have titles.
****

Code snippets:

.check PSI (server)
[source,bash]
----
tail /proc/pressure/*
----

Snippets will indicate whether they occur on the server or elsewhere.
The previous command (from <<Monitoring>>) is intended to be run on the server.
If the location is omitted, the snippet may occur on the server or elsewhere and will be explained in context.

== Background

You might be thinking, "`this looks like a lot of background!`"
And you'd be right.

I go deep into background here because of something I found while giving talks about self-hosting: people know how to learn and discern, they wish for meaningful motivation to commit to learning.

I hope you find that here.

=== Who am I?

I'm a dad, tech entrepreneur, and ((FOSS)) (free and open source software) enthusiast.
I love to parent, care, laugh, sing, listen, code, build, produce, debug, architect, debug, lead, manage, debug some more, lecture, and write.
I'm good at administering and securing systems and processes while ensuring privacy, compliance, and reliability.

(((SeaGL)))
I'm most proud of my family, growing https://mifos.org[Mifos], founding https://seagl.org[SeaGL], selling https://csats.com[C-SATS], and writing this book.

I've been running my own services for decades.
I started with a humble blog running on a buddy's machine.
The feeling of freedom and control was exciting and it complemented my effectiveness at work, so I kept on.
I worked with many services and servers but usually avoided running my own hardware.
Once I had a family, our data storage needs increased at home.
It became handy as parents to be able to provide more and safer online services for our kids.
A simple network drive and file sync were no longer enough; I wanted better services for managing our data along with the autonomy of our own ((bare metal)).

At the start of the pandemic our family tech needs increased sharply.
We were all stuck at home and online, and I was wary of companies swooping in to capitalize on our captivity.
At the same time, I decided to https://en.wikipedia.org/wiki/DeGoogle[de-Google].
The family needs and my de-Googling coincided well.
Self-hosting was a serendipitous fit.
Just _trying_ to de-Google was a fascinating and fulfilling journey, punctuated with many self-hosting experiments.

=== Why did I write this book?

I wrote this book to promote ((data sovereignty)) as a prosocial behavior.
This is easier to achieve than ever before with self-hosting, and I wanted to share that in book form.
Existing books lack a good, fast, and cheap technique for self-hosting on ((bare metal)).
I figured one out and I think you'll love it.
It works fine if you run your server in the ((cloud)) too, it just costs a lot more (see <<Server>>).

Also, learning is fun.
I learn when I write.
While learning how my phone works, it struck me how important it is to understand _how "`the cloud`" works_, since the modern phone experience relies heavily on services and data in public clouds.
In trying to make my phone "`my own`" (do what I want to help me live my best life), I was inspired to host my own data in my own ((cloud)).

Also, most tech folks I know self-host _something_, likely something I've never heard of.
There's always another self-hosted service to try out, learn about, improve, and share.

Also, maybe I can make a buck or two doing this, or at the next thing I do.
Maybe you can hire me to help you out.

Also, I wanted to write the book I wish _I_ had when I started self-hosting.

Also, so there's a _book_ about this.
There are countless videos, articles, and chunks of code online for doing everything in this book and more.
Many are excellent.
This book is your to keep, hold, and refer back to as you try, test, and learn.

Also, there's a stark gap between useful individual computers and useful ((cloud)) services.
It's easy to pay for cloud, but the true price is obscured: surveillance, lock-in, inflexibility.

Also, I can picture a future where owning a truly privacy-respecting home data appliance becomes as commonplace as owning a refrigerator.
Creating this appliance has been attempted many times and it'll be attempted again.
Until it succeeds and sticks, self-hosting--setting up a server and services for yourself and others--is a great way to go.

=== What's with the title?

==== Steadfast Self-Hosting

I like the word _steadfast_.
It reminds me of reliable things and people.

(((data sovereignty)))
The key to reliable self-hosting is data sovereignty.
Software will change, services will change, you will change and the world will change.
You've got to have control of your data if you want it to reliably serve you well through all that change.

It does make a difference to have your own copy.
You might lose access to something you "`bought`" or it might even change right under your nose.
More on this:

* https://kotaku.com/sony-ps4-ps5-discovery-mythbusters-tv-1851066164[PlayStation To Delete A Ton Of TV Shows Users Already Paid For] by Ethan Gach
* https://defectivebydesign.org/what_is_drm[What is DRM?] by the Free Software Foundation
* https://nytimes.com/2023/04/04/arts/dahl-christie-stine-kindle-edited.html[It's Their Content, You're Just Licensing it] by Reggie Ugwu

Saving copies of data someone else is hosting for you is fine.
Self-hosting goes a step beyond, giving you far-reaching control of how your data are used and shared.
You'll gain agency over authoritative copies of your files, allowing you to know and control your ((source of truth)).
All this with reliability and flexibility within a reasonable budget.

Self-hosting means providing computing services by and for individuals, families, and hobbyists in ((SOHO)) (small office / home office) environments.

"`Small community hosting`" is perhaps a more accurate and appropriate term here.
You're reading the right book to host services for a small community.

Last, a note on terminology.
When it comes to compilers in computer science (and perhaps also other areas in tech), "`self-hosting`" refers to the wonderfully satisfying milestone when a programming language is able to compile itself.
I apologize to my friends in related disciplines for blatantly overloading the term "`self-hosting`" to mean small community hosting.
You had it first, I'm borrowing it and hoping our contextual lane lines will sufficiently prevent collisions.

==== Rapid-Rise Personal Cloud

_Rapid_ is there to get you excited to jump right in and learn.
_Rapid_ does not mean _reckless_!
I'm a strong advocate of a thoughtful and robust approach to self-hosting.
When you encounter a challenge, slow down to learn faster.
Once you understand a concept, practice it.
Fail fast and often, with rapid iterations trending towards perfection.

_Rapid-rise_ is something you might find on a package of baker's yeast, and I love fresh-baked bread.
If your server is a loaf of bread, this book is your rapid-rise yeast.

[#image-bread-server]
.Server in the shape of a loaf of bread.
image::bread-server.png[align="center",scaledwidth=80%]

_Cloud_ implies scalable and automatable.
_Personal_ scopes that scalability to what's reasonable for a small group.
Modern ((bare metal)) hardware can scale (to a degree) within its box.
It can scale automatically by using more or less power according to compute demand, and manually when you upgrade hardware components (say, adding another hard drive).

I'll also admit my inner child enjoys multiple meanings of the phrase _Personal Cloud_.

=== Who is this for?

This book is for people who are kind to others, brave in trying new things, curious about the possibilities of self-hosting, and either uncertain how to do so or eager to improve their existing homelab (self-hosting space).

This book is for people who want to know where their data live, and to be able to work all kinds of magic with it.
It's a "`from scratch`" or "`the hard way`" approach, and it keeps the doors wide open to many possibilities with a principled self-hosting technique.
I'll sometimes recount what worked for me rather than specifically recommend what you should do.

This book is for people curious about or already biased towards ((FOSS)).
And--as much as I'll blather on about FOSS--I'm not here to judge.
I'm here to _grow_, primarily by sharing and learning.

This book is for students, especially tech-savvy or tech-adjacent students active in clubs and teams.

This book provides motivation for self-hosting with an excellent process for learning same.
Its version-specific material is expected to fall out of date.
Its motivation and process for learning will become more relevant as time passes.

This book is for those trying to live more for others and less for themselves; selfishly enjoying the act of being selfless.
Leaders, parents/guardians, members of a collective or a handful of friends.
People who want to self host, who _also_ love others and doing other things besides systems administration.
I'll save you some precious time for those other things while making the sysadmin bits fun.

Similar to "`small community hosting`", _Small Group Cloud_ would be more accurate title words than _Personal Cloud_.
"`Small group`" is a great target size for what you'll create.
I wouldn't bother doing all this just for yourself.

This book is for people into (or hoping to get into) self-hosting.
It is geared towards useful, secure, and quick setup of a single ((bare metal)) server with many services.

This book is for people who want to _de-Google_, _de-iTunes_, _de-OneDrive_, _de-Dropbox_, _de-Whatever_.

=== What is this book _not_?

This is not a comprehensive guide to self-hosting.
I won't attempt to enumerate the endless ways to mix and match hardware, operating systems, ((isolation)) techniques, and services.
This book is for small scale.
Look elsewhere for:

* high availability
* enterprise security
* N + 1 redundancy
* managing many machines
* clustering
* single sign-on
* advanced monitoring and metrics centralization
* regulatory compliance
* intrusion/threat detection/prevention
* in-depth security hardening
* running your own container registry
* 100% offline / off-the-grid self-hosting

There are some topics like these I'll skip or cover only briefly.
Any one of these topics is an entire industry, another piece of hardware, a setting on your home router, a potential career, none or all of the above, and otherwise well worth further consideration.
You can and should be aware of them.
If you feel I've completely omitted proper detail about something critically relevant to my method of self-hosting, please let me know.

This book is not for the heavily-resourced already-done-thats.
If you have $50k and unlimited time to spend on your concrete bunker homelab... well then, may I have a tour?
I would _love_ to see that.
If you are more curious than certain you may still enjoy learning from my choices.

I'm not writing to accommodate hardline software patent and license activists.
These wonderful folks will spot my intentional use of the word _open_ and omission of the word _libre_.
I love all these words, I agree words are important, and I stand on the side of inclusion at the cost of idealism (while maintaining hope these concepts are not mutually exclusive).
I thank the activists for helping swing the needle towards freedom, to all our benefit.

This book is not a manifesto for always/only self-hosting.
It's fine to self-host some services and pay for others.
You'll come up with your own checklist for what to self-host and when.
Mine focuses on providing a useful, reliable, future-proof ((cloud)) for me and my family.

This book is not the fastest path to trying out web services.
You can usually find demo instances running for particular projects.
There are ((cloud)) providers that will run a service for you and host your data.

See also: <<Alternatives to this book>>.

=== How write book?

Why are you talking like a caveman?

(((Vim)))
I wrote the book originally in Markdown plain text in my steadfast text editor, https://www.vim.org[Vim].
(((Pandoc)))
I applied generous amounts of https://pandoc.org[Pandoc], time, and love.
Pandoc is a fantastic ((FOSS)) tool which allowed me to use that single plain text file with fairly human-readable Markdown syntax to generate several different decent outputs.
While revising, I came across the build system for https://github.com/progit/progit2[Pro Git 2] (thank you Scott and Ben!).
In short order I converted the book to https://asciidoc.org[AsciiDoc] and ported my typsetting code to https://asciidoctor.org[Asciidoctor].
This simplified the book build and gave me more and better output formats.

TIP: Check out the source code--you're welcome to hack away at it.
See <<More resources>>.

I tried to stick with off-the-shelf FOSS software as much as possible, with minimal customization.
This helped me focus on the content while keeping the book simple enough to self-publish.

==== When write book?

Still with the caveman.
Enough already.
I wrote this in 2023.
And, listen, even blessed cave-dwellers like us should give self-hosting a shot.
We got this!

==== Where?

Seattle.

==== Hey now.

Admittedly, those last few sections exist so I could cover all https://en.wikipedia.org/wiki/Five_Ws[5 Ws] and include the caveman gimmick.

=== A note on FOSS

(((FOSS, bias)))
I prefer FOSS over non-FOSS.
This can be a polarizing topic.
Heck, even using the term FOSS instead of the other variants can be polarizing.
These are just distractions.
Today we need compromise, patience, and kindness.
Curiosity over certainty.

Here's my promise to you, dear Reader:

I will try not to get too preachy.

I will prioritize _practical_ solutions over _idealistic_ ones.
I will sometimes fail to do this when it comes to FOSS.
Most notably, I will barely acknowledge the existence of non-FOSS alternatives in this book.

I'm aware of the tension between practical and idealistic solutions, and I believe this tension is a Good Thing because it reminds us to think critically about what ((cloud)) services we _should_ pay for and use, not just what we _can_ pay for and use.
It's worth a moment's thought.

Our data matter and our personal choices matter.
The impact spreads to the groups you are a part of, as does the opportunity for improvement.

I believe self-hosting ((FOSS)) is doable and affords many practical benefits over non-FOSS.

Hang in there and give me some feedback.
You'll strike your own balance between idealism and practicality and I'm interested to know where you land.

Continued ad nauseam in <<More about FOSS>>.

== Your journey

Continuing advances in hardware and software means self-hosting today is easier and cheaper than ever before.
And in one key way, much more complex: there are an overwhelming number of choices to be made for someone starting out on this journey.

Hang in there.
I'll help you narrow the choices by providing specific, focused guidance.

Don't worry too much about the specific choices you make.
Your personal ((cloud)) will be malleable.
Swap out bits as you like.
If you choose poorly, just choose again (ideally based on metrics and user needs).

You aren't a failure if you don't get it right the first time.

It is OK to slowly migrate from whatever you currently use.
No need to upset everything all at once.

It is OK to _not migrate at all_ and just follow this book to expand your own personal learning and experimentation.

It is OK if you don't adhere perfectly to your or someone else's ideals.
Stick to your values while you question and develop these values.
Enjoy your journey.

=== Why you should self-host

Ask again--as you should--why the heck would anyone self-host software services?
So many reasons!

* Flexibility
** run only the services you and your users want
** use multiple services backed by the same data storage
** automate what you want, when you want
** unlimited sharing
** unlimited streaming
** unlimited choices
* Fun!
** learn and grow
** self-hosting is a doable challenge
** solve right-sized puzzles as you learn and improve
** be part of the thriving self-hosting community
* Be future-proof
** insulate your users from the unpredictable shifting of proprietary product prices, service offerings, and UI/UX
** share your hard-earned data to your friends and family, forever
** migrate to something else easily if and when you need to (for example, using a newer/better photo server once one becomes available)
** it's really the _data_ that must be safeguarded, the frontends to those data (file viewers, editors, etc) will change when _you_ choose
* Democratize computing
** self-hosted software (especially ((FOSS))) enables data and computational autonomy
* Conserve electricity
** backend ((cloud)) power per device drops dramatically with a few users
** save even more power the more users you add
** see linked articles in <<Server>>
* Save money
** self-hosted hardware will typically beat cloud (renting someone else's)
** savings increase as your users`' data storage requirements enter the terabyte range
** save more with every service you run
** avoid unexpected public ((cloud)) costs
*** ((egress)) fees make it expensive to download your data and move it somewhere else
*** forgetting to shut down a ((VM)) (virtual machine) can get expensive quickly
*** you could spend excessive time and money navigating the public cloud's confusing menu of service offerings
** avoid unexpected public clouds changes
*** changes in license fees
*** changes in usage fees
*** changes in support costs
*** changes in service offerings
** near-zero incremental cost of adding users and services
* Speed / Save time
** a nearby server can have much better response times, assuming reasonable hardware and well-behaved services
** nearby data ("`data locality`") means you don't need round-trips to someone else's data center to run experiments
** shared storage allows you to front your data with multiple services, choosing read-write/read-only access sensibly
* Avoid vendor lock-in
** you'll be able to use software features public cloud providers don't offer or don't yet exist because you fully own and control your raw data
** when you buy something with ((DRM)), you don't really own it
** is there an integration you count on?
Sometimes a service stops working with another service.
This happens less often with ((FOSS)) because anyone can simply fork a project.
* Privacy
** avoid the chilling effect of mass surveillance
** with a personal ((cloud)) you can safely and confidently keep GPS latitude and longitude in your photo ((metadata))
** once you keep your location metadata, you can do creative things with it
** if you don't _need_ to share your location and behavior with Google every second, why do you?
** remove yourself from the equation of user analysis data--when you stream video from someone else's service, they know and analyze every time you (or your kids) (re-)watch a video you "`own`", every time you rewind, fast-forward, pause... but do they need to? why?
* Unlock new possibilities
** apply arbitrary workflows to uploaded files
** deploy trustworthy, offline generative ((AI)) (artificial intelligence) models
** enjoy features that don't exist in public services

(((Nextcloud)))
See https://nextcloud.com/athome/ for more self-hosting propaganda and app ideas.

=== Why you should not self-host

Self-hosting is more complex and time-consuming than paying for the same functionality, especially at first.
It takes discipline and patience, like learning a new instrument (but _this_ instrument eventually plays itself!).

If something breaks, you're fixing it.
Sometimes you get a useful error, sometimes you can search the web for a quick fix.
Sometimes you don't and can't.

CAUTION: If you don't enjoy troubleshooting and debugging, self-hosting might not be for you.

If you don't take care with ((backups)) and security, you'll risk time, energy, and trust with people you care about.

On-premise self-hosting entails additional meatspace-specific considerations.
You need to ensure sufficient power, connectivity, HVAC (heating, ventilation, and air conditioning), and security.
Just don't keep your server outside.

== Practical examples

=== Criminal chickens

Here's a real example of a positive outcome I realized from self-hosting.

My family has a homemade chicken safety system and the videos are important to me.
I used to just plop them on YouTube because hey, it's free and it "`just works`", right?

Except when it doesn't.
YouTube sometimes felt my chickens were being spammy, deceptive, and/or scammy.

[#image-YT-censor]
.Screenshot of an email from YouTube content team having removed my chicken coop camera video.
image::YT-censor.png[align="center",scaledwidth=80%]

For the record, our chickens are _squeaky clean_.

[#image-squeaky-clean-chicken]
.One absolutely upstanding, hard-working, law-abiding chicken.
image::squeaky-clean-chicken.png[align="center",scaledwidth=50%]

Once I stood up my personal cloud I felt freedom and ease when posting and hosting these videos.
I no longer needed to complete any YouTube paperwork to be able to keep an eye on my chickens.
I can safely ignore their audit and its erroneous policy violation claim.

[#image-YT-audit]
.Screenshot of a YouTube legal audit for my old API client.
image::YT-audit.png[align="center",scaledwidth=80%]

I also no longer need to work with YouTube's ((API)) (application programming interface), including registering an API client and completing periodic audits.
(((Nextcloud)))
After standing up Nextcloud I deleted my YouTube API client to upload videos, cleaning up my code and simplifying its maintenance.
Turns out the Nextcloud Talk ((API)) is easier for posting my chicken coop photos and videos anyway.

With my own cloud I'm also able to tune quotas and rate limits as desired.
Full speed ahead!

=== Photo search by location

Here's one more pro-personal-cloud example.
This one worked because I am comfortable storing location ((metadata)) in my self-hosted photos.

A while back I was trying to find some particular photos from a pile of thousands, taking up terabytes on disk.
I knew where I was when I took the photos (within 10 miles or so) and my photos have embedded locations.
I couldn't remember when they were taken.

My photos are just a bunch of JPEG files.
I examined them with a small Python program I wrote.
I looked for any photos taken within 10 miles of the point I knew.
The key was being able to access the data directly and quickly.

This is just one (likely outdated) example.
By the time you read this you may be able to query your photos with a sentence like: "`show me all photos taken within 10 miles of Mexico City`", and it'll just work.

Then you can move on to saving the world.
Just make sure you've got your data!

=== Surprises

Should you choose to proceed: godspeed, traveler.
This is seriously fun stuff.

You may be surprised by how fast and easy some things are with self-hosting.
I'd love to know how this goes for you.

You may also be surprised by how time-consuming and difficult some things are.
Maybe you'll get held up with hardware (and its power, wires, cooling, failures).
Maybe networking.
(((Nextcloud)))
Maybe "`change management`" (trying to convince your users to use Nextcloud instead of Dropbox).

Here are some things that surprised me, both positively and negatively.

==== Good surprises

===== Hardware wasn't that hard

With help from a friend (thanks Rob!), I bought a reliable and cheap refurbished server.
I thought I'd be tinkering with wires, cards, and CMOS batteries.
Not so!
I opened the chassis to see the guts.
I confirmed the contents were normal server guts, or close enough.
The CPUs and memory sticks were all there as advertised.

I plugged it in; it worked.

[#image-inside-chassis]
.View inside the server showing two empty PCI-E card slots.
image::inside-chassis.jpg[align="center",scaledwidth=80%]

===== Containers == happy

I was pleasantly surprised by ((container))s (explained in <<Contained services>>) following my varied earlier experiences with ((VM))s.
VMs are simple at first because they behave much like physical hardware.
Installing Linux into a VM is as easy as installing it onto ((bare metal)) (sometimes even easier).
Then you can set up one or more services in the VM.
The real rub here is with maintenance; maintaining a VM can be as complex as maintaining a bare metal server.

Containers take a different approach and simulate much less of a bare metal server.
They are fast and small compared with VMs, allowing higher non-conflicting service density.
That is, you can stand up more services per server and they don't interfere with one another (e.g. by requiring different versions of PHP (PHP: Hypertext Processor)).
One ((container)) typically contains only one service.

Isolation of containers is limited compared to VMs.
The kernel (the part of the OS that talks directly with the underlying hardware) is shared, for example.
Limited ((isolation)) keeps the resource and maintenance costs of container-based isolation low compared with VMs.

Containers are excellent for a consistent and resilient personal cloud.
They are easy to declare (in code), build, deploy, test, and repeat.
They can also be used along with VMs: you might use a VM as your server instead of ((bare metal)).

I chose Docker to manage containers because it is popular and I have experience with it.
Your server is also considered a _host_ since it it is a _host_ to Docker containers.

One downside of Docker is how often root access is assumed in example code and popular public images.
Running as `root` makes ((container))s simpler but less secure.

===== Go paperless with OCR

Another smile-worthy advancement is free ((OCR)) (optical character recognition).
I keep trying to "`go paperless`" by scanning in all my paper files.
After scanning papers I am shouldered with, unsurprisingly, a bunch of PDFs of images.
(((Nextcloud, search)))
(((Paperless-ngx)))
These can be easily OCR'd and managed with tools like https://docs.paperless-ngx.com/[Paperless-ngx] and https://apps.nextcloud.com/apps/fulltextsearch[Nextcloud Full text search].

===== Jellyfin works well

((Jellyfin)) is a personal streaming media server.
I was stoked to see how Jellyfin showed up as an excellent and complete ((FOSS)) alternative to ((Plex)).

==== Bad surprises

===== Traefik learning curve

The ((Traefik)) ((reverse proxy)) was surprisingly challenging to set up because my networking fundamentals were rusty.
I've got it working reliably and I still need to keep improving my fundamental knowledge in networking.

See <<Reverse Proxy>> for more about Traefik.

===== Nextcloud bugs

(((Nextcloud, surprises)))
I was frustrated with some bugs in Nextcloud.
These felt like the most urgent since I rely heavily on it.

Community support is hit or miss.
Nextcloud seems more popular outside the USA.

Not all Nextcloud apps are ready for prime time.
See <<Customization>>.

===== Jitsi ports

((Jitsi)) is a self-hostable ((FOSS)) video call platform.
I gave up trying to get Jitsi running in Docker.
I recall lots of open ports or port ranges being a problem.
This service might be easier to self-host in a virtual machine.

There's also a workaround assigning port ranges to specific IP addresses, but this is beyond the scope of this book.
I will eventually give it another shot because https://jitsi.org/blog/authentication-on-meet-jit-si/[logging in is now required when using the free 8x8-hosted Jitsi service].

==== Absorb them all

When it comes to surprises, try to absorb the bad ones when they affect your users.
Ideally _before_ they affect your users, via research, planning, and testing you're likely already doing.

Dogfood what you self-host.
Try your best to ensure everything is attractive and useful, then wait.
Be patient.
Never try to force people to use whatever you self-host.

I hope this book inspires you with many positive surprises and helps you and your users avoid many negative ones.

== Plan

We'll now briefly cover the salient points of a self-hosting plan.
I love this part!
I get excited about what's to come, and I know a solid plan makes a vision real.

Make _your_ plan.
Maintain and improve your plan along with your server.
Share the plan with other admins.

Yes, other admins.
You need someone to cover for you when you are not available, or a crystal clear expectation that when you die, the server dies too.

=== Budget

Consider the time and cost of self-hosting.
To yourself _and your users_.
How much do you have and want to spend?
Write down a number and stick to it.

=== Resources

Sketch out your thoughts on resources you'll need.
Some ideas:

Compute and memory::
CPU and RAM are the fundamental resources necessary for computation.
See <<Map services to resources>> for ideas on how to estimate requirements based on the services you'll host.
GPU workloads are not covered in this book, although <<_whats_next>>, and <<Exercises>> touch on a few things you might try on your own.

Data storage::
Estimate how much storage space you'll need.
There's a significant jump in complexity and cost with each jump in unit (for example, GB (gigabyte) to TB (terabyte)).
This book is appropriate for data storage up to about 10 TB.
See <<Hard drives>> for how to spend less on storage by self-hosting.

Electricity::
Check your home power bill for the cost per kWh and run some estimates.
See <<Server>> for an example of the power used by a capable server.

Support::
Who will help you when you get stuck?
<<Support>> has some ideas.

Physical location::
Where will the server live?
Will you have to install new wiring for power or network?
<<Networking>> covers my home setup.

=== Schedule

Rough out key dates so you and your users can plan ahead.
For example:

Apr 28::
  Brainstorm, plan.
Apr 30::
  Order hardware.
May 3::
  Pull ethernet from router into garage.
May 5::
  Set up server: Install hard drives, power on, install OS, start services.
Jun 9::
  Review result against original goals.

Invite others to participate, starting at the beginning when you brainstorm and plan.
This is a great time to include other people who may help care for the server.

=== Transition

Your users already have their data somewhere else.
Consider how you'll help them migrate their data onto the server.

The key to this is excellent communication.
Include this in your plan and seek buy-in since migration cost is a reality for every transition.

TIP: To learn more about gracefully transitioning users between systems, study _change management_.

=== Sysadmin mindset

The server exists for the users.
It is important to establish the right mindset to be able to provide an excellent user experience.

Make sure your self-hosted services work well for them.
Solicit their input often and take it seriously.
Carefully tease out _wants_ vs. _needs_.
Translate the word "`users`" as necessary.
Perhaps: "`those most dear to you, those you care about most above all others, those who give you meaning and purpose.`"

Yeah, that's way over the top.
You get the point: we must care about the user experience or it will be frustrating.
Ideally you already know your users in real life, so just continue to practice being thoughtful.

== System design

Let's dive into the various layers of a _Steadfast_ system.

=== Service stack

(((Docker)))
(((Jellyfin)))
(((Nextcloud)))
(((Ubuntu)))
(((Wallabag)))
(((ZFS)))
(((ext4)))
A _Steadfast_ system presents nicely as a simplified stack of colored boxes.
These are conceptual, based on where and how frequently a sysadmin will likely act and investigate when supporting or troubleshooting.

[#image-service-stack]
.Layers of a Steadfast system. From the bottom we have hardware: bare metal, filesystem: ext4 for / and ZFS for /data, OS: Ubuntu LTS 64-bit server, container runtime: Docker, containers: Nextcloud file sharing app, Jellyfin media server, Wallabag article reader.
image::service-stack.svg[align="center",scaledwidth=80%]

I am most often working around the top layers e.g. adding or updating a ((container)).
Less often I am updating OS (operating system) packages.
Less often still I might examine versions of a configuration file stored on disk from its ((ZFS)) automatic snapshots.
Finally, when my server dies, I'll be on that bottom layer fixing or replacing hardware.

==== Stack layer details

* containers:
** <<Containers == happy>>
** <<Contained services>>
** <<Nextcloud>>
** <<Jellyfin>>
** <<Wallabag>>
* OS: <<Operating system>>
* filesystem: <<Filesystem>>
* hardware: <<Server>>

=== Digital security

Let's cover the basic tools for understanding and securing your server.

==== Categorize your data

First, consider your data.
It helps to break it down into two common categories:

===== Sensitive data

Examples: passwords, credit card numbers, government ID numbers.
Recommendations:

. Store offline only if possible.
. If ever saved on a computer, store encrypted.
. Easy fix: store in a ((password manager)).

===== Everything else

(((WAN access)))
Examples: notes, photos, documents, personal information.
Recommendations:

. Store on encrypted media, including ((backups)).
. Access only with up-to-date software you trust.
. Disallow ((WAN)) (wide area network) access to these data.

==== WAN access

Once you've categorized your data, think about how people will get to it.
At home you can generally just connect directly to your server.
When you're away or you're trying to share with someone else, you're talking ((WAN access)).

(((router, network device)))
WAN access is--informally--remote access to services and data running in your ((LAN)).
One means of allowing WAN access to a service is by port forwarding ((HTTPS)) traffic through your router/firewall.
Port forwarding without taking additional security measures is both risky and convenient.

NOTE: Consider alternatives to port forwarding, such as using a VPN.

==== Threat model

Let's back up a step and talk about threat modeling.
Your _threat model_ is how you'll consider threats to your data and how you'll mitigate these threats.
With your ((threat model)) in mind, you'll be able to gain confidence in, for example, the decision of whether or not you should permit WAN access.

WARNING: If you already know you are a valuable target (public figure, high net worth, wartime journalist, responsible for a server with information about many people), buckle up for a longer journey.
This guide is not sufficient for your threat model.

Let's build a simple example threat model for the "`everything else`" data class.
Consider:

Assets::
  Data you are trying to protect.
Actors/Threats/Vectors::
  People and bots acting badly, and their means of attack.
Includes mistakes and bugs.
Mitigations::
  Steps taken to reduce chances attacks succeed.

Put it all together and you get my 100% marketing-friendly threat model acronym *A.A/T/V.M.* (all punctuation is vocalized).
Really just rolls off the tongue!

==== Example: WAN access

Test ((WAN access)) with this ((threat model)).

Assets::
  Files with personal information stored in out-of-date service (e.g. an old, vulnerable version of Nextcloud).
Actors/Threats/Vectors::
  Bot scrapes websites and finds URL to service on a public mailing list archive.
Bot automatically attempts exploit against known vulnerability in service.
Exploit succeeds, bot owner gains access to compute resources and personal information.
Mitigations::
  Keep service up to date.
Secure ((WAN)) boundary: monitor traffic logs, employ an ((IPS)) (intrusion prevention system), only cross into ((LAN)) using a ((VPN)) (virtual private network).
Close WAN boundary: disallow all inbound WAN access.

Should you choose to expose a service, these mitigations will help secure it.
"`Avoid public mailing lists`" is not listed in mitigations as it only obscures the URL to the out-of-date service, and one shouldn't rely on "`security through obscurity`".

[%unbreakable]
TIP: Mitigating at multiple layers (OS firewall, service, WAN boundary) demonstrates "`defense in depth`", a common and worthwhile security practice.

==== VPN

A ((VPN)) can secure your ((WAN)) boundary by only allowing authenticated users and adding a layer of encryption.
You can safely teleport back into your ((LAN)) while you are remote.

If all your users are able to use a VPN, you can keep ports closed for HTTP/S traffic and instead only allow VPN traffic.
Assuming your VPN server is well-configured and up to date, this is an excellent way to reduce your ((attack surface)).

((VPN)) technology enjoyed a major upgrade with https://www.wireguard.com[Wireguard].
From a user perspective there's no heavyweight login process, as with older VPNs.
((Wireguard)) is fast, easy, and secure.

==== Full-disk encryption

(((encryption, full-disk)))
Encrypting prevents data recovery by an attacker.
You'll have to enter a password on boot, though.
This is inconvenient if you have intermittent power and/or no remote management capability.
There's also the reasonable argument that full-disk or "`at-rest`" encryption offers little for an always-on server: during normal operation you've already supplied the decryption key.

(((OS)))
If you decide you want full-disk encryption, choose it during <<OS install>>.
Review the material earlier in this chapter if you want help with your decision.

==== More tips

.Self-hoster security tips
****
* Maintain useful encrypted ((backups)).
Perform test restores to prove they are useful.
See <<Backups>>.
* Avoid running commands as the `root` user.
* Use multi-factor authentication.
* Use firewalls.
* Use strong passwords.
* Be very careful when port forwarding or don't do it at all.
* Be vigilant about all the usual stuff too: ((phishing)), ((malware)), SMS spoofing, and social attacks.
** Take caution with email links and attachments.
** Don't install untrusted software.
Always use HTTPS.
** Use a special passphrase with your ((mobile)) carrier as an extra layer of authentication.
** Question urgency and suspicious requests.
* Send unrecognized calls to voicemail.
* Pay attention to data breaches and protect your identity.
** Freeze your credit after a breach.
* Learn about compartmentalization and the principle of least privilege.
****

Further reading:

* https://oreilly.com/library/view/personal-cybersecurity-how/9781484224304/[Personal Cybersecurity: How to Avoid and Recover from Cybercrime] by Marvin Waschke
* https://modernprivatelife.com/how-to-choose-privacy-threat-model/[Personal Privacy Threat Modeling (With LOTS Of Examples)] by Eliza
* https://arstechnica.com/information-technology/2017/07/how-i-learned-to-stop-worrying-mostly-and-love-my-threat-model/[How I learned to stop worrying (mostly) and love my threat model] by Sean Gallagher

=== Filesystem

I recommend (and will demonstrate) starting with one ((ext4)) filesystem and, optionally, one ZFS filesystem.
ext4 is the stable, simple, and default filesystem for Ubuntu.
((ZFS)) (originally: Zettabyte File System) provides encryption, lightweight snapshots and ((RAID)) (redundant array of inexpensive disks).
You may optionally use ZFS for storage (`/data`) on your server following <<ZFS setup>>.

For the root (`/`) partition, I recommend using ext4 instead of ZFS to:

* stick as closely as possible to the default ((Ubuntu)) install
* avoid ((Docker)) filesystem clutter
** when `/var/lib/docker` is on ZFS, many Docker-related filesystems are created, cluttering up `zfs list` a bit
* avoid taking ZFS snapshots of the OS, since
** we don't need to
** the OS will live outside ZFS folders
** we won't modify the OS--changes will be managed upstream (e.g. during package updates or via mario)

Docker volumes (persistent container data) will be on ZFS.
The ((container))'s filesystem--everything besides mounted volumes with persistent data--is ephemeral and stored on ((ext4)) in `/var/lib/docker`.
To learn more about ZFS, see:

* https://arstechnica.com/information-technology/2014/01/bitrot-and-atomic-cows-inside-next-gen-filesystems/[Bitrot and atomic COWs: Inside "`next-gen`" filesystems] by Jim Salter
* https://arstechnica.com/information-technology/2020/05/zfs-101-understanding-zfs-storage-and-performance/[ZFS 101Understanding ZFS storage and performance] by Jim Salter
* https://wiki.debian.org/ZFS[ZFS (Debian wiki page)] by various authors

Other ZFS concepts worth learning about: fragmentation, ARC (adaptive replacement cache), resilvering, scrubbing, `ashift`, and `recordsize`.

=== Operating system

Linux is a popular and reasonable choice for self-hosting.
I recommend a 64-bit ((Ubuntu)) ((Linux)) server with at least 2GB memory and 30GB storage.
((Ubuntu)) ((LTS)) (long-term support) releases are the most stable and I recommend them.
Installing the ((OS)) is generally quick and painless, see <<OS install>>.

==== Customizations

It's good practice to carefully manage customizations to the ((operating system)) from a default install.
This eases maintenance, including eventual re-installs.
Not mucking about on the server takes discipline, especially for old-school hands-on ((sysadmin))s like me.

Try to avoid SSH'ing into the server and making one-off changes.
You'll learn how to instead modify mario's configuration files and re-provision the server in <<_mario>>.

You can and should still ((SSH)) into the server, but when you do, try to only run read-only or exceptional read-write commands.
I often do something manually, undo it, then do the same thing with mario to confirm results are as expected.

****
Example read-only server-side operations:

* show per-((container)) resource usage: `sudo docker stats`
* follow container log messages: `sudo docker compose logs -f` (run this in a folder containing a `compose.yml` file)
* check server health: `date; tail /proc/pressure/*`

Example read-write server-side operations:

* upgrade ((OS)) packages: `sudo apt full-upgrade`
* change permissions for a folder: `chmod 0700 ~/bin/`
****

Start a "`monthly maintenance`" checklist like the one found in <<Server maintenance>>.
Include these read-write operations in your checklist.
Whenever possible, use mario to perform read-write operations.

Always use `sudo` to run privileged commands instead of logging in as `root`.
This ensures every command is captured in `/var/log/auth.log` along with when it was executed, and by whom.

Upgrades may be automated.
This is appropriate once you have sufficient scale (along with trust and control of the source of the upgrades).
I usually do ((OS)) upgrades manually because I manage few systems so the burden is minimal and infrequent, and upgrading a package may require testing or manual intervention (e.g. rebooting).
These reasons are similar to the reasons I install the OS itself by hand.

My OS is more a pet than cattle (see "`cattle vs. pets`" in <<Glossary>>).
Perhaps it is a pet phoenix.
When it dies, it will be relatively easy to revive from the ashes.
It is backed up, there are few manual steps to perform, and all the manual steps are carefully documented.

=== Contained services

mario uses ((Docker)) to run services in containers.
Docker is but one of many valid choices for how to isolate and run services.
((VM))s are also often used for this purpose.
See <<Containers == happy>> for a comparison of the two.
If you're interested in ((VM))s (instead of or in addition to containers), check out https://proxmox.com[Proxmox].

((Kubernetes)) also works well for running services.
Try Kubernetes (especially one of the interesting micro-versions) if you are more familiar or interested in that.
I found it to be overkill.
If I needed high availability via clustering I'd be more likely to use Kubernetes.
If one computer in a Kubernetes cluster breaks, services can automatically migrate to working hardware in the cluster.
Regardless of your tech choices, set a clear expectation to your users as to how long your server might be down when something breaks.

Docker balances features and usability well, making it easy to run one service in ((isolation)).
((Docker Compose)) adds the ability to define and run the groups of processes necessary to support a whole service (e.g. a web server and its database).
Kubernetes can do this too, along with everything you _don't_ need to learn unless you are building out an entire virtual data center.
Docker Compose is a good fit for a single-server setup.

It is also good to avoid intermingling services and their dependencies along with everything else on the server's primary storage.
Having everything on one filesystem is easy at first, for one service.
https://en.wikipedia.org/wiki/Dependency_hell[It gets more complicated the more services you add].

Many of the desperate self-hoster support requests I see in FOSS communities are about incompatibilities between this or that version of PHP or relational database between two different services.
Docker mitigates this by bundling dependencies.
Each Docker image is basically a complete filesystem (sans kernel), so a service's image would always include the correct PHP version.
Another image would be used to create the database, if/as necessary.

It's worth lingering on bundled dependencies for a minute.
If dependencies are clothes, a Docker ((container)) is a strong and cheap suitcase with all the clothes you need for a week's travel.
You check your suitcase and board the train, then rest easy knowing your suitcase is tucked neatly, separately, next to all the others.
Docker containers are suitcases while the old way is everyones`' unfolded clothes in a giant pile in the caboose.

Containers are created from images.
An image is the blueprint to magic a fresh new suitcase (container) into existence, all packed and ready with the right clothes for your trip.
An image is built once, stamped with an identifier, and shared, where it can act as the basis for countless consistently-behaving containers.

Images are defined by a file named `Dockerfile`.
The `Dockerfile` should be tracked in source control.
Since mario uses ((Docker Compose)), another important file is `compose.yml`.
Each service will have its own `compose.yml` file.
These should be kept in source control too.
For ((sysadmin))s these conventions provide reproducible images and containers.
For users: predictable, reliable services.

Practice treating containers as temporary things.
You'll gain confidence in your system by creating and destroying them frequently, and you'll enjoy the speed and ease of doing so.
Think:

* ephemeral
** ((container))s are temporary
** temporary containers provide robust, reproducible services
* cattle, not pets
** hand-managed ((VM))s are burdensome pets
** apologies to the cattle--in this analogy they are expendable
* stateless
** persistent data can and must be defined explicitly
* phoenix server
** a term by Kornelis Sietsma describing repeated server destruction and re-creation

=== Reverse Proxy

A ((reverse proxy)) sits in front of containers and directs traffic to the right service based on arbitrary rules.

Say you've purchased the domain example.com and want to host Nextcloud at cloud.example.com and Jellyfin at jellyfin.example.com.
In order to direct incoming traffic to each of these services, your server will need a reverse proxy.

mario uses Traefik for its reverse proxy.

==== Traefik architecture

Here's a bit about how ((Traefik)) works and how it works with ((Nextcloud)) and other self-hosted web services.

We want ((HTTPS)) requests to port 443 bound for cloud.example.com to reach the Nextcloud service.
Study the included Traefik architecture diagram to better understand this process along with the mario sources.

[#image-traefik-architecture]
.Traefik architecture diagram showing how a request reaches a service. From the MIT-licensed Traefik source code. Credit to Peka for the gopher logo, licensed CC-BY-3.0.
image::traefik-architecture.png[]

(((router, Traefik)))
In the mario source code (or the snippets appearing later), look at the `compose.yml` files for Traefik and Nextcloud, which include:

* the `websecure` ((entrypoint)), where we accept HTTPS traffic on port 443
* the `app` service definition for Nextcloud, which includes Traefik routing labels
* the `Host(...)` rule in the `nc-https` router

[%unbreakable]
NOTE: The symbols `app`, `websecure`, and `nc-https` are arbitrary.
I used short names to keep them from wrapping across lines.
You may wish to use longer, more descriptive names.

The routing labels wire together the entrypoint and router with the service under which they are defined.
That is: `websecure` to `nc-https` to `app`.

These two snippets of the mario source show how we set up Traefik for ((Nextcloud)).

.Traefik and Nextcloud service configuration snippets (admin computer)
[source,yaml]
----
# snippet from traefik/compose.yml
services:
  reverse-proxy:
    command:
      - --entrypoints.websecure.address=:443 <1>

# snippet from nextcloud/compose.yml
services:
  app:
    labels:
      - "traefik.http.routers.nc-https.entrypoints=websecure" <2>
      - "traefik.http.routers.nc-https.rule=Host(`cloud.example.com`)" <3>
----

<1> Define ((entrypoint)) `websecure` on the `reverse-proxy` service, accepting traffic over port 443.

<2> Connect the `websecure` entrypoint with the `nc-https` router on the `app` service.

<3> Use the hostname rule with the `nc-https` router.

(((router, Traefik)))
Each self-hosted service will have its own router.
Other web services will also use the `websecure` ((entrypoint)).

HTTPS encryption is configured using other labels on the ((Traefik)) ((container)).
See <<Encryption certificates>> for details.

== Implementation

Now we're ready to stand up the first three layers in <<Service stack>>: Hardware, filesystem, and OS.
I'll start by providing tools to evaluate services, then continue to OS installation and server maintenance.

=== Service plan

Services are long-running software programs on your server.
Some have an interface, some run in the background on a schedule.
"`Web services`" are the ones you can connect to using a web browser or other tool speaking HTTP.

==== Choose services

Start by reviewing your earlier needs and plans and use the material below to guide your decisions on which services you'll run.
You may also skip ahead to <<Prepare hardware>> to continue on the path of using the services mario installs by default, then return to this section when you're considering other services to add.

===== Good for self-hosting

You'll find some services are better choices to self-host than others.
The good ones will likely share at least some of these traits.

.Traits of Good Self-Hosted Services
[#traits-of-good-services]
****
* Easy to install and self-hosting instructions exist.
* Works with your preferred deployment method, e.g. has a popular and well-maintained Docker image, has instructions for integrating with ((Docker Compose)) and ((Traefik)).
* Community uses tools such as moderated chats, forums, news, mailing lists, and meetups.
* Recent source code activity: releases, contributions, news.
* Uses a FOSS software license.
* Transparent about owners and sponsors.
* Public roadmap, issue tracking, continuous integration, working demo, build scripts, bug/security bounties.
* If you experience a problem you're able to easily find more information about it (e.g. existing issue in tracker, workarounds) by searching the web.
* Well-organized, elegant code.
* Useful and up-to-date documentation.
* Mentions and compares itself with other similar services.
* Well-documented, useful, and complete ((API)).
* Flexible and extensible (easy to customize and extend with plugins and such).
****

See also: <<solution-viability-checklist>> in <<Alternatives to this book>>.

These traits are based on standard industry practice as well as my personal values and preferences.
Your own list may differ if, for example, you don't prefer FOSS licensing or do prefer a particular programming language.

===== Bad for self-hosting

Here are some indications a self-hosted service might be one to avoid.

.Traits of Bad Self-Hosted Services
[#traits-of-bad-services]
****
* Unpopular, inactive, or poorly maintained.
** Few maintainers / contributors.
** Maintainers are inattentive to contributors.
* Includes telemetry (phones home, collects statistics or usage data), especially without your consent and/or enabled by default.
* Has known security vulnerabilities.
* Confusing or opaque governance, roadmap, licensing, source control, contribution intake, issue tracking.
* Sprawling complexity.
* Difficult to fork.
* Only geared towards enterprise: self-hosting instructions are complex or missing entirely.
* Frequent annoying upsells/nags.
* Intentional vendor lock-in.
* Depends on closed/proprietary standards/services.
* https://en.wikipedia.org/wiki/Open-core_model[Open core].
****

(((Nextcloud)))
I'm going to pick on Nextcloud here a bit.
Nextcloud has far more good traits than bad, but these are still worth mentioning.

First, their apparently non-FOSS build script.
https://help.nextcloud.com/t/build-bzip-and-package-from-git/58341/2[Nick's explanation] for this makes sense: it is more convenient for them to hardcode secrets directly in the build script and keep the whole thing secret.
But hardcoded secrets are bad practice, it may be an ((AGPL)) license violation to hide a build script, and it makes forking harder.
It's good practice to visualize succession, to be prepared for an eventual fork and change of ownership.
Nextcloud is a fork of ((ownCloud)), after all (see <<Nextcloud vs. ownCloud>>).

Second, sprawling complexity.
"`Nextcloud`" is not one thing, it is a collection of _many_ software projects and services under various degrees of control by a single company.
This complexity makes forking costly and time-consuming.
Even switching between extant forks (say, migrating back to ownCloud from Nextcloud) may be complex.
They are clearly _not_ trying to lock in customers, but the complexity itself may ultimately have that effect.

==== Map services to resources

Here's an early, rough resource planning table I used.
You can use this pattern to estimate your own resource needs.
I go into detail about a few of these services later in the book.

[%unbreakable,cols="4,4,3,2,2"]
|===
|Service |Purpose |Isolation |Cores |RAM

|jellyfin |stream music |Docker |2 |2
|kahoot-clone |quiz game |Docker |0 |0
|poller |polls |Docker |0 |0
|backuppc |backups |none |0 |0
|taskd |task tracking |Docker |0 |0
|sftp |file transfers |none |0 |0
|syncthing |file sync |none |1 |1
|nextcloud |file sharing |Docker |2 |2
|minetest |game server |Docker |4 |8
|irssi |chat client |none |0 |0
|jitsi |video calls |Docker |2 |2
|wallabag |article saver |Docker |1 |1
|===

"`Cores`" represents relative peak compute requirements.
RAM: peak memory, in GB.
These were rough estimates based on published documentation.
The estimates turned out to be accurate enough.
I could see right quick I'd need something more powerful than the latest available Raspberry Pi.
See <<Server>> for more lessons learned about resource requirements.

=== Prepare hardware

It's called __hard__ware because these problems are _hard_.
That's fun to say and, in my experience, false.
While there is a learning curve for understanding basic computer hardware components and hardware can certainly fail, there are plenty of wonderfully positive aspects of hardware. For example:

* Hardware is tangible and behaves consistently.
* Just plug it in, turn it on, and it'll probably work.
* When it does work, it is quite satisfying.

==== Server

You'll need a server.

You can always pay for "`compute`" in someone else's cloud, but it'll end up costing more in the long run.

If you're in a hurry, you can start with pretty much any old desktop or laptop, or your own VM running on either.
Use something more powerful and expandable than a Raspberry Pi, though.
What if your users love it?
How will you increase storage?
What about bursty workloads?
If you start with something too small you won't have enough speed nor expandability.

I've worked with quite a few different servers and I did my homework for this self-hosting adventure, so I had a decent idea of what I wanted.
I chose something powerful, cheap, and fast with plenty of storage and room to grow.
I sought professional commodity hardware for its replace-ability.
It can handle a reasonable amount of bursty compute needs, including building Docker images, flurries of user activity, and some generative ((AI)) (even without a GPU).

I found a used refurbished 1U rackmount server on eBay for about $1,000.
This is sometimes called "`off-lease enterprise hardware`".
A 1U server is one https://en.wikipedia.org/wiki/Rack_unit[rack unit] tall, like a long pizza box.
Tech companies dump these by the truckload so you can usually find a good deal.
Mine has two 24-core CPUs and 128 GB RAM.

[#image-racked-server]
.DIY rackmount server attached to garage ceiling. It's fun to look at and is out of the way, but I need a ladder for maintenance and it weighs about 50lbs.
image::racked-server.jpg[]

The fans are _way_ louder than a desktop, especially when it is under load.
It is supposed to have decent ventilation, temperature and humidity regulation yet has so far been extremely hardy even below freezing and above 100F for extended periods of time.
It has several enterprise features to ease maintenance such as redundant power supplies, hot-swap drive bays, lots of sensors, and remote management via a web browser or IPMI.

Power consumption averages 130W, or about 1,140kWh per year; roughly $138.15 in Seattle.
That's about as much as a bright incandescent light bulb, and it's a bit wasteful for one user.
Five users though?
~228kWh/year each.
That's less than the cloud server hardware required for a ((mobile)) device making use of Google's or Apple's clouds.
Further reading on this topic:

* https://science.time.com/2013/08/14/power-drain-the-digital-cloud-is-using-more-energy-than-you-think/[The Surprisingly Large Energy Footprint of the Digital Economy] by Bryan Walsh
* https://theguardian.com/sustainable-business/2014/sep/10/energy-consumption-behind-smart-phone[The spiralling energy consumption behind your smart phone] by Betsy Reed
* https://increment.com/energy-environment/the-secret-energy-impact-of-your-phone/[The secret energy impact of your phone] by Owen Williams

A rackmount server like mine can handle far more than 5 users, assuming they aren't all trying to transcode video.

It also makes a great heated perch.

[#image-bird-on-server]
.Bird perched on server.
image::bird-on-server.jpg[align="center",scaledwidth=50%]

==== Admin computer

(((admin computer)))
(((provision)))
It's helpful to have a separate computer from your server to make changes.
I usually run mario using a laptop as my admin computer.

==== Test devices

Your users will have their own computers and ((mobile)) devices (their _clients_).
Maintain a couple of different clients so you have comparable environments to better help your users.

TIP: Be a user of the services you self-host.
This is _dogfooding_.
Dogfooding keeps you honest and helps you empathize with others.

==== Hard drives

(((ZFS, HDDs and)))
I use ((HDD))s (hard disk drives) for data storage, mainly as a cost-saving measure vs. public cloud storage or ((SSD))s (solid-state drives).
The cost of public cloud ((block storage)) far exceeds the gigabyte-hour cost of my HDDs.
I priced out one month of 5TB HDD block storage on AWS at $228.10.
With ZFS I'm also taking a snapshot (bascially a full local backup) _every fifteen minutes_.
One month's worth of hourly snapshots (the closest comparable I could find) is another $310.68 on AWS.
That's $535.67 total, which is about what I spent on my drives.
So I broke even in a month and the drives should last _years_.

(((RAID)))
For redundancy I recommend using two of the same drive, mirrored (RAID 1).
This also increases read performance (for most reads) and halves usable storage space.

HDDs are plenty fast when measured from the standpoint of self-hosted service response time.
(((operating system)))
The OS (operating system) and services do well at caching data served, assuming the server has sufficient RAM.
Remote ((backups)) can take a while, and that's fine.

I use one ((SSD)) for the ((OS)) and everything besides my photos/documents/etc, since start-up time for the OS is important and realizes far less benefit from the OS filesystem cache (especially at boot time).

(((data sovereignty)))
An interesting alternative to HDDs is ((object storage)).
((Nextcloud)) can use object storage directly, for example.
There are many aspects to consider when comparing the two options, such as:

* cost of storage and ((egress)) (download)
* control, autonomy, sovereignty
* direct access to data
* speed and means of access
* network availability
* ((backups)), versioning, security

I went with ((HDD))s for direct, local access to my data.
I really wanted to know exactly where they were stored and for ultimate flexibility when I change or try new services.
Most of my services require direct access anyway.

==== Networking

If you are hosting at home, you need a reliable WAN (wide-area network) connection if you want to be able to connect from other places besides your ((LAN)).
Use wired ethernet cables to your server, not Wi-Fi.
A wired LAN is more reliable and easier to troubleshoot.

===== Minimum requirements

Here are some typical minimums for hosting at home:

* 100mbps up / 100mbps down ISP connection
* Cat 5 ethernet cable (for your server)
* 802.11ac Wi-Fi (for clients)

I just made these up based on what works for me, then doubled that so you have some room to grow.

===== Home router configuration

(((router, network device)))
Learn how to configure your router.
Keep it up to date and maintain a strict ((firewall)) with only the necessary ports open / forwarded.

[%unbreakable]
CAUTION: Port forwarding allows inbound connections through your WAN boundary to your server.
Read <<Digital security>> before forwarding any ports.

Make a sketch to better understand your network.
Here's a simple diagram I created using https://asciiflow.com to plan cabling and visualize the flow of traffic through my network devices:

[#image-WAN-to-LAN-traffic]
.WAN into LAN traffic flow diagram.
image::WAN-to-LAN-traffic.svg[align="center",scaledwidth=80%]

(((router, network device)))
Arrows represent ethernet cable.
The router provides electricity to the mini switch using PoE (power over ethernet).
The server has two NICs (network interface cards): one for the ((OS)) and everything within (including all services), and one for a network connection to the embedded OOB (out-of-band) remote management computer with IPMI (Intelligent Platform Management Interface).
WAN traffic is allowed to flow to the main NIC and not to the IPMI NIC.

==== Electricity

Use a surge protector.
Consider a UPS (uninterruptible power supply) if your power at home is unreliable.

==== Physical security

Keep your server safe, similar to other valuables in your home.
At the very least, restrict physical access.

=== OS install

Here's a guide to setting up your server.
The OS install takes about five minutes if everything proceeds smoothly.
Steps are omitted for brevity when the default is acceptable.

NOTE: As you install the OS, think ahead to disaster recovery.
Take notes and visualize yourself repeating the process precisely.
At each step in the interactive Ubuntu installer, accept the default or write down your choice.

. *Install Ubuntu*.
Pick the latest ((Ubuntu)) ((LTS)) release, e.g. 64-bit Ubuntu 22.04 LTS server.
Refer to https://ubuntu.com/tutorials/install-ubuntu-server[this tutorial] for step-by-step instructions.
. Optional: use full-disk encryption.
See <<Full-disk encryption>>.
. When you set up a user account (called a "`Profile`" in the installer), *note the username and password*. You'll need these in <<Connect to server>>.
. *Install OpenSSH server* when prompted to do so.
. *Do not install Nextcloud or Docker*, let mario install these later.

That's it for the OS install.
Next steps:

. Optional: after installing Ubuntu, add two ((HDD))s and format them with ((ZFS)).
See <<ZFS setup>>.
. Download mario onto your ((admin computer)) (a separate computer from your server). See <<More resources>>.
. Run mario on your ((admin computer)) to provision your server. See <<_mario>>.

==== ZFS setup

(((ZFS, setup)))
The ((OS)) takes care of itself pretty well.
For more robust data storage, we can add a couple of ((HDD))s and manage them with ((ZFS)).

ZFS adds many features and some complexity.
The learning curve is worth it.
The guide below walks through creating a simple pool of two mirrored drives, visible at `/data`.
This is a reasonable starting point, providing increased fault tolerance and better read performance than a single drive.

On the server, run these commands as `root` (hint: use `sudo su -` first).
The code below assumes you've added two drives and they were assigned `/dev/sda` and `/dev/sdb`, so adjust device names as necessary.
Use `lsblk` to figure out your device names.

// This code snippet is wrapped by Vim with textwidth=75 since this just happens to be what fits in the current print book margins. 

.ZFS setup (server)
[source,bash]
----
# Create partition tables.
parted /dev/sdb mklabel gpt
parted /dev/sdc mklabel gpt

# Create ZFS main mirrored pool and set attributes (for all future datasets
# in this pool).
zpool create -O mountpoint=none main mirror /dev/sdb /dev/sdc
# For performance.
zfs set atime=off main
# To save space.
zfs set compression=on main
# For security.
zfs set exec=off main
zfs set setuid=off main
zfs set canmount=off main

# Create encrypted dataset in "main" pool. This is the "parent" dataset, we
# can easily add more later and they'll all be encrypted.
openssl rand -base64 32 > /root/secure-dataset-key
zfs create -o encryption=on -o keyformat=passphrase \
    -o keylocation=file:///root/secure-dataset-key main/secure
zfs set canmount=off main/secure

# Create usable (mount-able) dataset.
zfs create -o mountpoint=/data main/secure/data

# This might not be necessary if you _never_ want to execute anything in
# /data. I found I needed it for something within a container (ffmpeg, I
# think). You can start with exec=off and turn it on later if you want.
zfs set exec=on main/secure/data
----

Here are a few commands to see details about what you just created.
These do not require root access.

.show ZFS details (server)
[source,bash]
----
# Examine pools.
zpool status
zpool list

# Examine datasets.
zfs list
----

On Ubuntu 22.04 LTS, more steps are required to automatically mount this new filesystem when the server boots.
What follows is from the `zfs-mount-generator(8)` manual page, with a few corrections.
These must be run as `root`.

.ZFS mount on boot setup (server)
[source,bash]
----
# enable tracking for the pool
mkdir /etc/zfs/zfs-list.cache
touch /etc/zfs/zfs-list.cache/main

# enable the tracking ZEDLET
systemctl enable zfs-zed.service
systemctl restart zfs-zed.service

# trigger cache refresh
zfs set relatime=off main/secure
zfs inherit relatime main/secure

# re-run systemd generators and reboot
systemctl daemon-reload
reboot
----

=== Server maintenance

(((router, network device)))
I use short monthly and yearly ((maintenance)) checklists.
I update my checklists about as often as I use them.
Here are examples you might use as starting points.

.Checklist: Monthly Maintenance
[%unbreakable]
****
* [ ] Upgrade ((OS)) packages.
* [ ] Check storage space remaining.
* [ ] Back up router configuration.
****

.Checklist: Yearly Maintenance
[%unbreakable]
****
* [ ] Test restore from backup.
* [ ] Review and improve ((threat model)).
* [ ] Open server chassis and vacuum dead spiders.
****

The following sections cover specific maintenance tips and tricks.

==== Hardware failure

Plan on hardware failure.
If you can afford it, the easiest way to reliably run one server is to _buy two identical servers_.
Use the second for parts or a ready as-is replacement machine (also called a "`cold spare`").

==== Software updates

Keep your server up to date.
For the OS:

.upgrade packages (server)
[source,bash]
----
sudo apt update && sudo apt full-upgrade
----

This will update local package information and--if that succeeded--upgrade the OS.
Root access is required, hence `sudo`.
This is relatively safe and typically requires little to no interaction besides a confirmation to proceed.
A reboot may be required afterwards (e.g. when the kernel is upgraded).
When you ((SSH)) into the server, it will tell you if a reboot is required. 

Each service in <<Services>> includes a "`Maintenance notes`" section with update instructions.
Container images can be updated by hand with ((Docker Compose)) or automatically by ((Watchtower)).
See <<Watchtower>> for details.

==== Monitoring

Monitor server health.
Check free disk space with `df -h`.
If things feel slow, check PSI (pressure stall information) with

.check PSI (server)
[source,bash]
----
tail /proc/pressure/*
----

`atop` will also show PSI values.
If your PSI check shows high resource usage, try `docker stats` to see resource usage per container.
That should help you narrow down the issue to specific services.

If you are using ((ZFS)), you can use `zpool iostat` to see input/output statistics for your storage pool(s).

At the host level, you can use `htop -d 100` to see stats for all processes and threads.
Follow all logged events for the host with `journalctl -f`.

==== Backups

Having useful backups is one critically important practice you'll rarely get credit for doing well, only blame if it is done poorly.

Check your backups regularly to make sure they work.

(((ZFS, snapshots)))
Make consistent backups of everything on your server, such that the services running are unaware they are even being backed up.
For example: create a ZFS snapshot and back _that_ up.

Backing up using ZFS snapshots _can_ still cause problems.
For example, ZFS doesn't guarantee consistent state of backed-up data for running programs.
Say you restored a ((MariaDB)) database from backup.
Unless you flushed and locked tables before taking that ZFS snapshot, MariaDB might have been in the middle of a write operation with in-memory data not yet flushed to disk.
It would need to recover, and the data MariaDB was trying to write may be lost.
This manner of data loss is rare, and the risk is acceptable for the typical homelab.

[%unbreakable]
TIP: Create ((backups)) following the 3-2-1 rule of thumb: make *3* backups.
Store at least *2* local copies on different media.
Have *1* remote backup.

(((restic)))
(((Borg)))
I recommend a backup strategy combining ZFS snapshots with either https://restic.net[restic] or https://borgbackup.org[Borg] for sending them offsite.
https://reddit.com/r/BorgBackup/comments/v3bwfg/[Here's a decent comparison of restic vs. Borg].

Here are some example commands demonstrating how to back up a ((ZFS)) filesystem.
You can use these to get started writing your own backup script.

.example backup script (server)
[source%unbreakable,bash]
----
snapName=$(date -I)-backup

sudo zfs snapshot main/secure/data@$snapName <1>

sudo restic backup /data/.zfs/snapshot/$snapName <2>

sudo zfs destroy -R main/secure/data@$snapName
----

<1> Running this command to create a snapshot takes 0.040 seconds on my server.
Once it is done, a new read-only folder will appear under `/data/.zfs/snapshot` containing the snapshot.

<2> This line assumes you have installed and configured ((restic)).
It can send your snapshot offsite, following the 3-2-1 rule of thumb.

== mario

mario is a tool I built to help you set up and maintain a server.
It is mainly a wrapper around the well-established https://ansible.com[Ansible] system provisioner.
Everything I'll do with mario can also be done manually, directly on the server.
The advantage of using mario instead is that each change (say, installing a package) will be made consistently and with an audit trail.
The real payoff of this practice is realized when you collaborate with others, including your future self.
It's not often easy to remember what you did a year ago and why.

Once your server is online following <<OS install>>, use mario to configure and start services.

Please download the source code (see <<More resources>>).
It'll be helpful to have this handy so you can follow along as you read.

mario can be found alongside this book, in the `mario/` folder.
The `provision.sh` script is in `ansible/`.

=== mario philosophy

mario is a practical learning tool.
It comes with sensible, tested defaults.
It automates some of the tedious, confusing steps of setting up services on a server.
mario is not a supported and production-ready software product.
It'll get you started, that's all.
Continue with it if you like or just use it to fast-forward your personal cloud setup.
Something else does or will do its job better.
Here are some suggestions to get the most out of mario.

The first time you run mario, follow the instructions as closely as possible.
Many assumptions are made so it works "`out of the box`", and it is meant to be easily customizable.

mario configuration files are declarative: They contain the _state_ you want your server to end up at, not all the individual commands you'd run manually to achieve the same state.
mario runs Ansible, and Ansible runs the commands for you on the server (like running `chmod` on a file) in a predictable and repeatable manner.
The desired end state, as declared in the configuration files, is reached and confirmed by Ansible.

(((provision)))
After getting mario up and running successfully once, run it again!
Provisioning with mario is reassuringly ((idempotent)): The system will not change in any meaningful way after the desired state is reached.
Once `provision.sh` completes successfully, it may be re-run to confirm the server is still in the desired state.
Then, start tinkering.
You can find some ideas in <<Exercises>>.

If you are familiar and comfortable with ((VM))s, you may want to first create a VM and run mario against that until you're ready to run mario pointed at your real server.
Or perhaps your real server _is_ a VM--that'll work fine too.

=== First run

Go ahead and run `provision.sh` on your ((admin computer)) (_not_ on your server):

.mario first run (admin computer)
[source%unbreakable,bash]
----
cd mario/ansible
./provision.sh
----

mario is semi-automated, providing hints on manual steps to take between runs.
On this first invocation, mario will check for prerequisites and prompt you to enter values specific to your server into a configuration file.

.mario first run output (admin computer)
[source%unbreakable,text]
----
You don't have a config file. I'll create one for you now.

Please edit 'config' and re-run this script.
----

Here's a guide for settings in your `config` that must be changed from their defaults.
Be sure to study the comments in that file, too.
I'll assume you have a domain name and a DNS provider with an API.
See <<Server domain name>> for details on how to obtain this.

`DNS_API_PROVIDER`::
Enter the name of your ((DNS)) provider here.
mario configures ((Traefik)) to talk directly with your DNS server for issuing ((Let's Encrypt)) certs.
`NAMECHEAP_*`, `DUCKDNS_*`, `R53_DNS_*`, `DO_*`...::
Enter credentials in these fields corresponding to the value you specified in `DNS_API_PROVIDER`.
`DNS_RESOLVER_EMAIL`::
Enter an email matching what you use with your DNS API provider.
You may receive emails from Let's Encrypt at this address.
`MARIO_DOMAIN_NAME`::
This will be a name like `example.duckdns.org` or `example.com`.
Individual services will be named based on this, e.g. `jellyfin.example.com`.

Finish editing `config` and run `provision.sh` again.

.mario second run output (admin computer)
[source%unbreakable,text]
----
You don't have an Ansible inventory file. I'll create one for you now.

Please edit 'hosts.yml' and re-run this script.
----

Oh great, _another_ configuration file?
Don't worry, there's only one value to change: `ansible_become_password`.
That should be set to the password you entered when you created the user account on your server, way back in <<Server startup>>.

TIP: If you don't want to store the password in `hosts.yml`, see <<Plaintext password alternative>>.

Make sure you can connect to your server via `ssh mario_server` with public key authentication.
See <<Connect to server>> for how to configure your SSH client for this.

Finally, you're ready to mario your server into submission.
Forge ahead to <<Provision complete>>.

=== Server domain name

Your server needs a domain name.
You can either use a free domain name or buy a domain name from a registrar.
mario needs the domain name to be able to use a DNS provider with an API for setting up ((HTTPS)) web traffic encryption.

You may also want to be able to refer to your server by name when you're away from your LAN if you allow ((WAN access)) and/or if you have a ((dynamic IP address)).
This text does not include a complete primer on DNS, so you'll need to look elsewhere to learn concepts such as public and private IP address spaces, CIDR notation, and the various kinds of DNS records.

==== Public DNS

Duck DNS provides a free domain name and DNS service.
mario also works with paid services such as Namecheap, DigitalOcean, and Route 53.
I recommend any of the paid options over Duck DNS.
Support for other ((DNS)) providers (ahem, especially self-hosted ones!) may be added later.

NOTE: Public DNS records do not presume ((WAN access)).
<<Digital security>> covers WAN access in detail.

===== Duck DNS

If you want a free domain name from a provider with an API, you can try your luck with Duck DNS.

. Start at https://duckdns.org.
. Log in and add a domain.

===== Amazon Route 53

If you choose Route 53, create a new hosted zone with the domain name you own.
Make note of the Route 53 name servers.
Back at your registrar, input these name servers.

On Amazon IAM, create a user with permission to update this hosted zone.
Here's a policy with way too much access that nevertheless works:

.naive Route 53 policy
[source%unbreakable,json]
----
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": "route53:*",
      "Resource": "*"
    }
  ]
}
----

==== Dynamic DNS

If you want ((WAN access)) and your ((IP address)) changes periodically, it's handy to have this updated in ((DNS)) automatically.
Similar to Traefik setting up ((HTTPS)) certs, this uses a DNS provider API.
There are several options here, all left as exercises for the reader.
One idea is to find and stand up a dynamic DNS client for your Docker image.
These are generally very simple services to set up.
(((router, network device)))
Another idea is to see if your router will do the dynamic DNS updates.

==== Internal DNS

It is handy to have an internal ((DNS)) server to be able to refer to your server by name.
These internal names should match the public names and point to ((LAN))-only private IP addresses.
This way you can use the same names inside and outside your LAN and your Let's Encrypt certs will work.

If you don't have an internal ((DNS)) server, use hostname to IP address mappings in `/etc/hosts` or similar directly on your admin computer.
For example:

[source%unbreakable,text]
----
192.168.1.100	traefik.example.com
192.168.1.100	cloud.example.com
192.168.1.100	jellyfin.example.com
192.168.1.100	wallabag.example.com
----

IP addresses can be repeated because the ((reverse proxy)) will direct traffic based on hostname.

Overriding DNS records like this is a temporary measure.
Only the computer with these specific mappings will be able to get to your sever by name.

TIP: I've shown examples of two styles of service domain names.
`cloud.example.com` indicates the function of the service, rather than the service's brand name.
`nextcloud.example.com` would work just as well.
The choice is yours.

=== Connect to server

mario runs on your ((admin computer)) and expects to be able to connect directly to your server using SSH.
Public key authentication eases this.
If you have a key pair, use it.
If you need a key pair, run `ssh-keygen` or similar on your ((admin computer)) to create one.
Copy the public key to the server with `ssh-copy-id` or similar.

Teach your client what to do when you run `ssh mario_server`.
Map `mario_server` to the name of your server, and `your-username` to the account username on your server.
Here's an example client configuration template for ((OpenSSH)):

.mario server snippet in OpenSSH client configuration (admin computer)
[source%unbreakable,text]
----
Host mario_server
  HostName console.example.com
  User your-username
----

(((provision)))
Test it by running `ssh mario_client`.
If that works, run `provision.sh` again.

IMPORTANT: mario not only encourages you to use public key authentication for remote SSH connections, it forcibly disables password-based SSH authentication on its first run.
If you want to be able to log in remotely with a password, delete the related task from `roles/base/tasks/main.yml`.
If you already successfully ran mario once and want to re-enable password-based SSH auth, delete that task _and_ delete the file `/etc/ssh/sshd_config.d/disable-ssh-password-auth` on your server.

==== Plaintext password alternative

`hosts.yml` (created by `provision.sh`) includes a place for you to enter a plaintext password.
mario needs this prior to setting up passwordless sudo.

If you don't want to type the password into `hosts.yml`, comment out `ansible_become_password` and run this (after following all other instructions in `provision.sh`):

.one-time manual Ansible run (admin computer)
[source%unbreakable,bash]
----
source config
ansible-playbook --ask-become-pass playbook.yml
----

You should only have to do this once.
If it succeeds, you can go back to using `provision.sh`.

Another security improvement (left as an exercise for the reader) is to move secrets from `config` into an Ansible vault.

=== Provision complete

When mario is able to connect to the server and provision it successfully, `provision.sh` will produce output similar to this:

.output when mario is working (admin computer)
[source,text]
----
+ /usr/bin/ansible-playbook playbook.yml

PLAY [all] *********************************************************************

TASK [base : Configure apt cache] **********************************************
ok: [mario_server]

TASK [base : Install packages] *************************************************
changed: [mario_server]

... snip ...

PLAY RECAP *********************************************************************
mario_server               : ok=21   changed=0    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0
----

It takes around ten seconds for mine to complete.
All tasks will be `ok` in the recap for a fully provisioned system.
Some tasks will be `skipped` until Nextcloud is started for the first time--ignore those.

=== Start services

mario has prepared your server to run a handful of services.
Docker and ((Docker Compose)) are installed.
Docker configuration files are stored in directories under `/root/ops`.
Data for services are stored in directories under `/data`.

None of the services are running yet.
We'll soon get to how to turn them on and start using them.

Let's first take a step to save a lot of typing.
Services are started and stopped with Docker Compose, which is always run with `docker compose`.
When you run `docker compose`, you must first be in a folder containing a `compose.yml` file.
By convention, the name of that folder is the name of the service.
A typical usage pattern is:

.start a service in its folder (server)
[source%unbreakable,bash]
----
sudo su -
cd /root/ops/traefik
docker compose up -d
----

Try to avoid this method.
The fewer commands you run directly as `root`, the better.
I recommend this instead:

.start a service, explicit configuration file (server)
[source,bash]
----
sudo docker compose --file /root/ops/traefik/compose.yml up -d
----

mario installs a program called `dc` to save you some typing:

.start a service with dc (server)
[source%unbreakable,bash]
----
# equivalent to
# sudo docker compose --file /root/ops/traefik/compose.yml up -d
dc traefik up -d
----

TIP: sudo is required to run some commands, including `docker compose`.
The `dc` script will run `sudo` for you.

==== Start reverse proxy

Stand up the ((reverse proxy)) first.
Connect to your server and start ((Traefik)) with `dc traefik up -d`.
If that worked, wait a minute or two and visit `\https://traefik.example.com` in a web browser.
While you are waiting, tail the logs with `dc traefik logs -f`.

It may take that minute or two for ((Traefik)) to set up ((Let's Encrypt)) ((HTTPS)) encryption certs, so don't worry if you get invalid cert warnings at first.
You should see something like this for a working ((Traefik)) service:

// line numbers make it easier to read these very long lines

.typical Traefik logs (server)
[source%linenums,text]
----
Attaching to traefik_reverse-proxy_1
reverse-proxy_1  | time="2023-05-09T18:53:41Z" level=info msg="Configuration loaded from flags."
reverse-proxy_1  | time="2023-05-09T18:53:41Z" level=info msg="Traefik version 2.10.1 built on 2023-04-27T14:52:35Z"
reverse-proxy_1  | time="2023-05-09T18:53:41Z" level=info msg="\nStats collection is disabled.\nHelp us improve Traefik by turning this feature on :)\nMore details on: https://doc.traefik.io/traefik/contributing/data-collection/\n"
reverse-proxy_1  | time="2023-05-09T18:53:41Z" level=info msg="Starting provider aggregator aggregator.ProviderAggregator"
reverse-proxy_1  | time="2023-05-09T18:53:41Z" level=info msg="Starting provider *traefik.Provider"
reverse-proxy_1  | time="2023-05-09T18:53:41Z" level=info msg="Starting provider *docker.Provider"
reverse-proxy_1  | time="2023-05-09T18:53:41Z" level=info msg="Starting provider *acme.ChallengeTLSALPN"
reverse-proxy_1  | time="2023-05-09T18:53:41Z" level=info msg="Starting provider *acme.Provider"
reverse-proxy_1  | time="2023-05-09T18:53:41Z" level=info msg="Testing certificate renew..." ACME CA="https://acme-v02.api.letsencrypt.org/directory" providerName=myresolver.acme
----

If you waited and are still getting invalid cert warnings from your browser when you visit `\https://traefik.example.com`, read the Traefik log messages carefully and also see <<Encryption certificates>> for troubleshooting steps.

==== Start other services

Starting a mario service is always done with `dc SERVICE up -d`, just like we did with Traefik.
To stand up everything at once, you could use this shell script:

.start all services ad-hoc Bash script (server)
[source%unbreakable,bash]
----
for service in $(sudo ls /root/ops); do
    dc $service up -d
done
----

This will also pull and build images and update containers as necessary.
Services out of sync with their `compose.yml` file will be restarted.
This is idempotent: running and up-to-date services are left unchanged.

=== Encryption certificates

((Traefik)) will automatically install ((Let's Encrypt)) certs to encrypt HTTP traffic.
The certs are issued using a https://doc.traefik.io/traefik/https/acme/#dnschallenge[DNS challenge].
This way to https://letsencrypt.org/docs/challenge-types/[authenticate a cert request] is especially handy for servers with zero public-facing inbound ports, allowing convenient HTTPS even within closed LANs.
The ((DNS)) challenge is configured using labels in Traefik's `compose.yml` configuration file.

Traefik can accept ((HTTPS)), decrypt it, and pass along unencrypted HTTP to web services.
This is called ((SSL termination)), and is indicated by lines in Traefik's `compose.yml` mentioning `acme`.

(((router, network device)))
Take a look at a `compose.yml` file for any service included with mario.
Every service has a `tls` section defined on its router to enable HTTPS encryption and SSL termination.

If you see cert warnings while trying to reach your web services, first examine Traefik logs as indicated in <<Start reverse proxy>>.
To increase the Traefik log verbosity, change `--log.level=INFO` to `--log.level=DEBUG` in Traefik's `compose.yml`, re-provision, and re-start Traefik.
Next, confirm DNS queries are succeeding since the DNS challenge requires it.

.example DNS tests
[source,bash]
----
####
# Try these commands on both the admin computer and server.
# Replace dig (and its arguments) with your favorite DNS tool.
# Replace traefik.example.com with your Traefik service name.
####

# Look up Traefik on default DNS server.
# Should quickly return a LAN private IP address.
dig traefik.example.com

# Look up Traefik server name on Quad9 DNS.
# - @9.9.9.9 forces Quad9's DNS service.
# - +short uses terse output
# Should return nothing--we didn't set an IP address.
dig @9.9.9.9 +short traefik.example.com

# Fetch TXT record for Traefik.
# Contains a long unique string while Traefik is executing a
# DNS challenge and is otherwise not set.
dig traefik.example.com TXT
----

=== Tiny test service

Standing up a test service is easy.
Let's give this a shot.
A test service is useful to confirm networking is functional for Docker containers running on your host.

This service demonstrates pinging a public server.
On _your_ server, create the folder `~/ping/`.
Create a file `compose.yml` in that folder, containing:

.tiny test service config
[source%unbreakable,yaml]
----
version: '3'

services:
  test:
    image: alpine
    command: ping example.com
----

In the folder `~/ping/`, run the command `sudo docker compose up`.
Hit kbd:[Ctrl+c] after a few seconds.
You should see something like this:

.start tiny test service (server)
[source%unbreakable,text]
-----
$ cd ~/ping/
$ sudo docker compose up
Creating network "ping_default" with the default driver
Creating ping_test_1 ... done
Attaching to ping_test_1
test_1  | PING example.com (93.184.216.34): 56 data bytes
test_1  | 64 bytes from 93.184.216.34: seq=0 ttl=55 time=3.477 ms
test_1  | 64 bytes from 93.184.216.34: seq=1 ttl=55 time=3.236 ms
test_1  | 64 bytes from 93.184.216.34: seq=2 ttl=55 time=3.363 ms
^CGracefully stopping... (press Ctrl+C again to force)
Stopping ping_test_1   ... done
-----

[%unbreakable]
TIP: For extra credit, incorporate your tiny test service into mario.

This is the basis for adding more interesting services, too.
It's only a few more lines of code and configuration to create a small ((API)) or web service and a few more to publish it with your ((reverse proxy)).

== Services

Let's dive into the details of self-hosting a handful of useful services.
Each service has a "`Setup`" section explaining how to start it.

The services I'll highlight are a tiny fraction of those available to self-host.
They reflect my users`' preferences (including and over-indexed to my own) in reading, sharing, media, and so on.
Getting them running will provide some useful functionality and a good starting point.
With the help of mario your cloud gets these out of the box and will be flexible enough to accommodate your preferred service choices.

These particular services--while all reasonable choices to make your data useful--may not be the best available choices nor the best fits for your use case.
That is absolutely fine!
Plan to add and remove services as desired and as time passes.

If I link to a bug that is closed in an issue tracker, it's because I have tested and, at the time of writing, I'm still experiencing the bug in an official/supported release that is supposed to have the fix.

(((router, Traefik)))
Note that mario blocks ((WAN access)) by default.
Read <<Digital security>> to decide if you want this or not.
You may remove this protection by removing the `lan-only` ((middleware)) from the corresponding router's ((Traefik)) label.
For example, to allow WAN access to Nextcloud, make this change in Traefik's `compose.yml`:

.patch for WAN access to Nextcloud (admin computer)
[source%unbreakable,diff]
----
- traefik.http.routers.nc-https.middlewares=nc-head,nc-redir,lan-only
+ traefik.http.routers.nc-https.middlewares=nc-head,nc-redir
----

Similarly for Jellyfin, you may delete the whole line referencing the `lan-only` ((middleware)) in Jellyfin's `compose.yml` if you decide to expose that service on your WAN.

=== Nextcloud

(((Nextcloud, overview)))
Nextcloud is primarily a cloud "`drive`" for file storage and sharing.
It is daunting to self-host.
With ((mario)), it is of course easy and fun.
Done well, it serves as a solid foothold for de-Googling.
Nextcloud can be self-hosted for free when installed via mario.

==== Basic install

(((Nextcloud, install)))
A basic (default, un-customized) Nextcloud install provides remote file storage, organization, and sharing.
It keeps track of actual files and folders stored somewhere (local, remote, cloud, wherever) and tracks additional ((metadata)) about those files and folders in a database.
You access it via a web browser and there is a desktop client to sync files locally, similar to Dropbox, Google Drive, and OneDrive.

I've come to _really_ trust desktop file sync.
If I see a check mark on my desktop app, I know everything is properly synchronized with the server.
I am constantly creating and editing content locally and counting on sync to work (usually on my desktop computer), or creating and editing directly in Nextcloud via the web UI.

There are also apps for ((mobile)) devices.
I'll come back to mobile later in the following sections.

==== Object storage

Nextcloud is able to use ((object storage)) for primary data storage.
This is an advanced topic left as an exercise to the reader.
I'll assume primary storage on a local ((HDD)) set up by mario.

==== Security

(((Nextcloud, security)))
A basic Nextcloud install appears to have excellent security.
The source is in heavy use and is backed by a solid company with a reputation that depends on their commitment to security.
They make it easy to lock down and vet (it is FOSS after all).
The defaults appear secure.
They follow best practices.
They have a public bounty program and threat model.

==== Setup

(((Nextcloud, install)))
Setting up a new Nextcloud server is well documented.
In brief:

. Provision with mario.
. Start Nextcloud containers with `dc nextcloud up -d`.
. Navigate to `\https://cloud.example.com`
. Follow the web-based setup page to create an admin account.
. Skip installing recommended apps.

Done.
You should be redirected to the dashboard and a short intro video.

Some tips:

. To confirm reproducibility of your Nextcloud server, destroy and re-create it (before you use it for real).
.. After you get it working once, stop it with `dc nextcloud down`.
.. Destroy all persistent data with `sudo rm -rf /data/nextcloud`.
That _really_ deletes everything.
.. Re-provision with mario (run `provision.sh` again).
.. Follow the setup steps again.
. Read the official docs at `/settings/help` or https://docs.nextcloud.com.
. Add apps at `/settings/apps`.
See <<Customization>> for tips on how to roll out apps thoughtfully and which ones are worth your time.
. Test configuring a mail server and sending an email at `/settings/admin` (Basic settings).
. Add users at `/settings/users`.
. Check logs for all containers related to Netcloud with `dc nextcloud logs -f`.
. Check Nextcloud internal logs at `/settings/admin/logging` in the web UI or `/data/nextcloud/root/data/nextcloud.log` on the server.
. Review "`Security & setup warnings`" at `/settings/admin/overview`.
.. You can ignore Could not check for JavaScript support. Please check manually if your webserver serves `.mjs` files using the JavaScript MIME type..
This warning appears to be caused by DNS issues but shouldn't break anything.
.. If you see a warning about an error in the logs and that error is **NotPermittedException** "`Could not create folder "/appdata_NNN/theming/global"`", just ignore it.
This appears to be a harmless install-time issue.
. Some ((maintenance)) requires the `occ` tool (short for "`ownCloud command`").
.. Run it with `sudo docker exec --interactive --user www-data nextcloud_app_1 php occ`.
. Add `/data/video` as an External storage.
Media files uploaded there will automatically appear in ((Jellyfin)).
First, visit `/settings/apps/featured` and install the "`External storage support`" app.
Next, visit `/settings/admin/externalstorages` and install the "`External storage support`" app.
.. Folder name: Video
.. External storage: Local
.. Authentication: None
.. Configuration: `/data/video`
.. Set users, previews, sharing, and remaining options as desired.
. Add `/data/music` as an External storage, similar to `/data/video`.

==== Maintenance notes

* upgrades
** choose a release tag at https://hub.docker.com/_/nextcloud/
** change the version number in `roles/services/templates/ops/nextcloud/compose.yml`
** re-provision from ((admin computer))
** replace containers on the host with `dc nextcloud up -d`
* visit `/settings/admin/overview`
** perform any recommended ((maintenance)) on that page
** ignore the Update section, it may disagree with Docker Hub
* tail logs
** https://lnav.org[lnav] is helpful for this

The `stable` release tag will likely be stable enough for you and your users.
This generally corresponds to the previous version listed at https://docs.nextcloud.com/.

You may opt to use a more specific tag such as `27.1.5-apache`.
This gives you the chance to review and test each upgrade.

NOTE: Nextcloud's blog posts and marketing materials use different version names than the release versions from source control.
"`Hub 6`" on the blog refers to versions `27.\_._` in source control, "`Hub 7`" to `28.\_._`, and so on.

===== Release cadence

(((Nextcloud, release cadence)))
https://docs.nextcloud.com/server/stable/admin_manual/release_schedule.html[A major release is shipped every four months].
Most Nextcloud app developers are able to keep up with this pace.
Be sure to check your `/settings/admin/overview` page before upgrading to make sure all the apps you use will work with the version you're upgrading to.
You can override an out-of-date app with the "`enable untested app`" option under `/settings/apps`.
Sometimes this works.

Four months seemed to me like a short window for major releases, so I started a https://help.nextcloud.com/t/major-release-cadence/161685[thread about it].

==== Performance

If you use mario to deploy Nextcloud, you'll start with a nominally performant server.
I've built the most important steps from their https://docs.nextcloud.com/server/stable/admin_manual/installation/server_tuning.html[server tuning guide] into mario.

Troubleshooting performance issues can be challenging.
An https://github.com/nextcloud/server/issues/35311[issue about mounts] had me under the hood with ((MariaDB)) for a while.
They've since https://github.com/nextcloud/server/pull/33540[fixed the root cause] so it isn't a problem for new installations.

==== Customization

(((Nextcloud, apps)))
Nextcloud can be used as-is (see <<Basic install>>) or heavily customized.
The simplest and safest way to customize is by installing an app from the built-in app store, especially if an app is marked "`featured`".
These _Nextcloud apps_ are installed on the server, expanding the functionality of a base Nextcloud instance.

Here are some Nextcloud apps I've tried, what they do, and a ruling on whether they're worth looking into.
Read "`Worth your time?`" as "`Adam maybe tried this app and has shared his opinion whether others will find this particular app worth the effort to learn and maintain, based on his own experiences projected onto our possibly different use cases.`"
Grain of salt, in other words.
When in doubt, start small (default Nextcloud install), and roll these out thoughtfully if you do at all.

[cols="1,1,2"]
|===
|Nextcloud App |Purpose |Worth your time?

|Antivirus for files |virus scan uploads |*Yes*. Note: uploads from desktop clients are not scanned for viruses (https://github.com/nextcloud/files_antivirus/issues/219)
|Analytics |track and graph metrics |*Yes*. Only for small/simple use cases though.
|Appointments |easy 3rd party scheduling |*Yes*. Requires careful calendar curation. Somewhat fiddly setup.
|Calendar |manage meetings and appointments |*Yes*.
|Circles |arbitrarily group users |*No opinion*. I don't have enough users to justify this.
|Collectives |wiki or knowledge base |*Maybe*. Looks like a useful way to organize a set of related documents. Requires Circles.
|Cookbook |recipe manager |*Yes*. Great at importing from web pages (thanks to standardized recipe data already present in HTML source). I wish it were better at printing/exporting though.
|Contacts |address book |*Yes*.
|Dashboard |various widgets on a page |*No*. I like to go right to my files.
|Deck |kanban board |*No opinion*. I tried it a little and it worked, I just don't use kanban much.
|Draw.io |diagram editor |*Yes*.
|Duplicate Finder |find and cull duplicate files |*No*. Slow and opaque. I recommend https://github.com/pauldreik/rdfind[rdfind] instead.
|Electronic Signatures |e-sign documents |*No*. Requires a 3rd party service. It should work locally and just help folks fill in documents with signatures, dates, text, etc.
|End-to-End Encryption |encrypt files server-side, decrypt with client |*No*. Unnervingly buggy. Confusing UI/UX.
|Files |file management, sharing |*Yes*, although the "`Versions`" tab is not very useful.
|Forms |Google Forms alternative |*Yes*.
|Full text search |search through all documents |*Maybe*. Fast. Buggy. Likely dormant project.
|Holiday Calendars |easily add public holiday calendars |*Yes*. The configuration for this app shows up under "`Personal`" -> "`Availability`" for me, not "`Groupware`" (although the URL path is `/settings/user/groupware`).
|Maps |maps and directions |*Yes*. Grab a cup of tea if you have lots of photos with GPS coordinate ((metadata)).
|Mail |email |*No opinion*. I tried it briefly and it choked on my bazillion Gmail messages. And yes, I do want to de-Gmail someday.
|Memories |photos |*Yes*.
|News |track blogs and news via rss/atom feeds |*Yes*.
|Nextcloud Office |edit spreadsheets, slides, etc. |*Yes*. I don't love this but I need it. Maybe that's a "`No`"? Mobile apps for this are painful.
|Notes |simple markdown-based note taking |*Yes*. There's an excellent companion mobile app. Replaced Google Notes for me.
|Passwords |password manager |*Yes*. Warning: online only (requires connection to Nextcloud server).
|PhoneTrack |location sharing and tracking |*Yes*. UI is feature-rich and complicated. Traveled movement lines are cool.
|Photos |photos, sorta |*No*. Slow, clumsy, lacking features compared with other FOSS photo management software. Note that it is required by Memories. I do install it just so I can use Memories.
|Polls |simple polls |*Yes*.
|Ransomware protection |warns for bad file names on upload |*No*. Too many false positives. Unmaintained.
|Recognize |face recognition |*No*.
|Suspicious login |warn about suspicious IPs |*No*. Too many false positives.
|Tasks |tasks/todos |*Yes*.
|Tables |tabular data entry and API |*No*. Not yet, although keep an eye on this as a potentially powerful and useful ((low-code)) platform.
|Talk |video and text chat |*No*. Works, just not as well as other video and text chat services/apps. I do use it for my chicken safety system and I see it improving a lot with each release. For now I recommend https://signal.org[Signal] instead.
|Temporary files lock |avoid edit conflicts |*Yes*.
|Text |edit text documents |*Yes*. I'm a huge fan of Markdown plain text documents, and Nextcloud handles these well. It has a nice web-based collaborative editor. I like pasting in rich text and letting the editor auto-convert it to Markdown.
|Video converter |transcode videos |*No*. Cool idea but the project appears dormant.
|===

==== Talk High Performance Backend

(((Nextcloud, Talk)))
I haven't yet tried Talk with the https://nextcloud-talk.readthedocs.io/en/latest/scalability/[High Performance Backend] because I don't have dozens of users.
The AIO installer includes the https://github.com/strukturag/nextcloud-spreed-signaling[strukturag/nextcloud-spreed-signaling implementation], which is likely to be the "`official`" one (I don't know for sure).
See also: <<AIO installer>>.

==== Full text search

(((Nextcloud, search)))
This app allows you to search through all content of all documents on your server.
The search syntax is hard to get right.
It https://github.com/nextcloud/fulltextsearch/issues/601[uses a lot of CPU] and is memory-hungry too.

The GitHub project repositories are pretty quiet. See:

* https://github.com/nextcloud/fulltextsearch/pulse
* https://github.com/nextcloud/files_fulltextsearch/pulse
* https://github.com/nextcloud/fulltextsearch_elasticsearch/pulse

==== Mobile

(((Nextcloud, mobile)))
Nextcloud works OK as the backend for a mobile device.
It can be your single reliable ((source of truth)) for contacts, calendars, tasks, and most everything else that matters on mobile.
You can open files and edit them, but the UI/UX is bad.
See <<Mobile text editing is hard>> for a couple workarounds.

I had a https://murena.com[Murena Samsung S9+ phone] running /e/ ((OS)) for a while.
I loved it.
Easy to set up with Nextcloud and worked quite well.
Unfortunately, T-Mobile started requiring VoLTE so I had to switch back to Samsung's Android because /e/ OS does not support VoLTE on that phone.

(((FOSS)))
Murena rescued me in 2023 when they started shipping the Fairphone 4 to the USA. /e/ OS is up to date with the latest upstream Android code and once again provides a good deal more FOSS-friendliness, privacy, and native Nextcloud integration than other Android-based mobile operating systems.
Works with T-Mobile USA 5G, VoLTE, and Wi-Fi calling. 5 years of support.

==== Other mobile apps

Besides the primary mobile app (called simply "`Nextcloud`"), there are other mobile apps made to work with Nextcloud apps.
Here are the ones I recommend.
I don't have an iPhone so these are only Android apps.

[cols="1,1,2"]
|===
|Mobile app |Works with Nextcloud apps |More info

|DAVx5 |Calendar, Contacts, Tasks |https://davx5.com
|Maps Geofavorites |Maps |https://github.com/penguin86/nextcloud-maps-client
|NC Passwords |Passwords |https://gitlab.com/joleaf/nc-passwords-app
|Nextcloud Cookbook |Cookbook |https://github.com/nextcloud/cookbook
|Notes |Files, Notes, Text |https://github.com/nextcloud/notes-android
|OpenTasks |Tasks |https://github.com/dmfs/opentasks
|Nextcloud Talk |Talk |https://apps.nextcloud.com/apps/spreed
|===

Android devices usually ship with ((groupware)) (calendar and contacts) apps, or you can install your favorite ones.
DAVx5 handles synchronization of groupware data to and from your device.
DAVx5 is only necessary on Android, perhaps because iOS has better native WebDAV support.
DAVx5 is not needed on Murena phones (/e/ OS).

There are actually two Cookbook apps.
Either works fine for me.
I'm not picky, I just need to see the ingredients and directions.
Looks like the one by "`Teifun2`" is more popular.

Maps Geofavorites lets you easily save arbitrary GPS coordinates to the Maps Nextcloud app.
Handy for remembering where you parked your bike, for example.

Notes looks best configured in Grid View.

Talk... despite my own advice, I find myself using Talk anyway.
I like having my own chat server, I guess.
I am listing it here because I do actually use it, and to complain that https://github.com/nextcloud/talk-android/issues/217[I can't read messages offline].
It is also under heavy development and improving lots with every release.

These are just a few examples.
Since you've got all your data and Nextcloud always uses open formats, you can ride the wave of improvements and enjoy what works best.
For example, I just started using https://github.com/jonasoreland/runnerup[RunnerUp].
When I save my tracks in Nextcloud, they automatically show up in Maps.
Nice!

==== Nextcloud vs. ownCloud

At first glance it's a bit difficult to tell the difference between Nextcloud and ((ownCloud)).
This follows since ((Nextcloud)) started as a fork of ownCloud.

So why should you choose one over the other?
A healthy FOSS project is generally also an active project, so one way to guide your decision is by comparing activity metrics on GitHub.
See https://github.com/owncloud/core/pulse[owncloud/core activity] and https://github.com/nextcloud/server/pulse[nextcloud/server activity].
Based on those two sets of metrics it appears Nextcloud is thriving and ownCloud is dying.

Another interpretation is that ownCloud has a smaller and slower-moving core codebase.
More work is necessary to make a truly rigorous comparison.

See also: <<traits-of-good-services>> and <<traits-of-bad-services>> in <<Choose services>>.

==== Nextcloud Office

(((Nextcloud, Office)))
https://nextcloud.com/office/ gives some strong hints how the company behind Nextcloud wants us to think of "`office`" and their plans for it as a suite of related tools.
They clearly intend a holistic, integrated office experience, and Nextcloud can be configured to be used in this manner.
That page covers editing office documents (rich text and spreadsheets) collaboratively, along with uses for the Notes, Collectives, and Tables apps.
It provides some clever and useful workflow ideas.

Given that wide a scope, ((groupware)) should be part of "`office`" too, so instead let's for now focus specifically on collaborative editing of office documents.
Doing this within Nextcloud requires an https://apps.nextcloud.com/apps/richdocuments[app called Nextcloud Office] as well as a separate backend service.
Should you desire to add this functionality to your mario-provisioned server, either ((Collabora)) or ((ONLYOFFICE)) may serve as the backend for a ((mario)) server.
My strong preference is for Collabora, in line with <<Good for self-hosting>>; despite fewer stars on GitHub, it's clear Collabora development is flourishing while ONLYOFFICE is stagnant.

==== Bugs

===== Spinner on mobile

When you first open the Nextcloud ((mobile)) app, a loading spinner shows up in front of a cached view of whatever files and folders existed the last time you use the app.
If you ignore it and tap to navigate your way into a folder or open a file, you may end up tapping a different one than you intended because the folder order can change _as you are tapping the screen_.

Workarounds:

* wait until the spinner completes (usually takes me about one second)
* reduce chance of reordering with "`A - Z`" or "`Z - A`" sorting instead of "`Newest first`" or "`Oldest first`"

===== Mobile text editing is hard

(((Nextcloud, mobile)))
Nextcloud makes it easy to get to your stuff via ((mobile)) devices, but editing is a pain.

This is not a Nextcloud-only problem; I find _all_ mobile text entry and editing cumbersome.
This applies to email, plain text, Markdown, and office documents.

In Nextcloud-land, one workaround to improve plain and Markdown text entry is to use the https://github.com/nextcloud/notes-android[Notes app on Android] or https://github.com/nextcloud/notes-ios[iOS].
It has separate editing and viewing modes and more aggressive synchronization.
With Notes you have a better chance of up-to-date data and fewer conflicts.

Another workaround is to use https://github.com/gsantner/markor[Markor].
Install that app, then:

. In the Nextcloud mobile app, "`Download`" or "`Sync`" the file you wish to view or edit locally.
This caches a copy on your phone.
. In the Nextcloud mobile app, choose "`open with`" for the file.
Should open instantly.
. If you make changes to the file, save it, then manually "`Sync`" the file in the Nextcloud app.
It appears local changes like these never make it to the server otherwise.

See https://jenson.org/text/ for background on why mobile text editing is a complex and multifaceted problem.

===== Cumbersome mobile setup

To sync calendars, tasks, and contacts with your phone's storage of same, you need to install the 3rd party DAVx5 app.
I can't figure out why this is necessary (see: https://help.nextcloud.com/t/what-does-android-file-sync-do-for-a-nextcloud-account/154330).

Workarounds:

* use /e/ ((OS)): it includes native support for Nextcloud accounts
* buy a https://murena.com[Murena] phone: it uses /e/ OS

===== Spurious web text editor conflicts

Collaborating on plain text and Markdown text files sometimes results in spurious conflicts.
Editing is interrupted before it starts, and the web-based text file editor shows you two versions of the file side by side.
The left side is labeled "`Use current version`", and the right says "`Use the saved version`" (or equivalents for your locale or specific client).

Apparently the browser has a saved copy in local storage or something that gets loaded first and considers it the "`current`" version.
Then it loads the one on the right and calls it the "`saved`" version, and if they differ you get to choose.

Workaround: pick the one on the right.
That's the latest and greatest copy as it exists server-side.

Why the... never mind, just pick the one on the right.
If you're curious and want to dig in deeper, follow these links:

* https://github.com/nextcloud/text/issues/2388[Shared text file is not up-to-date with saved file]
* https://github.com/nextcloud/text/issues/4078[Changing File from Desktop leads to conflict in browser, even if browser was not doing any changes]
* https://help.nextcloud.com/t/text-document-current-vs-saved-version/151600[Text: document current vs. saved version] (by yours truly)

Related desktop client bug: https://github.com/nextcloud/desktop/issues/2467[Nextcloud-Client creating conflicts when it should not].
Conflicts seem to appear in cases where there shouldn't be any.
Workarounds: wait 10 seconds or so between saves until the desktop client syncs and returns to idle (roll your eyes while you wait).
Also, check out the https://apps.nextcloud.com/apps/files_lock[Temporary files lock] app for semi-automated advisory locking (e.g. quickly communicate "`gimme a minute, I'm editing that Markdown text file`").

===== Draw signature in forms

Feature request.

Forms are handy for gathering simple minimally-structured data... surveys, RSVPs, stuff like that.
The data are just dumped into a spreadsheet.
With a signature field Forms could be used to add a drawn signature to a form like a contract or waiver.

There are extant Nextcloud online signature apps that incorporate https://en.wikipedia.org/wiki/Digital_signature[digital signatures].
I don't want or need digital signatures, especially since they appear to rely on 3rd party services.
I really just want a low-tech image that looks like a drawn signature at the bottom of a page.
It doesn't even need to be wet ink.
If you want that too, vote for or help with https://github.com/nextcloud/forms/issues/947.

https://github.com/OpenSignLabs/OpenSign[OpenSign] and https://github.com/docusealco/docuseal[DocuSeal] are two alternative FOSS self-hostable apps supporting drawn signatures.

===== Release script missing from source

Nextcloud is ((FOSS)), although https://help.nextcloud.com/t/build-bzip-and-package-from-git/58341[some release scripts are held back].
They may or may not be required to release those, I don't know.
I hope they do decide to release them, for the same reasons the rest of Nextcloud is FOSS.

===== Spurious event updated notifications

The Calendar app is quite useful and perhaps the most heavily used by me and my users.
I have grown to expect one particular erroneous "`event updated`" notifications, possibly caused by calendar client/sync issues.

On one shared calendar (with many clients) I often get notifications that so-and-so "`updated event XYZ in calendar ABC`", but the only actual thing that occurred is that one of the clients just sync'd (or perhaps made some innocuous change to an event) and https://github.com/nextcloud/calendar/issues/5879[Nextcloud thinks it was a meaningful update].
At least, I think that's what's happening... some changes (like changing the event's date) do show up with the old and new values made explicit.
As an aside, I do like this "`explicit diff`" behavior showing the exact changes made to an event's Title, Time, Location, or Description.

==== End-to-End Encryption

It's a good idea to have End-to-End encrypted folders.
There's a Nextcloud app for this and I recommend you avoid it.

It seems close to working, but it feels like early-release software.
The UI/UX is confusing, and I ran into a dealbreaker bug that left files decrypted server-side.
Furthermore...

* https://help.nextcloud.com/t/how-to-setup-e2e-encryption-for-shared-folders/165610[Sharing] https://help.nextcloud.com/t/e2ee-and-file-sharing/145547[doesn't] https://github.com/nextcloud/end_to_end_encryption/issues/520[work].
* https://github.com/nextcloud/end_to_end_encryption/issues/82[There's no web client].
* https://github.com/nextcloud/end_to_end_encryption/issues/285[The roadmap is unclear].
* https://github.com/nextcloud/end_to_end_encryption/issues/8[Keys are always stored on the server] (these are thankfully stored encrypted).

I'd say (more than with other apps) review https://github.com/nextcloud/end_to_end_encryption/issues[known issues], make sure you can live with all those, then test it out thoroughly using a throwaway/sandbox Nextcloud instance.
(((mobile)))
Make sure it works with all clients you plan to use it with (e.g. desktop, mobile).

==== AIO installer

(((Nextcloud, install)))
Among the myriad install methods, there's a relatively new and interesting AIO ("`all-in-one`") installer (https://nextcloud.com/all-in-one).
It's free for an instance with less than 100 users.

I recommend the mario method instead not to save money (although you might), rather, to be able to have the same flexible and empowering experience you get with all services managed by mario.

See the https://github.com/nextcloud/all-in-one[AIO readme] for more information.

=== Jellyfin

(((Jellyfin, overview)))
https://jellyfin.org[Jellyfin] is a personal streaming media server.
mario will set up a basic Jellyfin server.

I like mounting local media folders using Nextcloud "`external storages`", then I can use Nextcloud to manage the actual movie and music files and Jellyfin to stream them.
Jellyfin only needs read access to these persistent data, it stores ((metadata)) elsewhere.
There's one example of a shared persistent data location in the Nextcloud `compose.yml` file.
Under `volumes`, you'll find `/data/jellyfin/media/tmp-video:/data/tmp-video:rw`.

==== Setup

. Provision with mario.
. Start Jellyfin with `dc jellyfin up -d`.
. Navigate to `\https://jellyfin.example.com`
. Follow web-based setup steps.
Try adding two media libraries using the folders shared with Nextcloud.
.. Choose content type "`Movies`", click the "`+`" icon next to "`Folders`", and choose `/data/video`.
.. Choose content type "`Music`", click the "`+`" icon next to "`Folders`", and choose `/data/video`.

(((Jellyfin, advanced)))
(((GPU)))
If you have a GPU, look into https://jellyfin.org/docs/general/administration/hardware-acceleration/[hardware acceleration].
This is useful if videos can't be played directly by a client and need to be transcoded on the fly.
Jellyfin can transcode using only CPU, but it is way faster with a GPU.

[%unbreakable]
TIP: Some CPUs include special facilities for accelerated transcoding.
Jellyfin can take advantage of Intel Quick Sync Video.

==== Maintenance notes

* upgrades
** change the version number in `roles/services/templates/ops/jellyfin/compose.yml`
** re-provision from ((admin computer))
** replace containers on the host with `dc jellyfin up -d`

==== Bugs

===== Share playlists

Feature request.

* https://github.com/jellyfin/jellyfin/issues/6264#issuecomment-1338518980[Playlists are private by design].
* https://features.jellyfin.org/posts/173/share-playlists[I'd like the ability to share them].

===== Clips

Feature request.

I often want to share, hear, or re-watch a specific part of some media.
I think it would be just so cool to be able to https://features.jellyfin.org/posts/1036/bookmark-audio-video-segments[create clips] without actually creating new media files.

===== Offline mobile media

Feature request.

I want the ((mobile)) app to auto-cache media and https://features.jellyfin.org/posts/218/support-offline-mode-on-android-mobile[allow playing while offline].

Workaround: there are two separate mobile apps that can download and cache media for offline playing.
https://github.com/jmshrv/finamp[Finamp] for music, and https://github.com/jarnedemeulemeester/findroid[Findroid] for video.

=== Wallabag

(((Wallabag)))
https://wallabag.org[Wallabag] saves articles for distraction-free offline reading.

==== Setup

. Provision with mario.
. Start Wallabag with `dc wallabag up -d`.
. Navigate to `\https://wallabag.example.com`
. Log in as `wallabag` user with password `wallabag`.
. Update password for `wallabag` user.

==== Maintenance notes

* upgrades
** change the version number in `roles/services/templates/ops/wallabag/compose.yml`
** re-provision from ((admin computer))
** replace containers on the host with `dc wallabag up -d`
** if you run into any issues, try manually applying database upgrades (see <<Upgrades break everything>>)

==== Bugs

===== Upgrades break everything

https://github.com/wallabag/wallabag/issues/6649[Database migrations are not (always?) automatically applied].
There may be other duplicate or related bug reports for this same thing, that's just one example.
Luckily, there's an https://github.com/wallabag/docker#upgrading[easy workaround].

Apply the workaround to a mario system with:

.force Wallabag database migration (server)
[source%unbreakable,bash]
----
dc wallabag exec app /var/www/wallabag/bin/console \
  doctrine:migrations:migrate --env=prod --no-interaction
----

The `exec` command says we want to run something in a container.
This runs the `console` utility in the `app` service container.
The second line indicates necessary database migrations (schema and data updates) should be run using `prod` settings, without interactive prompts.

This is ((idempotent)), as database migrations should be.
After the first run, subsequent runs output: `[OK] Already at the latest version`.

It's unclear why thes migration is not automatically performed during an upgrade.
Perhaps it is only necessary in special cases--I've only had to do it twice in a few years.

===== Share with other users

Feature request.

I want to be able to https://github.com/wallabag/wallabag/issues/679[share content with other Wallabag users, within Wallabag].

=== Watchtower

((Watchtower)) is handy for keeping your Docker containers up to date.
It will discover and check outdated containers, pull new images, and restart services to create new containers.

It https://github.com/containrrr/watchtower/issues/90[does not automatically roll back if a container upgrade fails].
Granted, this would be challenging to implement.
A service might only have one-way database migrations, for example.
I think the Watchtower maintainers made the right decision to omit automatic rollbacks (likely to keep Watchtower simple).

You may experience an issue where a service is broken by Watchtower.
If you suspect this is the case and you know when the service started breaking, try to correlate that with any upgrades appearing in `dc watchtower logs`.
I avoid this by only using Watchtower for non-critical services.
I don't let Watchtower auto-upgrade my ((Nextcloud)) service, for example.

==== Setup

. Provision with mario.
. Start Watchtower with `dc watchtower up -d`.

==== Maintenance notes

* upgrades
** change the version number in `roles/services/templates/ops/watchtower/compose.yml`
** re-provision from ((admin computer))
** replace containers on the host with `dc watchtower up -d`

=== Scratch

((Scratch)) is a popular and very approachable visual programming language geared towards interactive multimedia and learning.
I really enjoy using it without the "`community`" part: pure coding without sharing, studios, comments, stars, hearts, endless memes and games.
These often serve to redirect a user from creating to consuming.

Scratch doesn't require any persistent data, setup, nor auth.

==== Setup

. Provision with mario.
. Start Scratch with `dc scratch up -d`.
. Navigate to `\https://scratch.example.com`

==== Maintenance notes

* upgrades
** change the version number in `roles/services/templates/ops/scratch/custom/Dockerfile`
** re-provision from ((admin computer))
** re-build custom image with `dc scratch build --pull`
** replace containers on the host with `dc scratch up -d`

== What's next?

This is a jumble of ideas for future me and you.
These aren't covered in detail in this book and they aren't included in mario.

=== Learn more

If you like this book, and you want to learn and do more, do it.
Ride that wave of inspiration.
Seek both breadth and depth.

For breadth, look for a comprehensive book about Linux.
One of my first purchases when I wanted to just finally "`get`" Linux was _UNIX: The Complete Reference_, a thousand-page monster covering many, many concepts.
I studied it in chunks, referred to it often, and never read it cover to cover.
If I started learning again from scratch today, I'd still have a book like that handy while studying online resources and trying stuff at home.

For depth, immerse yourself in fundamentals.
Push past abstractions and make progress towards first principles.
Take a computer science class in an area supporting something else you want to do.
For example, if you want to code your own web services, take a class in programming for the web.
If you want to understand how source code makes a computer do things, take a class in compilers.

Work through this book in a class or small group.
See <<Discussion topics>> and <<Exercises>>.

Participate in ((FOSS)) communities to learn from and share with others.
Pass on what you've learned.
File a bug.
Post in a forum.
It's fun!

(((SeaGL)))
Conferences like https://seagl.org[SeaGL] bring together bright minds on many topics, including self-hosting.
If you've done something cool, share it!

=== Use GPUs

(((GPU)))
A GPU offers more efficient video transcoding with Jellyfin, reducing server CPU usage and speeding up remote video streaming.

A FOSS voice assistant would benefit from a GPU.

A GPU could also speed up video transcoding and facial recognition.

Modern generative AI workloads like large language model chat and image generation are much faster with a GPU.

=== AI

(((AI)))
AI is once again the latest hotness.
You can run your own image generators and LLMs (large-language models) at home.
No GPU is required.
Here's a `compose.yml` that'll work with mario to stand up https://localai.io[LocalAI].

.example LocalAI service config
[source,yaml]
----
version: '3.6'

services:
  api:
    image: quay.io/go-skynet/local-ai:latest
    environment:
      MODELS_PATH: /models
    volumes:
      - /data/localai/models:/models:cached
    command: ["/usr/bin/local-ai" ]
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.localai-https.entrypoints=websecure"
      - "traefik.http.routers.localai-https.rule=Host(`localai.example.com`)"
      - "traefik.http.routers.localai-https.tls.certresolver=myresolver"
      - "traefik.http.routers.localai-https.middlewares=lan-only"
    networks:
      - traefik_default
    restart: unless-stopped
networks:
  traefik_default:
    external: true
----

Note the middleware to only allow traffic from your ((LAN)).
This assumes your LAN uses 192.168.1.* addresses, and expects a corresponding label on the ((Traefik)) container to set up the ((middleware)), for example:

.label from Traefik configuration allowing only LAN access
[source,yaml]
----
"traefik.http.middlewares.lan-only.ipallowlist.sourcerange=192.168.1.0/24"
----

TIP: For extra credit, incorporate your LocalAI service into mario.

See the https://localai.io[LocalAI documentation] for further setup help.
Once you get that running, you can use the https://apps.nextcloud.com/apps/integration_openai[Nextcloud AI integration app] as a convenient frontend.

=== Pi-hole

(((Pi-hole)))
Running a https://pi-hole.net[Pi-hole] service in your ((LAN)) helps block advertisements, trackers, and bad actors using ((DNS)) block lists.

(((router, network device)))
Clients (laptops, phones, etc) on your network use the Pi-hole as their DNS server, generally as part of DHCP (Dynamic Host Configuration Protocol) auto-configuration by your router or Pi-hole itself (if you use Pi-hole as your DHCP server).

The Pi-hole translates domain names to IP addresses.
If a domain name is on a block list, it returns a false IP address such as 0.0.0.0.

The technique is imperfect, yet simple and effective.

My Pi-hole server sits between my router's DNS server and all clients.

[#image-DNS-traffic-diagram]
.Pi-hole DNS traffic flow diagram.
image::DNS-traffic-diagram.svg[align="center",scaledwidth=80%]

(((router, network device)))
Queries for domain names not on any block list will be answered directly or sent upstream.
I set up my Pi-hole to pass queries on to my home router, which will then query a DNS server outside my ((LAN)) as necessary.

It's easy to block individual domain names or entire lists as you see fit.
I've used this as an "`impulse blocker`", helping the kids avoid distractions during remote school.

The Pi-Hole also has a list of local DNS entries.
I add a few domain names to this list for servers inside my ((LAN)).

Note that some clients will by default bypass an auto-configured DNS server such as Pi-hole.
(((DNS)))
(((HTTPS)))
For example, https://support.mozilla.org/kb/firefox-dns-over-https[DNS over HTTPS in Firefox].

=== Single sign-on

(((Single sign-on)))
It would be convenient for users to be able to log in once to get access to all self-hosted services using a common, consistent, and well-designed mechanism (single sign-on), and for sysadmins to be able to manage all users and groups in one place (centralized identity management).

https://goauthentik.io[Authentik] is one service providing this, and appears to have all the features I want (single sign-on, backend user database, integrates with everything I self-host).
I want to try it out and see it running well for a good while before adding it to mario.
Some of the other self-hosting solutions mentioned in <<Alternatives to this book>> do include FOSS central identity management.

== More resources

Visit https://selfhostbook.com for all supporting material including source code for this book and mario.

* https://selfhostbook.com/code/[Source code]
* https://selfhostbook.com/contact/[Contact info]

Patches and feedback are most welcome.
This book is just a part of something big and I'm glad you're a part of it too!

=== Support

Here are a few ideas for when you get stuck.

* Ask for help in forums and chats related to a product/project.
* If you're confident you've found a bug, file an issue with the product/project.
* Try your luck in semi-moderated public places.
Don't expect much from these, although you may get lucky from time to time.
** https://reddit.com/r/selfhosted/[self-hosted subreddit]
** https://reddit.com/r/homelab/[homelab subreddit]
** https://matrix.to/#/#selfhosted:matrix.org[#selfhosted chat]
* Hire me to help you out.

=== Alternatives to this book

There are one-click-install appliances with many ready-to-go apps.
(((FreedomBox)))
https://freedombox.org[FreedomBox] is one promising contender in this space.

There are shortcuts and frontends for self-hosting.
For example, https://openmediavault.org[openmediavault] looks like a cool way to build a ((DIY)) (do it yourself) ((NAS)) (network attached storage).

(((YunoHost)))
(((CasaOS)))
(((Runtipi)))
And there are countless more of these kinds of partial or full-service self-hosting solutions, such as:

https://yunohost.org[YunoHost]::
  Not considered, I prefer always using containers.
https://casaos.io[CasaOS]::
  New, interesting, very little documentation.
https://runtipi.io[Runtipi]::
  New, interesting, uses ((Docker Compose)) and ((Traefik)).

These look like great ideas, and it's hopeful (and overwhelming) to see many options in this space.
I evaluated them (and others) only enough to get the sense they didn't fit my wants and needs.
Like a crotchety old man I've since raised my bar to change and instead come up with a checklist I'll share for evaluating the next self-hosting solution.

.Checklist: Self-Hosting Solution Viability
[#solution-viability-checklist]
****
* [ ] Will it work for years with minimal tinkering?
* [ ] Is it easily extensible?
* [ ] Do I trust the maintainers?
* [ ] Does it employ technologies I'm familiar with?
* [ ] Does it weaken or strengthen security by changing my ((attack surface))?
* [ ] Does it add features/value I need/want, beyond what I'm already able to do?
* [ ] Will it help my users?
* [ ] Will it help me learn what I need/want to learn, and safely take care of the rest for me without my needing to learn more?
* [ ] Will it help me figure out why I made a change to one of my services two years ago?
* [ ] Does it phone home, using telemetry or my data in a way I don't approve?
* [ ] Does it hold back "`enterprise`" features I need, even for my scaled-down use case?
Is it annoying about this, reminding me often?
* [ ] If I want paid support, is it available?
* [ ] Is it popular?
Has it been around a while, and do I expect it to endure?
****

See also: <<traits-of-good-services>> and <<traits-of-bad-services>> in <<Choose services>>.

After brief reviews, I find existing self-hosting solutions generally:

* are new and immature
* lack proper documentation
* do too much: try to solve many problems without sufficient inertia/resources to maintain it all
* don't do enough: just another Linux distro with an added layer to discover and install apps
* make opinionated tech choices I don't agree with
* have a limited list of apps in their app stores and exclude the ones I want
* have too many apps in their app store, without good ways to compare quality, privacy, features
* are ((GUI)) (graphical user interface)-focused where I prefer working on a command line

Still, check `'em out.
They might work better for you if you don't need the level of power and control provided by this book.
By the time I publish, they (or some new contenders) might grow to overcome my approach.
Please let me know what you discover.
If I missed something, I'd love to learn about it!

(((Ansible)))
(((NAS)))
(((Clace)))
(((Cosmos Cloud)))
(((DockSTARTer)))
(((HomelabOS)))
(((Start9)))
(((MicroCloud)))
(((LibreServer)))
(((LinuxServer.io)))
(((NextcloudPi)))
(((UBOS)))
Here are some more related and interesting self-hosting solutions worth researching further:

* https://github.com/davestephens/ansible-nas[Ansible NAS]
* https://clace.io[Clace]
* https://cosmos-cloud.io[Cosmos Cloud]
* https://dockstarter.com[DockSTARTer]
* https://homelabos.com[HomelabOS]
* https://start9.com[Start9]
* https://canonical.com/microcloud[MicroCloud]
* https://libreserver.org[LibreServer]
* https://www.linuxserver.io[LinuxServer.io]
* https://nextcloudpi.com[NextcloudPi]
* https://ubos.net[UBOS]

== Discussion topics

Here are some conversation starters for a class or small group.

. What services do _you_ run?
Why?
For whom?
. What are some considerations when choosing between public cloud and on-premise self-hosting?
. Compare and contrast different options for bare metal self-hosting hardware in terms of setup cost, power usage, and expandability.
. Why does the author encrypt all network traffic, even in a closed LAN?
. Review this book for poor security practices.
How might it be improved?
. Why is privacy important, especially with digital information?
. What's the best part about self-hosting?
. What are some pitfalls of self-hosting?
. What is the future of self-hosting?
. What is the ideal number of users to support with a single self-hosted server?
. How might this book be adapted for:
.. intermittent power
.. intermittent network
.. local-only network
.. clustered hardware
. Consider ((FOSS)) with respect to human attention and focus.
Contrast with non-FOSS.
. What approaches in this book may be conceptually dangerous or misleading?
Why?
How could they be improved?
. Summarize this book in one sentence.

== Exercises

Exercises for individual practice and study groups.

. Stand up a service besides those included with mario using an existing image.
For example, a https://awesome-selfhosted.net/tags/personal-dashboards.html[dashboard].
. Build a custom image.
Hint: use `docker build` or https://buildah.io[Buildah].
. Run a container using your custom image.
. Create a service (using your container) to know if it is time to reboot your server.
Hint: check if `/host/var/run/reboot-required` exists.
. Stand up a second Nextcloud service for experiments.
Use it to test out the latest release or a custom app.
. Try Nextcloud with ((object storage)) for primary storage.
. Adapt this guide to a ((Linux)) distribution besides Ubuntu.
. Help resolve a bug mentioned in this book.
. Set up periodic automatic offsite backups.
. Add a GPU to your server.
. Enable ((GPU)) transcoding in ((Jellyfin)).
. Sign the open letter at https://publiccode.eu[Public Money, Public Code] because software paid for with taxes should be FOSS.
. Aggregate logs.
. Monitor and/or block outbound network activity from containers.
. Pick a ((Docker)) container that doesn't require outbound network access.
Prevent it from making outbound connections and prove to yourself it works.
. What if the server won't boot?
.. Describe troubleshooting steps, in detail.
.. Make a plan for system recovery when it fails to boot.
. Set up https://en.wikipedia.org/wiki/Single_sign-on[single sign-on].
. Set up https://fail2ban.org[Fail2Ban].
Feed it logs from various services.
. Set up https://suricata.io[Suricata] network analysis and threat detection.
. Try running containers with https://podman.io[podman].
. Read up on other ways to isolate processes, e.g. FreeBSD jails and chroot.
. Contribute to ((mario)).
. Move secrets used by mario into an Ansible vault.
. Adapt mario to use ((podman)).
. Adapt mario to use https://kubernetes.io[Kubernetes].
. If you have a dynamic IP address, create or use an existing dynamic ((DNS)) update client container.
. Stand up a mail relay container such as https://github.com/crazy-max/docker-msmtpd or https://github.com/namshi/docker-smtp.
Allow all mario-managed services to send email through this relay.
. Stand up your own ((DNS)) server.
. Reorganize mario services into distinct Ansible roles.
Upload the roles to https://galaxy.ansible.com[Ansible Galaxy] as a playbook bundle.
. Modify mario to https://docs.docker.com/engine/security/userns-remap/[always run containers as unprivileged (non-root) users].
. Use appropriate ownership and permissions for persistent container data.
. Set up https://github.com/strukturag/nextcloud-spreed-signaling#running-with-docker[Nextcloud Talk high-performance backend].
. https://docs.docker.com/network/packet-filtering-firewalls/#docker-and-ufw[Uncomplicated Firewall and Docker do not get along well].
Work around this and share your solution with others.
. Try https://nixos.org[Nix and NixOS].
. Roll your own ((Linux)) distro.
. Build, configure and deploy an https://opnsense.org[OPNsense firewall].
. Set up your own https://headscale.net[headscale] VPN/tailnet for remote ((LAN)) access.
. Enable preview generation for ((Nextcloud)).
.. Research first: how does default preview generation work?
What file types are supported?
How much disk space is used?
How fast is it, subjectively and objectively?
What ((maintenance)) will it require once enabled?
.. Create a test bed with a clean install and many preview-able files of various file formats.
Write timing scripts for objective performance measurements.
Consider both client- and server-side.
Keep manual testing notes (subjective measurements).
.. Compare https://apps.nextcloud.com/apps/previewgenerator[Preview Generator], https://github.com/h2non/imaginary[Imaginary], and any other extant solutions.
.. Turn it on.
.. Evaluate the change.
Is it noticeable?
Does your timing script show any difference?
How much disk space is used for previews?
How challenging was this to enable?

The detailed steps in the last exercise suggest what may be required in general to achieve better outcomes.
I've omitted them from the other exercises for brevity.
Please apply similar detailed steps elsewhere as desired.

== More about FOSS

=== When FOSS is worse

==== Puppies

(((FOSS, drawbacks)))
In the words of Scott McNealy, former CEO of Sun Microsystems:

____
Open source is free like a puppy is free.
____

Everybody loves a puppy, right?
_Right??_
I sure hope so.
Because--fair warning--if you spend too much time with your "`puppy`" (self-hosting, FOSS, etc.), your partner will show up with an actual puppy.

[#image-puppy]
.Open Source is free like a puppy. Pictured: actual puppy.
image::puppy.jpg[align="center",scaledwidth=80%]

If your problem is _that_ cute, I suppose it's not too a bad problem to have.
Practically it means that you might become attached to something impractical.

==== The SMOP trap

With proprietary software, if it can't do something, it's easier to give up.
Because, what's the point?
If the change/customization/feature you want doesn't help _their_ bottom line (or their timeline), _you're_ not going to get it.

That never happens with FOSS.
At least, not the same way.
With FOSS you can participate in a software project all the way up to modification and redistribution without having to start your own from scratch.

There's always the possibility that you or someone you know (or pay!) can do that extra little thing.
It might be easy or it might be a https://en.wikipedia.org/wiki/Small_matter_of_programming[SMOP], and you might not know for sure which it is until you are already far down the rabbit hole.

Watch out for that, and https://en.wikipedia.org/wiki/Sunk_cost_fallacy[let go if and when you should].
It's hard sometimes, and it is also a great opportunity to learn about software project management and practice getting feedback from others.

==== Features

One adage of FOSS is "`release early, release often`".
If you stumble onto an early release of something, it might not suit your needs.
When you pick a service to stand up, it either has the features you need or it doesn't.
If it doesn't and you don't want another hobby, move on.

==== Quality

(((FOSS, quality)))
A common issue with FOSS is poor quality, specifically: UI/UX (user interface / user experience).
We (and our users!) are spoiled by the billions spent on intuitive, beautiful non-FOSS UI/UX.

FOSS UI/UX does improve, just not at a predictable rate.
It's hard to get right.
Be ready for this.

I'll avoid recommending anything obviously unusable.
Your mileage may vary.

=== When FOSS is better

(((FOSS, advantages)))
In theory: Always, because you can choose FOSS that lines up with your values.
In practice: Eventually.
FOSS lags behind non-FOSS because companies make _lots_ of money at the leading edge of technology (whether or not it aligns with values).
Some areas where FOSS is especially behind:

* ((mobile)) phones (((Murena)) is promising)
* speech recognition (but check out https://github.com/openai/whisper)
* ((AI)) (this area is changing rapidly)

Let's see how long before these are easily solvable with FOSS too.
It'll be right around the time the _next_ attractive over-hyped widget is available.

I've often pondered when that next attractive tech widget will be something implanted in my body.
Say, a chip that guarantees perfect sleep or supercharges my willpower.
I darn well want that chip to be FOSS.

We don't have to wait for the future to explore the implications of proprietary implants.
You can read about how https://theoutline.com/post/1398/why-can-t-karen-sandler-get-the-source-code-for-her-pacemaker[hero FOSS activist Karen Sandler tried to get the source code for her pacemaker], and follow the https://npr.org/2023/03/14/1163494707/neurotechnology-privacy-data-tracking-nita-farahany-battle-for-brain-book[work of Dr. Farahny on brain-computer interfaces].

==== What FOSS gets right

(((FOSS, profit)))
FOSS is for utility, non-FOSS is for profit.
FOSS exists because it addresses human needs.
Proprietary software exists because it makes money.

Consider that privacy-respecting home data appliance I mentioned earlier.
People really do want something like this, and it'll eventually happen because the "`incentive`" of FOSS most matches natural human incentives of healthy, happy, productive living in community (regardless of whether such qualities make some company or other more money).
FOSS exists because it is useful.
So use it!

If you aren't forced to trust a company with your data, you probably won't.
Once it is cheaper, easier and safer to have your own privacy-respecting home data appliance, you'll have one.
FOSS naturally aligns with this future.

That _truly_ privacy-respecting home data appliance should be FOSS, all the way down to the metal.

Besides privacy, FOSS is better for attention and focus.
FOSS doesn't require your data to exist, so it doesn't require your attention.
This makes it easier to focus on the task at hand, for only as long as you need to.

==== But Spotify has _every song ever_

You may have to listen to a few random songs or ads before you can get to the one you really want to listen to, but yes, Spotify does have many, many songs.
More than you could listen to in your lifetime.
Same with YouTube for video and Audible for audio books.

You will not get unlimited content from a self-hosted media server.
You'll only have the ((DRM))-free content you bought or created and saved.

But do you _need_ unlimited content?
The corporations would like you to believe so.
And we all get bored, so they don't have to work hard to convince us of this.

We live in Aldous Huxley's _Brave New World_... we can be amused to death.

With self-hosting you can choose to be amused just as much as you need to be.
Let's be amused to _live_: inspired, motivated, powerfully kind.

:sectnums!:

== Acknowledgments

Sometimes I feel more like a birthday boy than an author, accepting gifts from so many generous people.
I truly couldn't have done this alone and I am so, so grateful for you.

Thanks to Eva for more than I could ever account for here, from "`What if it rains?`" to leading by learning and fearlessly doing.
For supporting my dreams, including this book: your several inspiring rounds of thoughtful code review, technical critique, developmental editing, copy editing, proof reading, and line editing.

Thanks to my daughter for your fantastic illustrations.

Thanks to Deb Nicholson for writing the meaningful Foreword.

Thanks to my family and friends for tolerating my protracted ((FOSS)) self-hosting boondoggles, including this book.

Thanks to _Pro Git 2_, my inspiration to switch to Asciidoctor.

Thanks to the contributors to the myriad FOSS programs I used to create this book, especially John MacFarlane and the Pandoc team, Dan Allen and the Asciidoctor team, and Bram Moolenaar and the Vim team (rest in peace, Bram).

Thanks to Rob Smith and all #underlug for help with hardware, networking, ((Ansible)), and ((Traefik)).

Thanks to the "`Deadbeat Dads`" Bryan Daisley and Rob Floberg for your invaluable feedback.

Thanks to Bob Nystrom for your mind-expanding design review.

Thanks to Lenny Wondra for your life-changing tech review and editing.

Thanks most of all to my wife and kids for supporting and believing in me.
For all the cooking, talking, listening, art, coding, math, music, and love.
Aren't we lucky?!

== Glossary

Here's a list of definitions for some of the more non-obvious terms I use in this book to clarify how I use them.
These stick to common use as much as possible.
Specialists in computer science, security, administration, networking and so on will have more nuanced definitions.

AI::
  Artificial intelligence.
API::
  Application programming interface. This is for software engineers writing apps/integrations. They need consistent, documented interfaces to write code against.
attack surface::
  Total of possible attack vectors. Fewer is more secure. Example: closing all but the ports you need open reduces yours.
backend::
  I use this term to refer to either a service or server. It's something you more frequently interact with indirectly, say, via a frontend like a web or mobile UI.
bare metal::
  Physical nearby computing resources, as opposed to rented compute time on someone else's hardware.
block storage::
  Cloud storage option with direct filesystem access including files and folders. Used directly/natively/locally from an OS. Size is relatively fixed and determined at creation time.
bot::
  Short for robot. Software performing autonomous tasks such as responding to chat requests or attacking vulnerable servers.
cattle vs. pets::
  Highlights two distinctly different sysadmin approaches to systems/services. Cattle are automated, ephemeral, and hopefully immutable. Pets are managed manually, stateful, and long-lived.
cert::
  Shorthand for HTTPS encryption certificate.
change management::
  The means and methods of transitioning a group of people from one set of tools and processes to another.
cloud::
  An ambiguous amount of remote hardware. Scalable, programmable, and networked. "`The cloud`" or "`public cloud`" is someone else's hardware while "`personal cloud`" is your own.
cluster::
  Collated collection of machines treated as a single machine to achieve higher scale computing power.
compute::
  Noun: CPU or GPU resources expended when running software services.
containerization::
  Technique of isolating and bundling software, primarily to simplify deployment. Faster and lighter-weight than VMs. Close to bare metal performance.
container::
  Running instance of an image. Containers may also be referred to as "`guests`", although this is more commonly used to describe VMs.
cron job::
  Scheduled task executed automatically by the cron daemon.
daemon::
  Long-running background process.
data::
  Noun, plural. Yes, I use the annoying plural form! Sorry, old habit.
data sovereignty::
  Full control of your data. For example, having original copies of your files.
deploy::
  Prepare a service for use. Typically involves building or copying files before a service is started.
devops::
  Systems administration with more software development-like automation. Building/testing/deploying servers/services like software products, for example.
dogfooding::
  Being a user of something you also created and/or maintain. "`Eat your own dogfood.`"
DHCP::
  Dynamic Host Configuration Protocol.
DIY::
  Do it yourself. Said of activities involving some amount of learning and tinkering you'd otherwise pay for. Cooking, for example. Also: self-hosting.
DNS::
  Domain Name System.
domain name::
  Full name for a service as it is used in a URL, e.g. `www.example.com`. Synonymous with "`hostname`" as far as we're concerned.
DRM::
  Digital restrictions management. Ancient, evil technology designed to prevent unapproved consumption of content. Probably used for surveillance too.
dVCS::
  Distributed version control system. These days that pretty much means https://git-scm.com[git].
egress::
  Any outbound data transfer or download, in public cloud terms.
entrypoint::
  How traffic enters the Traefik reverse proxy; network ports.
firewall::
  Means of controlling network traffic between computers.
fork::
  Verb: to split one software project into two. Noun: a derivative software work. The fork diverges from the original (otherwise it would simply be a copy). One or many software projects may succeed the original.
FOSS::
  Free and open-source software. An acronym designed to unite the goals of the FSF and the OSI.
FSF::
  Free Software Foundation. They strongly defend the "`F`" in FOSS.
frontend::
  The UI for a system or service.
full-disk encryption::
  When an entire storage area is cryptographically secure. Also called at-rest encryption.
GB::
  Gigabyte. 10^9^ (1,000,000,000) bytes for HDDs, or 2^30^ (1,073,741,824) bytes for RAM.
good, fast, and cheap::
  Used with a wink in this text because https://en.wikipedia.org/wiki/Project_management_triangle[typically we must pick two].
Good Thing::
  A hand-wavy way of saying something is self-evidently wonderful.
groupware::
  Loosely: mail, calendar, and contacts.
GUI::
  Graphical user interface.
HDD::
  Hard disk drive. Stores ones and zeros on spinning metal platters.
homelab::
  A physical or conceptional space for do-it-yourself flexible systems administration leaning and experimentation. A homelab is not quite what this book describes, it is more of an at-home hardware, software, and electronics maker-space. A _Steadfast_ cloud should be nearly always online and useful--at least the user-facing part. Some self-hosters call this environment "`homeprod`". Far from this level of hair-splitting detail, I'll use "`homelab`" as a shortcut for "`self-hosting space`" and/or "`homeprod`".
host::
  The computer where Docker containers run. Also called a "`server`" in this text.
HVAC::
  Heating, ventilation, and air conditioning.
idempotent::
  An operation which enacts changes only until an end state is reached. Repeating the operation has no effect once the end state is reached. For example, updating an OS. After the OS is up to date, updating again will cause no changes to the list of installed packages (assuming no new updates become available while updating).
image::
  A filesystem with code and dependencies necessary to run a container.
immutable::
  Doesn't change. For example, a particular Docker image. A container instantiated from that image can be modified, but the image cannot; a new image must be built.
IPMI::
  Intelligent Platform Management Interface. Used for remote server management including reboots and OS installs.
IPS::
  Intrusion prevention system. Mitigates the risk of penetration.
ISP::
  Internet service provider.
kernel::
  The part of the OS that talks directly with hardware.
LAN::
  Local area network. For example, the network used by computers and devices to talk with each other inside your home.
LFNW::
  LinuxFest Northwest. Annual conference in Bellingham, Washington dedicated to serving and connecting open source communities. Established in 2000.
Linux::
  The most popular server OS. Also works fine on a desktop or laptop. The old me would have insisted on calling it "`GNU/Linux`" or "`a Linux distribution`". A lot has happened since then, and I've come to believe the term "`Linux`" is good enough to describe the OS used for self-hosting in the context of this book.
low-code::
  High-level application development platform with reduced focus on traditional programming. Typically provides a GUI and requires less files with configuration and code. Useful for prototyping or replacing some simpler data entry and analysis applications.
LTS::
  Long-term support. A stable software release, supported for many years.
mario::
  Provisioning system included with this book to set up and maintain your own server. Consists of scripts, documentation, and configuration files.
NAS::
  Network-attached storage. A server made for storing data. Usually has several HDD bays in a non-rackmount box-like form factor. Likely has less CPU and RAM (and less power usage) than mine, described in <<Server>>.
NIC::
  Network interface card, also called a network adapter. Hardware for receiving and sending data over a network.
object storage::
  Relatively unlimited, typically remote cloud storage option. Actual data are abstracted: backups and structured access require special services, indexes, and software.
OCR::
  Optical character recognition. The process of converting images of text to actual text.
OOB::
  Out-of-band (management). A means of remote low-level server control including power cycling and console interaction, typically provided by an independently powered and networked embedded computer.
OS::
  Operating system.
OSI::
  Open Source Initiative. More concerned with the "`OSS`" of FOSS.
PHP::
  PHP: Hypertext Processor. Programming language built for the web.
PoE::
  Power over ethernet. Utilizes an ethernet cable for electricity as well as data.
port::
  Along with an IP address, a number used to connect to a service. Reserved port numbers such as 80 for HTTP are listed in `/etc/services`.
partition::
  Delineated section of a HDD or block storage, formatted with a filesystem such as ext4 or ZFS.
port forward::
  Router configuration to send traffic for a particular port to a computer inside a LAN.
process::
  Instance of running software. Note that "`running`" processes are described in more detail by a lower-level state such as running, sleeping, idle, waiting for I/O completion and--my personal favorite--zombie.
provision::
  As in, "`provision a server`". Set up a machine or otherwise bring it into alignment with a known/good configuration.
RAID::
  Redundant array of inexpensive disks. Allows flexible use of multiple drives for redundancy and/or speed, as desired.
reproducible::
  Able to be repeated following specific steps. E.g. "`repro`" a bug or "`a reproducible [software] build`". If two people try to repro a bug, they should have the same experience. If two people each build an image from a `Dockerfile`, they should produce the same image. In practice, bug repros and build products are close enough and never exactly the same.
reverse proxy::
  Networking software for filtering and directing traffic. In a self-hosted context, useful for SSL termination and for running several self-hosted web services with different domain names with a single IP address.
router::
  Network device used to handle traffic at the boundary between networks such as a WAN and LAN. This is more formally a border router, so forgive my using the term loosely. A SOHO router typically also provides various other functions including switching, firewalling, and Wi-Fi. See: port forward. A Traefik router is something different: this is a software logic connecting entrypoints to services. See <<Traefik architecture>>.
runtime::
  The period of time when a software is running; when a set of machine instructions becomes a running process. Also used to describe a set of tools/libraries to facilitate same.
SeaGL::
  Seattle GNU/Linux Conference. Held yearly since 2013.
server::
  A computer that generally stays powered on and uses networking for interaction instead of a monitor, keyboard, or mouse.
service::
  A long-running process used by other local and remote processes to do something useful.
SOHO::
  Small office / home office.
source control::
  A system for tracking changes in source code along with who made the change, why, and when.
source of truth::
  The one true document or data point among some number of copies. Used as both plural and singular.
SSD::
  Solid-state drive. A hard drive that doesn't spin.
SSH::
  Secure Shell. Provides encrypted remote command line access to a server.
SSL termination::
  Accepting encrypted traffic and passing along unencrypted traffic. Act performed by Traefik reverse proxy in a mario-provisioned server. More accurately but rarely called TLS termination--SSL is deprecated and rarely used.
sysadmin::
  Portmanteau of "`systems administrator`". A party responsible for the upkeep of a computer system.
threat model::
  Analysis of risks and defenses of digital assets.
TB::
  Terabyte. Like GB, can either be base-10 or base-2, so: 10^12^ (1,000,000,000,000) bytes (for HDDs).
TLD::
  Top-level domain. For "`example.com`", "`.com`" is the TLD.
UI::
  User interface. The means of interaction between a user and a system, e.g.: a web site or mobile app. Often considered along with user experience and notated "`UI/UX`".
UPS::
  Uninterruptible power supply. A battery that sits between your server and an outlet, often with extra features such as a power outage alarm or surge suppressor.
UX::
  User experience. The nature of interaction between a user and a system they are using. Includes ease of use and steps involved to complete a task. Often considered along with user interface and notated "`UI/UX`".
volume::
  Docker container data storage location on the host.
VM::
  Virtual machine. OS isolation technique simulating nearly all aspects of hardware including power, input, and output.
VPN::
  Virtual private network. Useful to "`teleport home`" and behave (from a networking perspective) as if you are inside your home LAN.
WAN::
  Wide-area network. Everything outside your LAN / home network / router.
ZFS::
  A filesystem with many advanced features such as encryption, bit rot mitigation, journaling, volume management, and snapshotting. Used to stand for Zettabyte File System.

ifndef::shb-printPdf[]
== List of figures

* <<image-seagl-crew>>
* <<image-bread-server>>
* <<image-YT-censor>>
* <<image-squeaky-clean-chicken>>
* <<image-YT-audit>>
* <<image-inside-chassis>>
* <<image-service-stack>>
* <<image-traefik-architecture>>
* <<image-racked-server>>
* <<image-bird-on-server>>
* <<image-WAN-to-LAN-traffic>>
* <<image-DNS-traffic-diagram>>
* <<image-puppy>>
endif::[]

== Afterword

Ursula K. Le Guin declared:

____
A book is just a box of words until a reader opens it.
____

And it was so.
 +
 +
Dear Reader,

_This book exists because you exist._
I am humbled and grateful for your support.
Thank you, thank you, thank you.
 +
 +
 Adam

ifdef::backend-pdf[]
[index]
== Index
endif::[]
