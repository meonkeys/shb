= Steadfast Self-Hosting: Rapid-Rise Personal Cloud
Adam Monsen
:doctype: book
:docinfo:
:toc:
:toclevels: 2
:pagenums:
:sectnums:
:imagesdir: img
// FIXME: add a conditional for screen vs. print PDF here
:front-cover-image: image:cover.png[]
:icons: font
:xrefstyle: full
:hide-uri-scheme:
:source-highlighter: pygments
// fixes alignment of line numbers with source in EPUB and HTML
:pygments-linenums-mode: inline
:!chapter-signifier:
// prevent unnecessary blocking fetch of fonts
:!webfonts:
:pdf-theme: print-theme.yml
// FIXME: add a conditional for screen vs. print PDF here
:media: prepress
// necessary for keyboard macro (kbd)
:experimental:

//[colophon]
//== Colophon
//
//The Asciidoctor Press, Ceres and Denver.
//
//(C) 2020 by The Asciidoctor Press
//
//Published in the Milky Way Galaxy.
//
//This book is designed by Dagger Flush, Denver, Colorado.
//The types are handset Volcano Dust and Papaya, designed by Leeloo.
//Leeloo created the typefaces to soften the bluntness of documentation.
//
//Built with Asciidoctor on Fedora 33.
//
//Printing and binding by Ceres Lithographing, Inc., Ceres, Milky Way.
//
== Introduction

=== Thesis

This book will demonstrate data sovereignty through self-hosting.

=== Welcome

The self-hosting ecosystem is crowded and confusing.

Fear not!

This book is your personal guide to joy; a battle-tested fast path to success.
Together we'll quickly stand up *services* in *containers* behind a *reverse proxy*.

With these three basic components we will summon a robust data haven.
We'll take some basic concepts from systems administration and devops to create love, beauty, and deep meaning.

We will:

* Not settle for cheap cloud services.
* Reduce distractions.
* Cherish our attention, time, and freedom.
* Breathe the crisp, clear air of reduced surveillance by providing our own alternative to the chilling popular default of trading privacy for convenience.
* Save money by efficiently running lots of services on our own hardware with negligible incremental cost.
* Do well by our friends, families, and social groups.
* Do things we can't do with public services because we have full access to all our own raw data.
* Adapt and grow as software evolves, taking our data and metadata along with us, sharing when it makes sense to do so and with whom we trust.

This will be liberating.

=== Cover art

The beautiful cover art was created by my daughter using Krita (https://krita.org).

You'll find more of her excellent work later in this book, too.

=== Supporting the author

I wrote this book with my own resources after years of research with lots of help from awesome people.
See <<_acknowledgments>>.

Please buy a copy for yourself or someone else, especially if you'd like me to write more awesome books in the future.
See <<Buy or donate>>.

This book is a work in progress.
Please help me improve it.
See <<_contributions>>.

== Metadata

=== Version information

This book was generated

* on *{build_date_time}*
* from git commit *{build_git_commit}*
* using *{build_os_release}*

=== Copyright and license

_Steadfast Self-Hosting: Rapid-Rise Personal Cloud_ is copyright (C)2023 Adam Monsen.

==== Copy this book

Please make copies and derivative works.
I want it to be enjoyed and shared.
I chose a license that explicitly encourages sharing.
Check this out:

This book is distributed under the **Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) license**.
Contact me if you are interested in obtaining it under another license.

===== You are free to:

*Share* -- copy and redistribute the material in any medium or format

*Adapt* -- remix, transform, and build upon the material

_The licensor cannot revoke these freedoms as long as you follow the license terms._

===== Under the following terms:

*Attribution* -- You must give appropriate credit, provide a link to the license, and indicate if changes were made.
You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.

*NonCommercial* -- You may not use the material for commercial purposes.

*ShareAlike* -- If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.

*No additional restrictions* -- You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.

===== Notices

You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation.

No warranties are given.
The license may not give you all of the permissions necessary for your intended use.
For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.

==== Copy this book's code, too

I've got two things for you to fork (copy, modify, and share).

First: the book itself, along with code to generate beautifully typeset versions.
See <<How to build this book>>.

Second: a learning tool called _mario_. _mario_ is a small set of scripts and configuration files to help you set up and maintain your own server.
It is mainly a wrapper around Ansible (https://ansible.com).

The license for all original source code related to this book is the GNU AGPL (Affero General Public License) as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.

A copy of the AGPL is included in `mario/COPYING`.

=== Disclaimer

(((warranty, none offered)))
I offer no warranty and no guarantee.
Buying or reading this text is not an agreement for support.

While every precaution has been taken in the preparation of this book, I assume no responsibility for errors or omissions or for damages resulting from the use of its code or contents.

I am not professionally affiliated with the products or paid for by the companies mentioned in this book.
Their copyrights, trademarks and intellectual property are their own.

My opinions are my own.

I include direct references to many products and companies and add my specific, hard-won lessons on their comparative strengths and weaknesses.
My intent is to educate and inform.

I will take shortcuts.
I will not seek to deeply and exhaustively explore each topic.
I want you to get to the good stuff quickly, then decide if, when and where you want to dive deeper.

If you find contradictions to these statements, please let me know.

I'm human and error-prone.
I'll make it easy to contact me about missing or incorrect information.
Please do.
When you do, include references or other supporting material.

=== Style examples

(((typography)))
Here's how certain types of content will appear in the text.

|===
|Styled example |Used for

|`zpool status -t` |command, filename, username, password, variable
|kbd:[Ctrl+c] |key(s) pressed on the keyboard
|https://example.com |link to website (https scheme is assumed and omitted)
|<<Command line>> |cross-reference to another section or chapter
|===

== Background

=== Who am I?

(((FOSS)))
I'm a dad, tech entrepreneur, and FOSS (free and open source software) enthusiast.
I love to parent, care, laugh, sing, listen, code, build, produce, debug, architect, debug, lead, manage, debug some more, lecture, and write.
I'm good at administering and securing systems and processes while ensuring privacy, compliance, and reliability.

I'm most proud of my family, growing Mifos (https://mifos.org), founding SeaGL (https://seagl.org), selling C-SATS (https://csats.com), and writing this book.

I aspire to always be kind and minimize my ego.

I've been running my own services for decades.
I started with a humble blog running on a buddy's machine.
The feeling of freedom and control was exciting and it complemented my effectiveness at work, so I kept on.
I worked with many services and servers but usually avoided running my own hardware.
Once I had a family, our data storage needs increased at home.
It became handy as parents to be able to provide more and safer online services for our kids.
Samba and Syncthing were no longer enough; I wanted better services for managing our data and the autonomy of our own bare metal.

During the pandemic our family data/service needs increased sharply, and I was wary of companies swooping in to grab mindshare.
At the same time, I decided to de-Google (https://en.wikipedia.org/wiki/DeGoogle).
The family needs and my de-Googling coincided well.
Self-hosting was a serendipitous fit.
Just _trying_ to de-Google was a fascinating and fulfilling journey, punctuated with many self-hosting experiments.

=== Why did I write this book?

(((data sovereignty)))
I wrote this book to promote *data sovereignty*.
I use that phrase to mean you have full control of your data.
This is easier to achieve than ever before with self-hosting, and I wanted to share that out in book form.
Existing books lack a good, fast, and cheap technique for self-hosting on bare metal.
I figured one out and I think you'll love it.
It works fine if you run your server in the cloud too, it just costs a lot more (see <<_server>>).

Also: learning is fun.
I learn when I write.
While learning how my phone works, it struck me how important it is to understand _how “the cloud” works_, since the modern phone experience relies on services and data in public clouds.
In trying to make my phone “my own” (do what I want to help me live my best life), I was inspired to host my own data in my own cloud.

Also: everyone I know with at least a pinky toe in the tech industry self-hosts _something_.
There's always another self-hosted service to try out, learn about, improve, and share.

Also: maybe I can make a buck or two doing this, or at the next thing I do.
Maybe you can hire me to help you out.

Also: to write the book I wish I had when _I_ started self-hosting.

Also: so there's a _book_ about this.
There are countless videos, articles, and chunks of code online for doing everything in this book and more.
Many are excellent.
This book is your to keep, hold, and refer back to as you try, test, and learn.

Also: there's a stark gap between useful individual computers and useful cloud services.
It's easy to pay for cloud, but the true price is obscured: surveillance, lock-in, inflexibility.

Also: I can picture a future where owning a privacy-respecting home data appliance becomes as commonplace as owning a refrigerator.
Creating this appliance has been attempted and it'll be attempted again.
Until it succeeds and sticks: self-hosting--setting up a server and services for yourself and others--is a great way to go.
And when that home data appliance _does_ land, maybe you can buy one from me!

=== What's with the title?

==== Steadfast Self-Hosting

I like the word _steadfast_.
It reminds me of reliable things and people.

(((data sovereignty)))
The key to reliable self-hosting is data sovereignty.
Software will change, services will change, you will change and the world will change.
You've got to have control of your data if you want it to reliably serve you well through all that change.

It does make a difference to have your own copy.
You might lose access to something you “bought” or it might even change right under your nose.

* https://kotaku.com/sony-ps4-ps5-discovery-mythbusters-tv-1851066164
* https://defectivebydesign.org/what_is_drm_digital_restrictions_management
* https://nytimes.com/2023/04/04/arts/dahl-christie-stine-kindle-edited.html

Saving off data is easy.
Self-hosting goes a step beyond that to give you far-reaching control of how your data are used and shared.
You'll get reliability and flexibility within a reasonable budget.

Self-hosting means providing computing services by and for individuals, families, and hobbyists in SOHO (small office / home office) environments.

“Small-community-hosting” is perhaps a more accurate and appropriate term here.
You're reading the right book to host services for a small community.

==== Rapid-Rise Personal Cloud

_Rapid-rise_ is something you might find on a package of baker's yeast, and I love fresh-baked bread.
If your server is a loaf of bread, this book is your rapid-rise yeast.

.Server in the shape of a loaf of bread.
image::bread-server.png[align="center",scaledwidth=80%]

_Cloud_ implies scalable, _Personal_ scopes that to scalability to what's reasonable for a small group.
Modern bare metal hardware can scale (to a degree) within its box.
It can scale automatically by using more or less power according to compute demand, and manually when you upgrade hardware components (say, adding another hard drive).

I'll also admit my inner child enjoys multiple meanings of the phrase _Personal Cloud_.

=== Who is this for?

This book is for people who are kind to others, brave in trying new things, curious about the possibilities of self-hosting, and either uncertain how to do so or eager to improve their existing homelab (self-hosting space).

This book is for people who want to know where their data live, and to be able to work all kinds of magic with it.
It's a “from scratch” or “the hard way” approach, and it keeps the doors wide open to many possibilities with a principled self-hosting technique.

(((FOSS)))
This book is for people curious about or already biased towards FOSS.
And--as much as I'll blather on about FOSS--I'm not here to judge.
I'm here to _grow_, primarily by sharing and learning.

This book is for students, especially tech-savvy or tech-adjacent students active in clubs and teams.

This book is for those trying to live more for others and less for themselves; selfishly enjoying the act of being selfless.
Leaders, parents/guardians, members of a collective.
People who want to self host, who _also_ love others and doing other things besides systems administration.
I hope I can save you some precious time.

This book is for people supporting a small group, like a family or a handful of friends.

Similar to “small-community-hosting”, _Small Group Cloud_ would be more accurate title words than _Personal Cloud_.
Think of “small group” as the optimal user population size that will benefit from our services.
I wouldn't bother doing all this just for yourself.

This book is for people into (or hoping to get into) self-hosting.
It is geared towards useful, secure, and quick setup of a single bare metal server with many services.

This book is for people who want to _de-Google_, _de-iTunes_, _de-OneDrive_, _de-Dropbox_, _de-Whatever_.

=== What is this book _not_?

This is not a comprehensive guide to self-hosting.
I won't attempt to enumerate the endless ways to mix and match hardware, operating systems, virtual machines, and services.
This book is for small scale.
Look elsewhere for:

* high availability
* enterprise security
* N + 1 redundancy
* managing many machines
* clustering
* single sign-on
* advanced monitoring and metrics centralization
* intrusion/threat detection/prevention
* running your own container registry
* 100% offline / off-the-grid self-hosting

There are some topics like these above I'll skip or cover only briefly.
Any one of these topics is an entire industry, another piece of hardware, a setting on your home router, a potential career, none or all of the above, and otherwise well worth further consideration.
You can and should be aware of them.
If you feel I've completely omitted proper detail about something critically relevant to my method of self-hosting, please let me know.

This book is not for the heavily-resourced already-done-thats.
If you have $50k and unlimited time to spend on your concrete bunker homelab... well then, may I have a tour?
I would LOVE to see that.
If you are more curious than certain you may still enjoy learning from my choices and I'd appreciate your feedback.

I'm not writing for hard-line software licensing experts/extremists.
These wonderful folks will spot my intentional use of the word _open_ and omission of the word _libre_.
I love all these words, and I stand on the side of inclusion at the cost of idealism (while maintaining the hope these concepts are not mutually exclusive).
I thank the activists for helping swing the needle towards freedom, to all our benefit.

This book is not a manifesto for always/only self-hosting.
It's fine to self-host some services and pay for others.
You'll come up with your own rubric on what to self-host and when.
Mine focuses on providing a useful, reliable, future-proof cloud for me and my family.

This book is not the fastest path to trying out web-based services.
You can usually find demo instances running for particular projects.
There are cloud providers that will run a service for you and host your data.

There are one-click-install appliances with many ready-to-go apps.
FreedomBox (https://freedombox.org) is one promising contender in this space.

There are shortcuts and frontends for self-hosting.
For example, openmediavault (https://openmediavault.org) looks like a cool way to build a DIY (do it yourself) NAS (network attached storage).

And there are countless more of these kinds of partial or full-service self-hosting solutions.
More:

* YunoHost (https://yunohost.org) - not considered, I prefer always using containers
* CasaOS (https://casaos.io) - new, interesting, very little documentation
* Runtipi (https://runtipi.io) - new, interesting, uses Docker Compose and Traefik

These look like great ideas, and it's hopeful (and overwhelming) to see many options in this space.
I evaluated them (and others) only enough to get the sense they didn't fit my wants and needs.
Like a crochety old man I've since raised my bar to change and instead come up with a rubric I'll share for evaluating the next self-hosting solution.
One should ask:

* Will it work for years with minimal tinkering?
* Is it easily extensible?
* Does it weaken or strengthen security by changing my attack surface?
* Does it add features/value I need/want, beyond what I'm already able to do?
* Will it help my users?
* Will it help me learn what I need/want to learn, and safely take care of the rest for me without my needing to learn more?
* Will it help me figure out why I made a change to one of my services two years ago?
* Does it phone home, using telemetry or my data in a way I don't approve?
* Does it hold back “enterprise” features I need, even for my scaled-down use case? Is it annoying about this, reminding me often?
* If I want paid support, is it available?
* Is it popular? Has it been around a while, and do I expect it to endure?

After brief reviews, I find they generally:

* are new and immature
* lack proper documentation
* try to do too much without sufficient inertia/resources to maintain it all
* don't do enough: just another Linux distro with an added layer to discover and install apps
* make opinionated tech choices I don't agree with
* have a limited list of apps in their app stores and often exclude the ones I want
* have too many apps in their app store, without good ways to compare quality, privacy, features
* are GUI (graphical user interface)-focused where I prefer working on a command line

Still, check 'em out.
They might work better for you if you don't need the level of power and control provided by this book.
By the time I publish, they (or some new contenders) might grow to overcome my approach.
Please let me know what you discover.
If I missed something, I'd love to learn about it!

Here are more related and interesting self-hosting solutions I learned about too late in the writing process to research at all:

* Ansible NAS (https://github.com/davestephens/ansible-nas)
* Cosmos Cloud (https://cosmos-cloud.io)
* DockSTARTer (https://dockstarter.com)
* HomelabOS (https://homelabos.com)
* Start9 (https://start9.com)
* MicroCloud (https://canonical.com/microcloud)
* LibreServer (https://libreserver.org)
* UBOS (https://ubos.net)

==== Command line

The “command line” mention above is worth a beat, to understand my personal bias.
It's more than a relic from the old days, it's also a source of power and joy.

// see https://docs.asciidoctor.org/asciidoc/latest/macros/complex-urls/

* pass:macros[https://en.wikipedia.org/wiki/In_the_Beginning..._Was_the_Command_Line]

I use GUIs often, and I often _prefer_ the command line and only add a GUI layer when I need one.
It's often easier and faster to build and maintain a command line interface.
It gives me more control and forces me to learn.
It helps me understand what's happening and why.
With it I'm able to quickly make changes and automate.
It's also faster and more ergonomic than using a mouse.

==== You'll find your path

Continuing advances in hardware and software means self-hosting today is easier and cheaper than ever before.

And in one key way, much more complex: there are an overwhelming number of choices to be made for someone starting out on this journey.

Hang in there.
I'll help you narrow the choices by providing specific, focused guidance.

Don't worry too much about the specific choices you make.
Your personal cloud will be malleable.
Swap out bits as you like.
If you choose poorly, just choose again (ideally based on metrics and user needs).

You aren't a failure if you don't get it right the first time.

It is OK to slowly migrate from whatever you currently use.
No need to upset everything all at once.

It is OK to _not migrate at all_ and just follow this book to expand your own personal learning and experimentation.

It is OK if you don't adhere perfectly to your or someone else's ideals.
Stick to your values while you question and develop these values.
Enjoy your journey.

=== Why you should self-host

Ask again--as you should--why the heck would anyone self-host software services?

So many reasons!

* Flexibility
** run only the services you and your users want
** use multiple services backed by the same data storage
** automate what you want, when you want
** unlimited sharing
** unlimited streaming
** unlimited choices
* Fun!
** learn and grow (see also: suffer)
** self-hosting is a doable challenge
** solve right-sized puzzles as you learn and improve
** be part of the thriving self-hosting community
* Be future-proof
** insulate your users from the unpredictable shifting of proprietary product prices, service offerings, and UI/UX
** share your hard-earned data to your friends and family, forever
** migrate to something else easily if and when you need to (for example, using a newer/better photo server once one becomes available)
** it's really the _data_ that must be safeguarded, the frontends to those data (file viewers, editors, etc) will change when _you_ choose
* Democratize computing
** self-hosted software (especially FOSS) enables data and computational autonomy for more people
* Conserve electricity
** backend cloud power per device drops dramatically with a few users
** save even more power the more users you add
** see linked articles in <<_server>>
* Save money
** in the long run
** especially if/when your group's data requirements enter the terabyte range
** save more with every service you run
** avoid unexpected public cloud costs
*** when you want to download your data and move it somewhere else
*** when you need to do something the cloud doesn't support
** avoid unexpected _changes in_ public clouds
*** changes in license fees
*** changes in usage fees
*** changes in support costs
*** changes in service offerings
** near-zero incremental cost of adding users and services
** when you own your hardware outright, you have zero per-usage fees (compute, data transfer)
* Speed / Save time
** a nearby server can have much better response times, assuming reasonable hardware and well-behaved services
** nearby data (“data locality”) means you don't need round-trips to someone else's data center to run experiments
** shared storage allows you to front your data with multiple services, choosing read-write/read-only access sensibly
* Avoid vendor lock-in
** You'll be able to use software features public cloud providers don't offer or don't yet exist because you fully own and control your raw data
** When you buy something, _it's yours_. DRM should be illegal.
** Is there an integration you count on? Sometimes a service stops working with another service. This happens less often with ((FOSS)) because anyone can simply fork a project.
* Privacy
** avoid the chilling effect of mass surveillance
** with a personal cloud you can safely and confidently keep GPS latitude & longitude in your photo metadata
** once you keep your location metadata, you can do creative things with it
** if you don't _need_ to share your location and behavior with Google every second, why do you?
** when you stream video from someone else's service, they know and analyze every time you (or your kids) (re-)watch a video you “own”, every time you rewind, fast-forward, pause... but do they need to? why?
* It's not as hard as you think to self-host
** sometimes it is harder
** sometimes it is easier
* Unlock new possibilities
** view travel lines with phonetrack
** apply arbitrary workflows to uploaded files
** deploy trustworthy, offline generative ((AI)) (artificial intelligence) models

(((Nextcloud)))
See https://nextcloud.com/athome/ for more self-hosting propaganda and app ideas.

==== Criminal chickens

Here's a real example of a positive outcome I realized from self-hosting.

My family has a homemade chicken safety system (https://github.com/meonkeys/rpi-chx-code) and the videos are important to me.
I used to just plop them on YouTube because hey, it's free and it “just works”, right?

Except when it doesn't.
YouTube sometimes felt my chickens were being spammy, deceptive, and/or scammy.

.Screenshot of an email from YouTube content team having removed my chicken coop camera video.
image::YT-censor.png[align="center",scaledwidth=80%]

For the record, our chickens are _squeaky clean_.

Once I stood up my personal cloud I felt freedom and ease when posting and hosting these videos.

I no longer needed to complete any YouTube paperwork to be able to keep an eye on my chickens.
I can safely ignore their audit and its erroneous compliance infringement warning.

.Screenshot of a YouTube legal audit for my old API client.
image::YT-audit.png[align="center",scaledwidth=80%]

I also no longer need to work with YouTube's API (Application programming interface), including registering an API client and completing periodic audits.
(((Nextcloud)))
After standing up Nextcloud I deleted my YouTube API client to upload videos, cleaning up my code and simplifying its maintenance.
Turns out the Nextcloud Talk API is easier for posting my chicken coop photos & videos anyway.

With my own cloud I'm also able to tune quotas and rate limits as desired.
Full speed ahead!

==== Geo photo search

Here's one more pro-personal-cloud example.

A while back I was trying to find some photos from a pile of thousands, taking up terabytes on disk.
I knew _where_ the photos were taken within about 10 miles, and my photos have embedded geo metadata.

My photos are just a bunch of JPEG files.
I examined them with a small program I wrote.
I pulled out geo metadata and looked for anything within 10 miles of the point I knew.
I used Python, and any language would work.
The key was being able to access the data directly and quickly.

This is just one (likely outdated) example.
By the time you read this you may be able to query your photos with a sentence like: “show me all photos taken within 10 miles of Mexico City”, and it'll just work.

Then you can move on to saving the world.
Just make sure you've got your data!

=== Why you should not self-host

Self-hosting is more complex and time-consuming than paying for the same functionality, especially at first.
It takes discipline and patience, like learning a new instrument (but _this_ instrument eventually plays itself!).

If something breaks, you're fixing it.
Sometimes you get a useful error, sometimes you can search the web for a quick fix.
Sometimes you don't and can't.

If you don't enjoy troubleshooting and debugging, self-hosting might not be for you.

If you don't take care with backups and security, you'll risk time, energy, and trust with people you care about.

On-premise self-hosting entails additional meatspace-specific considerations.
You need to ensure sufficient power, connectivity, HVAC (heating, ventilation, and air conditioning), and security.
Just don't keep your server outside.

=== How write book?

Why are you talking like a caveman?

I wrote the book originally in Markdown plain text in my steadfast text editor, Vim.
I applied generous amounts of Pandoc (https://pandoc.org), time, and love.
Pandoc is a fantastic ((FOSS)) tool which allowed me to use that single plain text file with fairly human-readable Markdown syntax to generate several different decent outputs.
While revising, I came across the build system for Pro Git 2 (https://github.com/progit/progit2 - thank you Scott and Ben!).
In short order I converted the book to Asciidoc (https://asciidoc.org) and ported my typsetting code to Asciidoctor (https://asciidoctor.org).
This simplified the book build and gave me more and better output formats.

Check out the source code -- you're welcome to hack away at it.
See <<More resources>> and <<How to build this book>>.

I tried to stick with off-the-shelf FOSS software as much as possible, with minimal customization.
This helped me focus on the content while keeping the book simple enough to self-publish.

=== When write book?

Still with the caveman.
Enough already.

I wrote this in 2023.

And, listen: even blessed cave-dwellers like us should give self-hosting a shot.
We got this!

=== Where?

Seattle.

=== Hey now.

Admittedly, those last few sections exist so I could cover all 5 Ws (https://en.wikipedia.org/wiki/Five_Ws) and include the caveman gimmick.

=== A note on FOSS

(((FOSS, bias)))
I prefer FOSS over non-FOSS.
This can be a polarizing topic.
Heck, even using the term FOSS instead of the other variants can be polarizing.
These are just distractions.
Today we need compromise, patience, and kindness.
Curiosity over certainty.

Here's my promise to you, dear Reader:

I will try not to get too preachy.

I will prioritize _practical_ solutions over _idealistic_ ones.
I will sometimes fail to do this when it comes to FOSS.
Most notably, I will barely acknowledge the existence of non-FOSS alternatives in this book.

I'm aware of the tension between practical and idealistic solutions, and I believe this tension is a Good Thing because it reminds us to think critically about what cloud services we _should_ pay for and use, not just what we _can_ pay for and use.
It's worth a moment's thought.

Our data matter and our personal choices matter.
The impact spreads to the groups you are a part of, as does the opportunity for improvement.

I believe self-hosting FOSS is doable and affords many practical benefits over non-FOSS.

Hang in there and give me some feedback.
You'll strike your own balance between idealism and practicality and I'm interested to know where you land.

Continued ad nauseam in <<More about FOSS>>.

=== Surprises

Should you choose to proceed: godspeed, traveler.
This is seriously fun stuff.

You may be surprised by how fast & easy some things are with self-hosting.
I'd love to know how this goes for you.

You may also be surprised by how time-consuming and difficult some things are.
Maybe you'll get held up with hardware (and its power, wires, cooling, failures).
Maybe networking.
(((Nextcloud)))
Maybe “change management” (trying to convince your users to use Nextcloud instead of Dropbox).

Here are some things that surprised me, both positively and negatively.

==== Good surprises

===== Hardware

With help from a friend (thanks Rob!), I bought a reliable and cheap refurbished server.
I thought I'd be tinkering with wires, cards, and CMOS batteries.
Not so!
I opened the chassis to see the guts.
I confirmed the contents were normal server guts, or close enough.
The CPUs and memory sticks were all there as advertised.

I plugged it in; it worked.
Took me longer to build a rack for my server than it took me to power it on.

.View inside the server showing two empty PCI-E card slots.
image::inside-chassis.jpg[align="center",scaledwidth=80%]

===== Containers

I was pleasantly surprised by containers following my varied earlier experiences with VMs (virtual machines).
VMs are simple at first because they behave much like physical hardware.
Installing Linux into a VM is as easy as installing it onto bare metal (sometimes even easier).
Then you can set up one or more services in the VM.
The real rub here is with maintenance: maintaining a VM can be as complex as maintaining a bare metal server.

Containers take a different approach and simulate much less of a bare metal server.
They are fast and small compared with VMs, allowing higher non-conflicting service density.
That is, you can stand up more services per server and they don't interfere with one another (e.g. by requiring different versions of PHP (PHP: Hypertext Processor)).
One container typically contains only one service.

Isolation of containers is limited compared to VMs.
The kernel is shared, for example.
Limited isolation keeps the resource and maintenance costs of container-based isolation low compared with VMs.

Containers are excellent for a consistent and resilient personal cloud.
They are easy to declare (in code), build, deploy, test, and repeat.

I chose Docker to manage containers because it is popular and I have experience with it.
Your server is also considered a _host_ since it it is a _host_ to Docker containers.

One downside of Docker is how often root access is assumed in example code and popular public images.
Running as root makes containers simpler but less secure.

===== OCR

Another smile-worthy advancement is free OCR (optical character recognition).
I keep trying to “go paperless” by scanning in all my paper files.
After scanning papers I am shouldered with, unsurprisingly, a bunch of PDFs of images.
(((Nextcloud, search)))
These can be easily OCR'd and managed with tools like Paperless-ngx (https://docs.paperless-ngx.com/) and Nextcloud Full text search (https://apps.nextcloud.com/apps/fulltextsearch).

===== Jellyfin

((Jellyfin)) is a personal streaming media server.
I was stoked to see how Jellyfin showed up as an excellent and complete FOSS alternative to Plex.

==== Bad surprises

===== Traefik

Traefik was surprisingly challenging to set up because my networking fundamentals were rusty.
I've got it working reliably and I still need to keep improving my fundamental knowledge in networking.

===== Nextcloud

(((Nextcloud, surprises)))
I was frustrated with some bugs in Nextcloud.
These felt like the most urgent since I rely heavily on it.

Community support is hit or miss.
Nextcloud seems more popular outside the USA.

Not all Nextcloud apps are ready for prime time.
See <<_customization>>.

===== Jitsi

((Jitsi)) is a self-hostable FOSS video call platform.
I gave up trying to get Jitsi running in Docker.
I recall lots of open ports or port ranges being a problem.
This one might be easier in a virtual machine.
There's also a workaround assigning port ranges to specific IP addresses, but this is beyond the scope of this book.

I will eventually give it another shot because logging in is now required when using the free 8x8-hosted Jitsi service (see https://jitsi.org/blog/authentication-on-meet-jit-si/).

==== Absorb them all

When it comes to surprises, try to absorb the bad ones when they affect your users.
Ideally _before_ they affect your users, via research, planning, and testing you're likely already doing.

Dogfood what you self-host.
Try your best to ensure everything is attractive and useful, then wait.
Be patient.
Never try to force people to use whatever you self-host.

I hope this book inspires you with many positive surprises and helps you and your users avoid many negative ones.

== Prerequisites

=== Skills

This book assumes some prerequisite skills.
You must be able to:

* configure your router and LAN (local area network)
* install Linux on a computer (hereafter referred to as your _server_)
* execute programs using a command line
* connect to your server with SSH (secure shell)
* edit text files and run commands on your server
* transfer files to and from your server

These are not difficult.
You can quickly learn them online.

=== Experience level

New self-hosters can use this book to get started.

Experienced self-hosters can compare my choices to theirs.

=== Mindset

. ask for help
. ask for feedback
. listen to users, gather data, adapt accordingly

=== Discipline

* document everything you do
** if only for your future self!
* train help in case you get hit by a bus
** made much easier since you've documented everything
* focus, take breaks, be patient, sleep, exercise, eat healthy

== Plan

Consider the time and cost of self-hosting.
To yourself _and your users_.

I love this part.
I get excited about what's to come, and I know a solid plan makes a vision real.
I start by capturing my plans in a Markdeep (https://casual-effects.com/markdeep/) file, including a calendar, budget, network diagram, to-do list and notes.

Make _your_ plan.
Maintain and improve your plan along with your server.
Share the plan with other admins.

Yep: other admins.
You need someone to cover for you when you are not available, or a crystal clear expectation that when you die, the server dies too.

=== Budget

How much do you have/want to spend.
Write down a number and stick to it.

=== Resources

Sketch out your thoughts on resources you'll need.
Some ideas:

* Data storage. There's a significant jump in complexity and cost with each jump in unit (for example, GB (gigabyte) to TB (terabyte)). This book is appropriate for data storage up to about 10 TB.
* Electricity. Check your home power bill for the cost per kWh and run some estimates.
* Support. Who will help you when you get stuck?
* Physical location. Where will the server live? Will you have to install new wiring for power or network?

=== Schedule

Rough out key dates so you and your users can plan ahead.
For example:

* Apr 28: Brainstorm, plan.
* Apr 30: Order hardware.
* May 3: Pull ethernet from router into garage.
* May 5: Set up server.
** Install hard drives.
** Power on!
** Install operating system.
** Start services.
* Jun 9: Review result against original goals.

Invite others to participate, starting at the beginning when you brainstorm and plan.
This is a great time to include other people who may help care for the server.

=== Transition

Your users already have their data somewhere else.
Consider how you'll help them migrate their data onto the server.

The key to this is excellent communication.
Include this in your plan and seek buy-in since migration cost is a reality for every transition.

To learn more about how to do this well, study _change management_.

=== User support

Let's first get in the right mindset to do the best we can by our users.

Make sure the cloud works well for them.
Solicit their input often and take it seriously.
Carefully tease out _wants_ vs. _needs_.

Translate the word “users” as necessary.
Perhaps: “those most dear to you, those you care about most above all others, those who give you meaning and purpose.”

Yeah, that's way over the top.
You get the point: we must care about their experience or their experience will be poor.

Know your users.
For example: they might not be activists, or might not be activists for your cause.
Be thoughtful.

Also: know thyself.
I'll go first: I recognize that using the word FOSS is a signal to staunch pragmatists that I'm on the activist spectrum.
I solicit feedback from others to balance my idealism with pragmatism.

== System design

In <<_mario>> we'll get to know the tool you can use to take care of some of the fiddly details of setting up a server.
For now we'll cover its output from a high level.

=== Service stack

(((Docker)))
(((Jellyfin)))
(((Nextcloud)))
(((Ubuntu)))
(((Wallabag)))
(((ZFS)))
A _mario_-built system presents nicely as a simplified stack of colored boxes.
These are conceptual, based on where and how frequently I act and investigate when supporting or troubleshooting. “Stack” is also commonly used to describe interdependent layers of a system.

.Layers of a _mario_-built system. From the bottom we have hardware: bare metal, filesystem: ZFS, OS: Ubuntu LTS 64-bit server, container runtime: Docker, containers: Nextcloud file sharing app, Jellyfin media server, Wallabag article reader.
image::service-stack.png[align="center",scaledwidth=80%]

I am most often working around the top layers e.g. adding or updating a container.

Less often I am updating OS (operating system) packages.

Less often still I might examine versions of a configuration file stored on disk from its ((ZFS)) automatic snapshots.

Finally, when my server dies, I'll be on that bottom layer fixing or replacing hardware.

=== Digital security

Here's a quick recipe for the average self-hoster with limited time, considering two classes of data:

. sensitive data
* includes passwords, credit card numbers, government ID number
* store offline only if possible
* if ever saved on a computer, store encrypted
* easy fix: store in a password manager
. everything else
* includes notes, photos, documents, personal information
* store on encrypted media, including backups
* access only with up-to-date software you trust
* disallow WAN access to these data

One common sticking point is WAN access.
That's remote access to the data, through your router/firewall.
(((Nextcloud)))
Say: port-forwarding HTTPS traffic through your router/firewall to your Nextcloud server.
It is risky and convenient.

(((threat model)))
Let's back up a step and talk about threat modeling.
Your _threat model_ is how you'll consider threats to your data and how you'll mitigate these threats.
With your threat model in mind, you'll be able to gain confidence in, for example, the decision of whether or not you should permit WAN access.

WARNING: If you already know you are a valuable target (public figure, high net worth, wartime journalist, responsible for a server with information about many people), buckle up for a longer journey.
This guide is not sufficient for your threat model.

Everyone else: Let's build a simple example threat model for the “everything else” category above.

==== Threat model

Consider:

* *Assets*
** Data you are trying to protect (everything digital besides what you store in a password manager).
* *Actors/Threats/Vectors*
** People and bots acting badly, and their means of attack. Includes mistakes and bugs.
* *Mitigations*
** Steps taken to reduce chances attacks succeed.

That makes my marketing-friendly threat model acronym *A.A/T/V.M.* (all punctuation is vocalized).
Really just rolls off the tongue!

==== Example: WAN attack

Let's run “WAN access” through our ((threat model)).

* *Assets*
** Personal information stored on out-of-date ((Nextcloud)) server.
* *Actors/Threats/Vectors*
** Bot finds URL to Nextcloud server on a publicly archived mailing list. Bot automatically attempts exploit against known vulnerability in Nextcloud server. Exploit succeeds, bot owner gains access to personal information and attempts identity theft.
* *Mitigations*
** Keep Nextcloud server up to date.
** Secure WAN boundary: monitor traffic logs, employ an IPS (intrusion prevention system), only cross into LAN using a VPN (virtual private network).
** Close WAN boundary: disallow all inbound WAN traffic.

(((Nextcloud, security)))
This suggests we should only allow WAN traffic if we are keeping Nextcloud up to date and monitoring/limiting access via our WAN.

Allowing WAN access and not using public mailing lists only obscures an out-of-date Nextcloud server, and one shouldn't rely on “security through obscurity”.

Mitigating at multiple layers (OS firewall, Nextcloud, WAN boundary) is called “defense in depth”. It's a great idea.

==== open WAN access alternative: Wireguard

A few years ago, VPN technology got a major upgrade with Wireguard. From a user perspective there's no “logging in” as with older VPNs. Wireguard is fast and easy and secure. When you're away from home, you can simply flip it on to teleport back into your LAN.

If all your users are able to use Wireguard, you can keep ports closed for HTTP/S traffic and instead only allow Wireguard traffic from specific users with specific keys. Assuming your Wireguard server is well-configured and up to date, this is an excellent way to reduce your attack surface.

==== More tips

* Maintain useful encrypted backups. Perform test restores to know they are useful. See <<_backups>>.
* Avoid running commands as the `root` user.
* Use multi-factor authentication.
* Use firewalls.
* Use strong passwords.
* Be very careful when opening up WAN ports or don't do it at all.
* Be vigilant about all the usual stuff too: phishing, malware, SMS spoofing, and social attacks.
** Take caution with email links and attachments.
** Don't install untrusted software. Always use HTTPS.
** Use a special passphrase with your mobile carrier.
** Question urgency and suspicious requests.
* Send unrecognized calls to voicemail.
* Pay attention to data breaches and protect your identity.
** Freeze your credit after a breach.
* Learn about compartmentalization and the principle of least privilege.

==== Further reading

. _Personal Cybersecurity: How to Avoid and Recover from Cybercrime_ by Marvin Waschke (https://oreilly.com/library/view/personal-cybersecurity-how/9781484224304/)
. _Personal Privacy Threat Modeling (With LOTS Of Examples)_ by Eliza (https://modernprivatelife.com/how-to-choose-privacy-threat-model/)
. _How I learned to stop worrying (mostly) and love my threat model_ by Sean Gallagher (https://arstechnica.com/information-technology/2017/07/how-i-learned-to-stop-worrying-mostly-and-love-my-threat-model/)

=== Filesystem

(((ZFS)))
ZFS (originally: Zettabyte File System) is our one-stop shop for efficiently and safely making hard drives available for our OS and data.
Encryption, automatic lightweight snapshots and RAID (redundant array of inexpensive disks) are all included and used by _mario_.

The root partition is ext4 (not ZFS) for a few reasons:

* stick as closely as possible to the default Ubuntu install
* sidestep a Docker annoyance
** when `/var/lib/docker` is on ZFS, many Docker-related filesystems are created, cluttering up `zfs list` a bit
* we have less of a need for backups of the OS
** it doesn't/shouldn't change, or at least its changes will be managed upstream (e.g. OS package updates)

Docker volumes will be on ZFS.
The container's filesystem--everything besides mounted volumes with persistent data--is ephemeral and stored on ext4 in `/var/lib/docker`.

==== ZFS trim

(((ZFS, SSD TRIM)))
Note that if you use ZFS with SSDs, you may sometimes notice your system performing poorly.
On my Ubuntu desktop this happens once a month when the scheduled “trim” cron job starts.
Trimming is a process of reclaiming formerly used space on SSDs.
This is not an issue with HDDs.

On my desktop (again: not my server--I use HDDs in that) I see the trim cron job is scheduled for the first Sunday of every month, in `/etc/cron.d/zfsutils-linux`.

The trim job causes high values in `/proc/pressure/io` and I can see `z_trim_*` kernel threads doing heavy I/O in the process table (hint: use `top` or `htop` to view the process table).

It's no big deal and easy to work around.
If you run into this issue, give ZFS a couple hours to finish trimming or run `zpool trim --cancel <pool>`, replacing `<pool>` with the name of the pool being trimmed.
You can get the name of the pool and monitor trim progress with `zpool status -t`.
You can manually resume trimming when convenient with `zpool trim <pool>` or just wait a month for it to run again on its own.

Another approach is to enable `autotrim`.
This performs trimming continuously in smaller increments instead of periodically on an entire pool.
I'm not yet qualified to recommend one over the other.

Shout out to askubuntu post: _Should I turn on zfs-trim on my pools or should I trim on a schedule using systemd timers or cron?_ (https://askubuntu.com/questions/1200172/), too.

==== Further reading

. _Bitrot and atomic COWs: Inside “next-gen” filesystems_ by Jim Salter (https://arstechnica.com/information-technology/2014/01/bitrot-and-atomic-cows-inside-next-gen-filesystems/)
. _ZFS 101—Understanding ZFS storage and performance_ by Jim Salter (https://arstechnica.com/information-technology/2020/05/zfs-101-understanding-zfs-storage-and-performance/)
. _ZFS_ Debian wiki page by various authors (https://wiki.debian.org/ZFS)

If you choose to dig deeper with ((ZFS)), start by reading up on fragmentation, ARC (adaptive replacement cache), resilvering, scrubbing, `ashift`, and `recordsize`.

=== Operating system

_mario_ requires a 64-bit Ubuntu server.
Other Debian Linux flavors may work as well.

Ubuntu LTS (long-term support) releases are the most stable so we'll stick with that.

I sought to minimize customizations to the operating system from a default install to ease its eventual re-creation.
I tried to capture any and all necessary customizations in _mario_, or at least to document them.

Not mucking about on the server takes discipline, especially for old-school hands-on sysadmins like me.
It is much easier to SSH into the server and run a one-off command rather than change config files and re-run _mario_.
The real payoff from using _mario_ instead of hand-editing comes when you collaborate with others or try to remember what you did a year ago and why.

You can and should still SSH into the server manually.
When you do, you should exclusively perform read-only or exceptional read-write operations.
I often do something manually, undo it, then do the same thing with _mario_ to confirm results are as expected.

Example read-only server-side operations:

* show per-container resource usage: `sudo docker stats`
* follow container log messages: `sudo docker-compose logs -f` (run this in a folder containing a `docker-compose.yml` file)
* check server health: `date; tail /proc/pressure/*`

Read-write operations:

* upgrade OS packages: `apt full-upgrade`
* upgrade services: `docker-compose pull && docker-compose up -d` (at least for those not auto-upgraded -- see <<_watchtower>>)

Start a “monthly maintenance” list and include these read-write operations.
Always use `sudo` instead of logging in as the `root` user.
This ensures every command is captured in `/var/log/auth.log` along with when it was executed, and by whom.

Upgrades may be automated.
This is appropriate once you have sufficient scale (along with trust/control of the source of the upgrades).
I choose to do some OS upgrades manually because:

* I manage few systems so the burden is minimal and infrequent
* Upgrading a package may require testing or manual intervention (e.g. rebooting)

These reasons are similar to the reasons I install the OS itself by hand.

My OS is more a pet than cattle (see “cattle vs. pets” in <<_glossary>>), although it is relatively easy to rebuild since I've limited and documented my customizations.

=== Container runtime

We'll use Docker.

TIP: Docker is but one of many valid choices for where to put your services.
More interested in VMs?
That's fine.
Check out VMs especially if you want to self-host Jitsi--I had some issues trying to get Docker to handle the ranges of open ports Jitsi requires.
Kubernetes is fine too.
Try Kubernetes (especially one of the interesting micro-versions) if you are more familiar or interested in that.
I found it to be overkill, personally.
If I needed high availability via clustering I'd be more likely to use Kubernetes.
If one computer in a Kubernetes cluster breaks, services can automatically migrate to working hardware in the cluster.
Regardless of your tech choices, set a clear expectation to your users as to how long your server might be down when something breaks.

Docker balances features and usability well, making it easy to run one service in isolation.
We'll layer on Docker Compose to run the groups of processes necessary to support a whole service (e.g. a web server and its database).
Kubernetes can do this too, along with everything you _don't_ need to learn unless you are building out an entire virtual data center.
Docker compose is a good fit for our single-server setup.

We'll also avoid intermingling services and their dependencies along with everything else on our server's primary storage.
Having everything on one filesystem is easy at first, for one service.
It gets more complicated the more services you add (see https://en.wikipedia.org/wiki/Dependency_hell).
Many of the desperate self-hoster support requests I see in FOSS communities are about incompatibilities between this or that version of PHP or relational database between two different services.
Docker mitigates this by bundling dependencies.
Each Docker image is basically a complete filesystem (sans kernel), so a service's image would include the right PHP version.
Another image would be used to create the database, if/as necessary.

It's worth lingering on bundled dependencies for a minute.
If dependencies are clothes, a Docker container is a suitcase with all the clothes you need for a week's travel.
You check your suitcase and board the train, then rest easy knowing your suitcase is tucked neatly, separately, next to all the others.
Docker containers are suitcases while the old way is everyones' unfolded clothes in a giant pile in the caboose.

Containers are created from images.
An image is the blueprint to magic a fresh new suitcase (container) into existence, all packed and ready with the right clothes for your trip.
An image is built once, stamped with an identifier, and shared, where it can act as the basis for countless consistently-behaving containers.
Unlike suitcases, these containers are practically free.

Images are defined by a config file named `Dockerfile`.
The `Dockerfile` should be tracked in source control.
Since we'll use Docker Compose, another important config file is `docker-compose.yml`.
Each service will have its own `docker-compose.yml` file.
These should be kept in source control too.
For sysadmins these conventions provide reproducible images and containers.
For users: predictable, reliable services.

Practice treating containers as temporary things.
You'll gain confidence in your system by creating and destroying them frequently, and you'll enjoy the speed and ease of doing so.

Think:

* ephemeral
** containers are temporary
** temporary containers provide robust, reproducible services
* cattle, not pets
** hand-managed VMs are burdensome pets
** apologies to the cattle--in this analogy they are expendable
* stateless
** persistent data can and must be defined explicitly
* phoenix server
** a term by Martin Fowler describing the benefits of short-lived servers that can be easily re-created

See: https://martinfowler.com/bliki/PhoenixServer.html.

=== Reverse Proxy

A reverse proxy sits in front of containers and directs traffic to the right service based on arbitrary rules.

// FIXME: do I want to monospace these domain names?

Say you've purchased the domain `example.com` and want to host Nextcloud at `cloud.example.com` and Jellyfin at `media.example.com`. In order to direct incoming traffic to each of these services, your server will need a reverse proxy.

We'll use Traefik as our reverse proxy.

==== Traefik architecture

(((Nextcloud)))
(((Traefik)))
Here's a bit about how Traefik works and how we'll use it with Nextcloud and other web-based self-hosted services.

We want HTTPS requests to port 443 bound for `cloud.example.com` to reach our Nextcloud service.
Study the included Traefik architecture diagram to better understand this process along with the _mario_ sources.

(The diagram is from the MIT-licensed Traefik source code -- https://github.com/traefik/traefik/.
Credit to Peka for the gopher logo, licensed CC-BY-3.0.
For more information see the Traefik `README.md`)

.Traefik architecture diagram showing how a request reaches a service.
image::traefik-architecture.png[]

In the _mario_ source code (or the snippets below), look at the `docker-compose.yml` files for Traefik and Nextcloud, which include:

* the `websecure` entrypoint, where we accept HTTPS traffic on port 443
* the `app` service definition for Nextcloud, which includes Traefik routing labels
* the `Host(...)` rule in the `nextcloud-https` router

The routing labels wire together the entrypoint and router with the service under which they are defined.
That is: `websecure` to `nextcloud-https` to `app`.
(((Let's Encrypt)))
We'll come back to middlewares later, along with other Traefik features like automatic HTTP encryption certificate handling with Let's Encrypt (https://letsencrypt.org).

NOTE: The symbols `app`, `websecure`, and `nextcloud-https` are arbitrary.

These two snippets of the _mario_ source show how we set up Traefik for Nextcloud.

[source,yaml]
----
# snippet from traefik/docker-compose.yml
services:
  reverse-proxy:
    command:
      - --entrypoints.websecure.address=:443 <1>

# snippet from nextcloud/docker-compose.yml
services:
  app:
    labels:
      - "traefik.http.routers.nextcloud-https.entrypoints=websecure" <2>
      - "traefik.http.routers.nextcloud-https.rule=Host(`cloud.example.com`)" <3>
----

<1> Define entrypoint `websecure` on the `reverse-proxy` service, accepting traffic over port 443. HTTPS encryption is configured using other labels.

<2> Connect the `websecure` entrypoint with the `nextcloud-https` router on the `app` service.

<3> Use the hostname rule with the `nextcloud-https` router. I've simulated expansion of the `MARIO_DOMAIN_NAME` variable to `example.com`.

Each self-hosted service will have its own router.
Other web services will also use the `websecure` entrypoint.

=== Identity management

I wanted to include FOSS central identity management in _mario_ but I haven't figured it out yet.
When I do, this should give users a way to log in once and get to all the different _mario_-hosted services.
It takes care of authentication and authorization and all that good stuff.

I'm interested in Authentik (https://goauthentik.io) because it appears to have all the features I want (single sign-on, backend user database, integrates with everything I self-host).
I want to see it running well for a good while before adding it to _mario_.

Some of the other self-hosting solutions mentioned above in <<_what_is_this_book_not>> do include FOSS central identity management.

== Implementation

=== Service plan

==== Choose services

A service is something useful you'll self-host.
These are typically one or more containers.
Services may be accessed from a web browser or mobile device, or they may simply run in the background on a schedule.

===== Good for self-hosting

You'll find some services are better choices to self-host than others.
They will likely share at least some of these attributes:

* Self-hosting instructions available.
* Easy to install. Works with your preferred deployment method.
** For _mario_, we're looking for a popular, well-maintained Docker image.
** Bonus: instructions included for integrating with Docker Compose and Traefik.
* Healthy community: chat, forum.
* Recent source code activity: releases, contributions, news.
* Uses a FOSS software license.
* Transparent about owners and sponsors.
* Public roadmap, issue tracking, continuous integration, working demo, build scripts, bug/security bounties.
* Issue tracker already includes an issue you're aware of.
* Well-organized, elegant code.
* Useful and up-to-date documentation.
* Mentions and compares the service with other similar services.
* Well-documented, useful, and complete API.
* Flexible and extensible (easy to customize and extend with plugins and such).

(((Nextcloud)))
Nextcloud (https://nextcloud.com) has many of these, with some exceptions.
One exception is their secret build script (https://help.nextcloud.com/t/build-bzip-and-package-from-git/58341).
This is convenient for them to maintain control of a complex system, but worse for eventual succession.
Nextcloud is a fork of ownCloud, after all.
We should expect another fork and be prepared for it.

The sprawling complexity is also risky.
“Nextcloud” is not one thing, it is a collection of _many_ software projects and services under various degrees of control by a single company.
Forking would be costly and time-consuming, and even switching forks might be complex.

===== Bad for self-hosting

Here are some reasons you may want to reject a service:

* Your users don't want it or won't use it.
* Unpopular, inactive, or poorly maintained.
** Few maintainers / contributors.
** Maintainers are inattentive to contributors.
* Includes telemetry (“phones home”, collects “statistics” or “usage data”), especially without your consent and/or enabled by default.
* Confusing or opaque governance, roadmap, licensing, source control, contribution intake, issue tracking.
* Sprawling complexity.
* Difficult to fork.
* Only geared towards enterprise: self-hosting instructions are complex or missing entirely.
* Constant annoying upsells/nags.
* Intentional vendor lock-in: monopolistic tendencies or use of closed/proprietary standards/services.
* Open core (https://en.wikipedia.org/wiki/Open-core_model).

Habitica (https://habitica.com) demonstrates several of these.

==== Map services to resources

Here's an early, rough resource planning table I used.
I go into detail about some of these services later in the book.

[%header]
|===
|Service |Purpose |Isolation |Cores |RAM (GB)
|jellyfin |streaming music |Docker |2 |2
|kahoot-clone |quiz game |Docker |0 |0
|poller |polls |Docker |0 |0
|backuppc |backups |none |0 |0
|taskd |task tracking |Docker |0 |0
|sftp |file transfers |none |0 |0
|syncthing |file sync |none |1 |1
|nextcloud |file sharing |Docker |2 |2
|minetest |game server |Docker |4 |8
|irssi |chat client |none |0 |0
|jitsi |video calls |Docker |2 |2
|wallabag |article saver |Docker |1 |1
|===

“Cores” represents relative peak compute requirements.
RAM: peak memory.
These were fairly wild guesses, based as much as possible on published documentation.
The guesses turned out to be accurate enough.
I could see right quick I'd need something more powerful than the latest available Raspberry Pi.
See <<_server>> for more lessons learned about resource requirements.

=== Prepare hardware

It's called _hard_ ware because these problems are _hard_.

That's fun to say and, in my experience, false.

It's true there is a learning curve for understanding basic computer hardware components, but it is also tangible and behaves consistently, more or less.

Software problems easily and often outpace hardware problems.

==== Server

You'll need a server.

You could use a VM in someone else's cloud, but it'll end up costing more.
For that and other various reasons I'll focus on bare metal.

You can start with pretty much any old desktop or laptop.
Use something more powerful and expandable than a Raspberry Pi, though.
What if your users love it.
What about bursty workloads.
Adding storage later.
If you start with something too small you won't have enough speed nor expandability.

I've worked with quite a few different servers and I did my homework for this self-hosting adventure, so I had a decent idea of what I wanted.

I chose something powerful, cheap, and fast with plenty of storage and room to grow.
I sought professional commodity hardware for its replace-ability.
It can handle a reasonable amount of bursty compute needs, including building Docker images, flurries of user activity, and some generative ((AI)) (even without a GPU).

I found a used refurbished 1U rackmount server on eBay for about $1,000.
Two 24-core CPUs and 128 GB RAM.
Tech companies dump these by the truckload so you can usually find a good deal.

.DIY rackmount server attached to garage ceiling. It's fun to look at and is out of the way, but I need a ladder for maintenance and it weighs about 50lbs.
image::racked-server.jpg[]

The fans are *way* louder than a desktop, especially when it is under load.
It is supposed to have decent ventilation, temperature and humidity regulation yet has so far been extremely hardy even below freezing and above 100°F for extended periods of time.
It has several enterprise features to ease maintenance such as redundant power supplies, hot-swap drive bays, lots of sensors, and remote management via a web browser or IPMI.

Power consumption averages 130W, or about 1,140kWh per year; roughly $138.15 in Seattle.
That's about as much as a bright incandescent light bulb, and it's a bit wasteful for one user.
Five users though? ~228kWh/year each.
That's less than the cloud server hardware required for a mobile device making use of Google's or Apple's clouds.
Further reading on this topic:

. _The Surprisingly Large Energy Footprint of the Digital Economy_ by Bryan Walsh (https://science.time.com/2013/08/14/power-drain-the-digital-cloud-is-using-more-energy-than-you-think/)
. _The spiralling energy consumption behind your smart phone_ by Betsy Reed (https://theguardian.com/sustainable-business/2014/sep/10/energy-consumption-behind-smart-phone)
. _The secret energy impact of your phone_ by Owen Williams (https://increment.com/energy-environment/the-secret-energy-impact-of-your-phone/)

A rackmount server like mine can handle far more than 5 users, assuming they aren't all trying to transcode video.

It also makes a great heated perch.

.Bird perched on server.
image::bird-on-server.jpg[align="center",scaledwidth=50%]

==== Admin computer

(((provision)))
It's helpful to have a separate computer from your server to make changes.
I usually run _mario_ on a laptop.
This provisions my remote server, making changes as necessary to align it with the Ansible configuration files.

==== Test devices

Your users will have their own computers and mobile devices (their _clients_).
You should have a couple different clients of your own, so you have comparable environments to better help your users.

You should also be a user of the stuff you self-host.
This is _dogfooding_.
Dogfooding keeps you honest and helps you empathize with others.

==== Hard drives

(((ZFS, HDDs and)))
I use HDDs (hard disk drives) for data storage, mainly as a cost-saving measure.
The cost of public cloud block storage far exceeds the gigabyte-hour cost of my HDDs.
I priced out one month of 5TB HDD block storage on AWS at $228.10.
With ZFS I'm also taking a snapshot (bascially a full local backup) _every 15 minutes_.
One month's worth of hourly snapshots (the closest comparable I could find) is another $310.68 on AWS.
That's $535.67 total, which is about what I spent on my drives.
So I broke even in a month and the drives should last _years_.

For redundancy I recommend purchasing two of the same drive.
We'll configure them mirrored (RAID 1).
This increases redundancy and read performance (for most reads) and halves usable storage space.

HDDs are plenty fast when measured from the standpoint of self-hosted service response time.
The OS (operating system) and services do well at caching data served, assuming the server has sufficient RAM.
Remote backups can take a while, and that's fine.

I use one SSD (solid-state drive) for the OS and everything besides my photos/documents/etc, since start-up time for the OS is important and realizes far less benefit from the OS filesystem cache (especially at boot time).

Read more about SSDs and TRIM in <<Filesystem>>.

==== Networking

If you are hosting at home, you need a reliable WAN (wide-area network) connection if you want to be able to connect from other places besides your LAN.

Use wired ethernet cables to your server, not Wi-Fi.

===== Minimum specs

Here are some typical minimum specs for a home:

* 100mbps up / 100mbps down ISP connection
* Cat 5 ethernet cable
* 802.11ac Wi-Fi (for clients)

I just made these up based on what I estimated I'd need, then doubled that to allow some room to grow.

===== Home router configuration

Learn how to configure your router.
Keep it up to date and maintain a strict firewall with only the necessary ports open / forwarded.

CAUTION: Port-forwarding allows inbound connections through your WAN boundary to your server.
Read <<Digital security>> before forwarding any ports.

Here's a simple diagram I created using https://asciiflow.com to visualize my server's location and network connection, a “WAN into LAN traffic flow diagram”.
The router provides electricity to the mini switch using PoE (power over ethernet).
There server has two NICs (network interface cards): one is for the OS and everything within (including all services), the other provides a network connection to the embedded OOB (out-of-band) remote management computer with IPMI (Intelligent Platform Management Interface).
All arrows are ethernet cable.

.WAN into LAN traffic flow diagram.
image::WAN-to-LAN-traffic.svg[align="center",scaledwidth=80%]

==== Electricity

Use a surge protector.

Also consider a UPS (uninterruptible power supply) if your power at home is unreliable.

==== Physical security

Keep your server safe similar to other valuables in your home.

At the very least, restrict physical access.

=== Deploy

(((provision)))
Here's an abbreviated server setup guide.
It's a good idea to think ahead to disaster recovery: take notes and visualize yourself repeating the process precisely.
At each prompt, accept the default or write down your choice.

. Install Ubuntu Server. Debian might also work; I haven't tested it.
.. Use the latest LTS release, e.g. 64-bit Ubuntu 22.04 LTS server. Tutorial: https://ubuntu.com/tutorials/install-ubuntu-server.
.. Optional: use full-disk encryption. See <<_full_disk_encryption>>.
.. Install OpenSSH server.
.. Do not install `nextcloud` or `Docker`. Let _mario_ install these later.
. Optional: add two HDDs and format them with ((ZFS)). See <<_zfs>>.
. Set up _mario_ on your admin computer (a separate computer from your server).
. Run _mario_ on your admin computer to provision your server.

==== Full-disk encryption

(((encryption, full-disk)))
Encrypting prevents data recovery by an attacker.
You'll have to enter a password on boot, though.
This is inconvenient if you have intermittent power and/or no remote management capability.
There's also the reasonable argument that full-disk or “at-rest” encryption offers little for an always-on server: during normal operation you've already supplied the decryption key.

If you decide you want full-disk encryption, choose it during the OS install. <<Digital security>> is helpful for deciding whether or not to encrypt.

==== ZFS

(((ZFS, setup)))
The OS takes care of itself pretty well.
For more robust data storage, we can a couple of HDDs and manage them with ZFS.

ZFS adds many features and some complexity.
The learning curve is worth it.
We'll start with a simple mirrored 2-drive pool.

On the server, run these commands as root, adjusting as necessary.
For example, these assume you've added two drives and they were assigned device names `/dev/sda` and `/dev/sdb`.
Use `lsblk` to figure out your device names.

[%linenums,bash]
----
# Create partition tables.
parted /dev/sdb print
parted /dev/sdb mklabel gpt
parted /dev/sdc print
parted /dev/sdc mklabel gpt

# Create ZFS main mirrored pool and set attributes (for all future datasets in this pool).
zpool create -o ashift=12 -O mountpoint=none main mirror /dev/sdb /dev/sdc
# For performance.
zfs set atime=off main
# To save space.
zfs set compression=on main
# For security.
zfs set exec=off main
zfs set setuid=off main
zfs set canmount=off main

# Create encrypted dataset in "main" pool. This is our "parent" dataset, we can easily add more later and they'll all be encrypted.
openssl rand -base64 32 > /root/secure-dataset-key
zfs create -o encryption=aes-128-gcm -o keyformat=passphrase -o keylocation=file:///root/secure-dataset-key main/secure
zfs set canmount=off main/secure

# Create dataset we'll actually use.
zfs create -o mountpoint=/data main/secure/default

# This might not be necessary if you _never_ want to execute anything in /data. I found I needed it for something within a container (ffmpeg, I think). You can start with exec=off and turn it on later if you want.
zfs set exec=on data/secure/default

# Examine pools.
zpool status
zpool list

# Examine datasets.
zfs list

# Show I/O stats.
zpool iostat
----

=== Server maintenance

I use short monthly and yearly maintenance checklists. For example, monthly I might:

* [x] upgrade OS packages
* [x] check storage space remaining
* [x] back up router config

And yearly:

* [x] test restore from backup
* [x] review and improve ((threat model))
* [x] open server chassis and vacuum dead spiders

I update my checklists about as often as I use them.

The following sections cover specific maintenance tips and tricks.

==== Hardware

Plan on hardware failure.

If you can afford it, the easiest way to reliably run one server is two _buy two identical servers_.
Use the second for parts or a ready as-is replacement machine (also called a “cold spare”).

==== OS updates

Keep OS packages and container images up to date.
For the OS:

[source,bash]
----
sudo apt update && sudo apt full-upgrade
----

Reboot when necessary (e.g. when the kernel is upgraded).

==== Image updates

I keep container images up to date with Watchtower or by hand, with:

[source,bash]
----
sudo docker-compose pull
----

Or, if a service uses a locally-built image:

[source,bash]
----
sudo docker-compose build --pull
----

This is the case if a `docker-compose.yml` file includes a `build` directive instead of declaring an `image`.
The Scratch service included with _mario_ is one example.

==== Monitoring

Monitor server health.

Check free disk space with `df -h`.

If things feel slow, check PSI (pressure stall information) with

[source,bash]
----
tail /proc/pressure/*
----

`atop` will also show PSI values.
Read more about PSI at https://kernel.org/doc/html/latest/accounting/psi.html.

If your PSI check shows high I/O, try `docker stats` to see resource usage per container.

That should help you narrow down resource issues to specific containers.

At the host level, you can use `htop -d 100` to see stats for all processes and threads.
Follow all logged events for the host with `journalctl -f`.

==== Backups

Backups are one critically important thing you'll rarely get credit for, only suffering when they fail.

Make backups and test them.
Follow the 3-2-1 rule of thumb: make *3* backups.
Store at least *2* local copies on different media.
Have *1* remote backup.

_Test_ the backups regularly.

(((ZFS, snapshots)))
Make consistent point-in-time backups of everything on your server, such that the services running are unaware they are even being backed up.
For example: create a ZFS snapshot and back _that_ up.

NOTE: Backing up using ZFS snapshots _can_ still cause problems.
For example, ZFS can't guarantee the state of backed-up data for running programs.
Say you restored a MariaDB database from backup.
Unless you flushed and locked tables before taking that ZFS snapshot, MariaDB might have been in the middle of a write operation.
It would need to recover, and the data it was trying to write may be lost.
This manner of data loss is rare, and the risk is acceptable for the typical homelab.

I recommend restic (https://restic.net) or Borg (https://borgbackup.org).

Here's a decent comparison of restic and Borg: https://reddit.com/r/BorgBackup/comments/v3bwfg/.

I use `zfs-auto-snapshot` locally to be able to quickly get at old versions of files, but I don't count this as a backup.

== _mario_

//
// I think asciidoctor-epub3 complains about italics in these two _mario_ headers. I ignore this. It looks like:
//   Converting to Mobi (kf8)...
//   bundle exec asciidoctor-epub3 --attribute revnumber='1.0.1' --attribute revdate='2023-11-16' -a ebook-format=kf8 shb.asciidoc
//   asciidoctor: WARNING: Warning(inputpreprocessor):W29006: Tag rejected: <em>
//   asciidoctor: WARNING: Warning(inputpreprocessor):W29006: Tag rejected: </em>
//
// I'm not certain this is true... other headers have italics but I only see these two warnings from asciidoctor-epub3. 
//

Once our server is online, we can use _mario_ to configure and stand up services.

=== _mario_ philosophy

_mario_ is a practical learning tool.
It comes with sensible, tested defaults.
It automates some of the tedious, confusing steps of setting up services on a server. _mario_ is not a supported and production-ready polished software product.
It'll get you started, that's it.
Continue with it if you like or just use it to fast-forward your personal cloud setup.
Something else does or will do its job better.
Here are some suggestions to get the most out of _mario_.

The first time you run _mario_, follow the instructions as closely as possible.
Many assumptions are made so it works “out of the box”, and it is meant to be easily customizable.

_mario_ configuration files are declarative.
You write out the _state_ you want your server to end up at, not all the commands you'd run on a command line to achieve the same state. _mario_ runs Ansible, and Ansible runs the commands for you on the server (like running `chmod` on a file) in a predictable and repeatable manner.
The desired end state, as declared in the configuration files, is reached and confirmed by Ansible.

(((provision)))
After getting _mario_ up and running successfully once, run it again.
Provisioning with _mario_ is ((idempotent)).
The system should not change in any meaningful way after the desired state is reached.
Once `provision.sh` completes successfully, it may be run again without making further changes.

Then: start tinkering.
You can find some ideas in <<_exercises>>.

You may want to first provision a virtual machine until you're ready to run _mario_ pointed at your real server.

=== Conventions

_mario_ prepares the server filesystem as follows:

* Docker configuration files are stored in directories under `/root/ops`.
* Data for services are stored in directories under `/data`.

=== Usage

Go ahead and run `provision.sh`.
On your admin computer:

[source,bash]
----
cd mario/ansible
./provision.sh
----

On this first invocation, it will check for prerequisites, then prompt you to enter values specific to your server into a configuration file.

....
You don't have a config file. I'll create one for you now.

Please edit 'config' and re-run this script.
....

Do this.

==== Domain name

Buy a domain name from a registrar.
A registered domain name is required for HTTPS web traffic encryption.

==== Public DNS

(((Duck DNS)))
_mario_ expects to be able to use Duck DNS or Amazon Route 53 for DNS.
Support for other DNS providers (ahem, especially self-hosted ones!) may be added later.

Of the two options I provide, Duck DNS is the easiest and cheapest.

===== Duck DNS

. Start at https://duckdns.org.
. Log in and add a domain.

===== Amazon Route 53

If you choose Route 53, create a new hosted zone with the domain name you own.
Make note of the Route 53 name servers.
Back at your registrar, input these name servers.

On Amazon IAM, create a user with permission to update this hosted zone.
Here's a policy with way too much access that nevertheless works:

[source,json]
----
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": "route53:*",
      "Resource": "*"
    }
  ]
}
----

==== Internal DNS

It is handy to have an _internal_ DNS server in addition to a public one (e.g. Route 53).

Inside your private network you can use handy domain names or even make up your own TLD (top-level domain).
I recommend using internal hostnames matching public ones, but pointing to LAN-only private IP addresses.
For example:

[%header]
|===
|Service |Hostname |Public IP |Internal IP
|Nextcloud |cloud.example.com |175.102.205.1 |10.0.0.5
|Jellyfin |media.example.com |175.102.205.1 |10.0.0.5
|Wallabag |read.example.com |175.102.205.1 |10.0.0.5
|===

IP addresses can be repeated because our reverse proxy will direct traffic based on hostname.

If you don't have a DNS server yet, use hostname to IP address mappings in `/etc/hosts` or similar while you are getting started.

==== Connect to server

_mario_ expects to be able to connect directly to the server using SSH.
Public key authentication eases this.
If you have a key pair, use it.
If you need a key pair, run `ssh-keygen` or similar on your admin computer to create one.
Copy the public key to the server with `ssh-copy-id` or similar.

Use a stanza like this in your SSH client config:

....
Host mario_server
  HostName console.example.com
  User your-username
....

(((provision)))
Test it by running `provision.sh` again.

IMPORTANT: _mario_ not only encourages you to use public key authentication for remote SSH connections, it forcibly disables password-based SSH authentication on its first run.
If you want to be able to log in remotely with a password, delete the related task from `roles/base/tasks/main.yml`.
If you already successfully ran _mario_ once and want to re-enable password-based SSH auth, delete that task *and* delete the file `/etc/ssh/sshd_config.d/disable-ssh-password-auth` on your server.

Note that `mario/ansible/hosts.yml` (created by `provision.sh`) includes a place for you to enter a plaintext password value for `ansible_become_password`. _mario_ needs this on its first run, prior to setting up passwordless sudo.

If you don't want to type the password into `hosts.yml`, comment out `ansible_become_password` and run this (after following all other instructions in `provision.sh`):

[source,bash]
----
source config
ansible-playbook --ask-become-pass playbook.yml
----

You should only have to do this once.
If it succeeds, you can go back to using `provision.sh`.

Another security improvement (left as an exercise for the reader) is to move secrets from `config` into an Ansible vault.

==== Stand up services

_mario_ has prepared your server to run a handful of services.
Here's how to turn them on and start using them.

===== Start reverse proxy

We'll stand up the reverse proxy first.

Start Traefik with:

[source,bash]
----
sudo docker-compose --file /root/ops/traefik/docker-compose.yml up -d
----

If that worked, wait a minute or two and visit `\https://traefik.MARIO_DOMAIN_NAME` in a web browser.
(((Let's Encrypt)))
It may take a few minutes for Traefik to set up Let's Encrypt HTTP encryption certificates, so don't worry if you get invalid cert warnings at first.

You can tail the logs with:

[source,bash]
----
sudo docker-compose --file /root/ops/traefik/docker-compose.yml logs -f
----

You should see something like this for a working Traefik service:

[%linenums,text]
----
Attaching to traefik_reverse-proxy_1
reverse-proxy_1  | time="2023-05-09T18:53:41Z" level=info msg="Configuration loaded from flags."
reverse-proxy_1  | time="2023-05-09T18:53:41Z" level=info msg="Traefik version 2.10.1 built on 2023-04-27T14:52:35Z"
reverse-proxy_1  | time="2023-05-09T18:53:41Z" level=info msg="\nStats collection is disabled.\nHelp us improve Traefik by turning this feature on :)\nMore details on: https://doc.traefik.io/traefik/contributing/data-collection/\n"
reverse-proxy_1  | time="2023-05-09T18:53:41Z" level=info msg="Starting provider aggregator aggregator.ProviderAggregator"
reverse-proxy_1  | time="2023-05-09T18:53:41Z" level=info msg="Starting provider *traefik.Provider"
reverse-proxy_1  | time="2023-05-09T18:53:41Z" level=info msg="Starting provider *docker.Provider"
reverse-proxy_1  | time="2023-05-09T18:53:41Z" level=info msg="Starting provider *acme.ChallengeTLSALPN"
reverse-proxy_1  | time="2023-05-09T18:53:41Z" level=info msg="Starting provider *acme.Provider"
reverse-proxy_1  | time="2023-05-09T18:53:41Z" level=info msg="Testing certificate renew..." ACME CA="https://acme-v02.api.letsencrypt.org/directory" providerName=myresolver.acme
----

===== Start other services

Starting a _mario_ service is always done with `docker-compose up`.
See the “Setup” section of a particular service for more detail.

To stand up everything at once, you could use this shell script:

[source,bash]
----
services="watchtower dyndns mail wallabag jellyfin nextcloud scratch"
for svc in $services; do
    sudo docker-compose --file /root/ops/$svc/docker-compose.yml up -d
done
----

This will also pull and build images and update containers as necessary.

==== Check logs

Examine logs for any service with `docker-compose logs`.

Example shell commands:

[source,bash]
----
# follow Traefik logs
sudo docker-compose --file /root/ops/traefik/docker-compose.yml logs -f

# page watchtower log output through `less` (with color)
sudo docker-compose --file /root/ops/watchtower/docker-compose.yml logs | less -R
----

=== Encryption certificates

_mario_ (well, Traefik) sets up certificates to encrypt HTTP traffic.
The certificates are issued using a DNS challenge (https://doc.traefik.io/traefik/https/acme/#dnschallenge).
The DNS challenge is especially handy for servers with zero public-facing inbound ports.
There are other challenge types documented at https://letsencrypt.org/docs/challenge-types/.

If you see certificate errors, confirm DNS works (externally and internally).
Also: examine Traefik logs as indicated in <<Start reverse proxy>>.
You can increase the Traefik log verbosity by setting `--log.level=DEBUG` in `roles/services/templates/ops/traefik/docker-compose.yml` and re-provisioning.

Finally, try restarting Traefik with `sudo docker-compose --file /root/ops/traefik/docker-compose.yml restart`.
That particularly seems to help the first time I stand up a new service.

=== Tiny test service

How about a little tinkering.
Standing up a test service is easy.
This is useful to confirm networking is functional for Docker containers running on your host.

This service demonstrates pinging a public server.
On _your_ server, create the folder `~/ping`.
Create a file `docker-compose.yml` in that folder, containing:

[source,yaml]
----
version: '3'

services:
  test:
    image: alpine
    command: ping example.com
----

In the folder `~/ping/`, run the command `sudo docker-compose up`.
Hit kbd:[Ctrl+c] after a few seconds.
You should see something like this:

....
$ sudo docker-compose up
Creating network "ping_default" with the default driver
Creating ping_test_1 ... done
Attaching to ping_test_1
test_1  | PING example.com (93.184.216.34): 56 data bytes
test_1  | 64 bytes from 93.184.216.34: seq=0 ttl=55 time=3.477 ms
test_1  | 64 bytes from 93.184.216.34: seq=1 ttl=55 time=3.236 ms
test_1  | 64 bytes from 93.184.216.34: seq=2 ttl=55 time=3.363 ms
^CGracefully stopping... (press Ctrl+C again to force)
Stopping ping_test_1   ... done
....

This is the basis for adding more interesting services, too.
It's only a few more lines of code+config to create a small API or web service and a few more to publish it with your reverse proxy.

== Services

Here are details of self-hosting a handful of useful services.

The services I'll highlight are a tiny fraction of those available to self-host.
They reflect my users' preferences (including and over-indexed to my own) in reading, sharing, media, and so on.
Getting them running will provide some useful functionality and a good starting point.
With the help of _mario_ your cloud gets these out of the box and will be flexible enough to accommodate your preferred service choices.

These particular services--while all reasonable choices to make your data useful--may not be the best available choices nor the best fits for your use case.
That is absolutely fine!
Plan to add and remove services as desired and as time passes.

If I link to a bug that is closed in an issue tracker, it's because I have tested and, at the time of writing, I'm still experiencing the bug in an official/supported release that is supposed to have the fix.

Note that _mario_ blocks WAN access by default.
Read <<Digital security>> to decide if you want this or not.
You may remove this protection by removing the `lan-only` middleware from the corresponding router's Traefik label.
For example, to allow WAN access to Nextcloud, make this change:

[%linenums%unbreakable,diff]
----
- traefik.http.routers.nextcloud-https.middlewares=nextcloud_headers,nextcloud_redirect,lan-only
+ traefik.http.routers.nextcloud-https.middlewares=nextcloud_headers,nextcloud_redirect
----

To allow WAN access to Jellyfin, delete the whole line referencing the `lan-only` middleware.

=== Nextcloud

(((Nextcloud, overview)))
Nextcloud is primarily a cloud “drive” for file storage and sharing.

Nextcloud is daunting to self-host.
With _mario_, it is of course easy and fun.
Done well, it serves as a solid foothold for de-Googling.

Nextcloud can be self-hosted for free when installed via _mario_.

==== Base install

(((Nextcloud, install)))
A basic Nextcloud install is focused on remote file management (storage, organization, and sharing).
It keeps track of actual files and folders stored somewhere (local, remote, cloud, wherever) and tracks additional metadata about those files and folders in a database.
You access it via a web browser and there is a desktop client to sync files locally, very much like Dropbox, Google Drive, and OneDrive.

I've come to _really_ trust desktop file sync.
If I see a check mark on my desktop app, I know everything is properly synchronized with the server.
I am constantly creating and editing content locally and counting on sync to work (usually on my desktop computer), or creating and editing directly in Nextcloud via the web UI.

There are also apps for mobile devices.
I'll come back to mobile later in the following sections.

==== Security

(((Nextcloud, security)))
A basic Nextcloud install appears to have excellent security.
The source is in heavy use and is backed by a solid company with a reputation that depends on their commitment to security.
They make it easy to lock down and vet (it is FOSS after all).
The defaults appear secure.
They follow best practices.
They have a public bounty program and threat model.

==== Setup

(((Nextcloud, install)))
Setting up a new Nextcloud server is well-documented.
In brief:

. Provision with _mario_.
. Start Nextcloud containers with `sudo docker-compose --file /root/ops/nextcloud/docker-compose.yml up -d`.
. Navigate to `\https://cloud.MARIO_DOMAIN_NAME`
. Follow web-based setup page to create an admin account.
. Skip installing recommended apps.

Done.
You should be redirected to the dashboard and a short intro video.

Some tips:

* Stand up, destroy, and stand up again.
** After you get it working once, stop it with `sudo docker-compose --file /root/ops/nextcloud/docker-compose.yml down`.
** Destroy all persistent data with `sudo rm -rf /data/nextcloud`. That _really_ deletes everything.
** Re-provision with _mario_ (run `provision.sh` again).
** Follow the setup steps above.
* Read the official docs at `\https://cloud.MARIO_DOMAIN_NAME/settings/help` or https://docs.nextcloud.com.
* Add apps. See <<_customization>> for tips on how to roll out apps thoughtfully and which ones are worth your time.
* Test sending an email at `/settings/admin` (Basic settings).
* Add users.
* Check logs.
** Traefik.
** Containers.
** Nextcloud server log at `/settings/admin/logging` in the web UI or `/data/nextcloud/root/data/nextcloud.log` on the server.
* Some maintenance requires the `occ` tool (short for “ownCloud command”).
** Run it with `sudo docker exec --interactive --user www-data nextcloud_app_1 php occ`.
* Add `/data/tmp-video` as an External storage. Media files uploaded there will automatically appear in Jellyfin.
** Folder name: Temp Video
** External storage: Local
** Authentication: None
** Configuration: `/data/tmp-video`
** set users, previews, sharing, and remaining options as desired

==== Maintenance notes

* upgrades
** change the version number in `roles/services/templates/ops/nextcloud/docker-compose.yml`
** re-provision from admin computer
** replace containers on the host with `sudo docker-compose --file /root/ops/nextcloud/docker-compose.yml up -d`
* check the `/settings/admin/overview` page
** `occ db:add-missing-indices`
** `occ dav:sync-system-addressbook`
* tail logs
** `lnav` is helpful for this: https://lnav.org

===== Release cadence

(((Nextcloud, release cadence)))
A new stable release is shipped every four months.
These releases are scheduled, so a major version change might _not_ break backwards compatibility.

* https://docs.nextcloud.com/server/stable/admin_manual/release_schedule.html

Be sure to check your `/settings/admin/overview` page before upgrading to make sure all the apps you use will work with the version you're upgrading to.
You can override an out-of-date app with the “enable untested app” option under `/settings/apps`.
Sometimes this works.

I started a thread about Nextcloud's release cadence at https://help.nextcloud.com/t/major-release-cadence/161685.

==== Performance

If you use _mario_ to deploy Nextcloud, you'll start with a nominally performant server.
I've included the most important steps from their server tuning guide (https://docs.nextcloud.com/server/stable/admin_manual/installation/server_tuning.html).

Troubleshooting performance issues can be challenging.
An issue about mounts (https://github.com/nextcloud/server/issues/35311) had me under the hood with MariaDB for a while.
They've since fixed the root cause (https://github.com/nextcloud/server/pull/33540) so it isn't a problem for new installations.

==== Customization

(((Nextcloud, apps)))
Nextcloud can be used as-is or heavily customized.

The simplest and safest way to customize is via their app store, especially if an app is marked “featured”.

These _Nextcloud apps_ are installed on the server, expanding the functionality a base Nextcloud instance.

Here are some Nextcloud apps I've tried, what they do, and a ruling on whether they're worth looking into.
Read “Worth your time?” as “Adam maybe tried this app and has shared his opinion whether others will find this particular app worth the effort to learn and maintain, based on his own experiences projected onto our possibly different use cases.”
Grain of salt, in other words.
When in doubt: start small (default Nextcloud install), and roll these out thoughtfully if you do at all.

[%header,cols="1,1,2"]
|===
|Nextcloud App |Purpose |Worth your time?
|Antivirus for files |virus scan uploads |*Yes*. Note: uploads from desktop clients are not scanned for viruses (https://github.com/nextcloud/files_antivirus/issues/219)
|Analytics |track and graph metrics |*Yes*. Only for small/simple use cases though.
|Appointments |easy 3rd party scheduling |*Yes*. Requires careful calendar curation. Somewhat fiddly setup.
|Calendar |manage meetings and appointments |*Yes*.
|Cookbook |recipe manager |*Yes*. Great at importing from web pages (thanks to standardized recipe data already present in HTML source). I wish it were better at printing/exporting though.
|Contacts |address book |*Yes*.
|Dashboard |various widgets on a page |*No*. I like to go right to my files.
|Deck |kanban board |*No opinion*. I tried it a little and it worked, I just don't use kanban much.
|Draw.io |diagram editor |*Yes*.
|Duplicate Finder |find and cull duplicate files |*No*. Slow and opaque. I recommend rdfind instead (https://github.com/pauldreik/rdfind).
|Electronic Signatures |e-sign documents |*No*. Requires a 3rd party service. It should work locally and just help folks fill in documents with signatures, dates, text, etc.
|End-to-End Encryption |encrypt files server-side, decrypt with client |*No*. Unnervingly buggy. Confusing UI/UX.
|Files |file management, sharing |*Yes*, although the “Versions” tab is not very useful.
|Forms |Google Forms alternative |*Yes*.
|Full text search |search through all documents |*Maybe*. Fast. Buggy. Likely dormant project.
|Holiday Calendars |easily add public holiday calendars |*Yes*. The config for this app shows up under “Personal” -> “Availability” for me, not “Groupware” (although the URL path is `/settings/user/groupware`).
|Maps |maps and directions |*Yes*. Grab a cup of tea if you have lots of photos with GPS coordinate metadata.
|Mail |email |*No opinion*. I tried it briefly and it choked on my bazillion Gmail messages. And yeah, I want to de-Gmail someday.
|Memories |photos |*Yes*.
|News |track blogs and news via rss/atom feeds |*Yes*.
|Nextcloud Office |edit spreadsheets, slides, etc. |*Yes*. I don't love this but I need it. Maybe that's a “No”? Mobile apps for this are painful.
|Notes |simple markdown-based note taking |*Yes*. There's an excellent companion mobile app. Replaced Google Notes for me.
|Passwords |password manager |*Yes*.
|PhoneTrack |location sharing and tracking |*Yes*. UI is feature-rich and complicated. Traveled movement lines are cool.
|Photos |photos, sorta |*No*. Slow, clumsy, lacking features compared with other FOSS photo management software. Note that it is required by Memories. I do install it just so I can use Memories.
|Polls |simple polls |*Yes*.
|Ransomware protection |warns for bad file names on upload |*No*. Too many false positives. Unmaintained.
|Recognize |face recognition |*No*.
|Suspicious login |warn about suspicious IPs |*No*. Too many false positives.
|Tasks |tasks/todos |*Yes*.
|Talk |video and text chat |*No*. Works, just slower and not as well as other video and text chat services/apps. This is a very competitive and crowded space. I recommend Signal instead (https://signal.org).
|Temporary files lock |avoid edit conflicts |*Yes*.
|Text |edit text documents |*Yes*. I'm a huge fan of Markdown plain text documents, and Nextcloud handles these well. It has a nice web-based collaborative editor. I like pasting in rich text and letting the editor auto-convert it to Markdown.
|Video converter |transcode videos |*No*. Cool idea but the project appears dormant.
|===

==== Talk High Performance Backend

(((Nextcloud, Talk)))
I haven't yet tried Talk with the High Performance Backend because I don't have dozens of users.

* https://nextcloud-talk.readthedocs.io/en/latest/scalability/

The AIO installer includes the strukturag/nextcloud-spreed-signaling implementation, which is likely to be the “official” one (I don't know for sure).

* <<AIO installer>>
* https://github.com/strukturag/nextcloud-spreed-signaling

==== Full text search

(((Nextcloud, search)))
This app allows you to search through all content of all documents on your server.
The search syntax is hard to get right.
It uses a lot of CPU and is memory-hungry too.

* https://github.com/nextcloud/fulltextsearch/issues/601

The GitHub project repositories are pretty quiet.

* https://github.com/nextcloud/fulltextsearch/pulse
* https://github.com/nextcloud/files_fulltextsearch/pulse
* https://github.com/nextcloud/fulltextsearch_elasticsearch/pulse

==== Mobile

(((Nextcloud, mobile)))
Nextcloud works OK as the backend for a mobile device.
It can be your single reliable source of truth for contacts, calendars, tasks, and most everything else that matters on mobile.
You can open files and edit them, but the UI/UX is bad.
See <<_mobile_text_editing_is_hard>> for a couple workarounds.

I had a Murena Samsung S9+ phone (https://murena.com) running /e/ OS for a while.
I loved it.
Easy to set up with Nextcloud and worked quite well.
Unfortunately, T-Mobile started requiring VoLTE so I had to switch back to Samsung's Android because /e/ OS does not support VoLTE.

(((FOSS)))
Murena rescued me in 2023 when they started shipping the Fairphone 4 to the USA. /e/ OS is up to date with the latest upstream Android code and once again provides a good deal more FOSS-friendliness, privacy, and native Nextcloud integration than other Android-based mobile operating systems.
Works with T-Mobile USA 5G, VoLTE, and Wi-Fi calling. 5 years of support.

==== Other mobile apps

Besides the primary mobile app (called simply “Nextcloud”), there are other mobile apps made to work with Nextcloud apps.
Here are the ones I recommend.
I don't have an iPhone so these are only Android apps.

[%header]
|===
|Mobile app |Works with Nextcloud apps |More info
|DAVx5 |Calendar, Contacts, Tasks |https://davx5.com
|Maps Geofavorites |Maps |https://github.com/penguin86/nextcloud-maps-client
|NC Passwords |Passwords |https://gitlab.com/joleaf/nc-passwords-app
|Nextcloud Cookbook |Cookbook |https://github.com/nextcloud/cookbook/
|Notes |Files, Notes, Text |https://github.com/nextcloud/notes-android
|OpenTasks |Tasks |https://github.com/dmfs/opentasks
|Nextcloud Talk |Talk |https://apps.nextcloud.com/apps/spreed
|===

Android devices usually ship with groupware (calendar and contacts) apps, or you can install your favorite ones.
DAVx5 handles synchronization of groupware data to and from your device.
DAVx5 is only necessary on Android, perhaps because iOS has better native WebDAV support.
DAVx5 is not needed on Murena phones (/e/ OS).

There are actually two Cookbook apps.
Either works fine for me.
I'm not picky, I just need to see the ingredients and directions.
Looks like the one by “Teifun2” is more popular.

Maps Geofavorites lets you easily save arbitrary GPS coordinates to the Maps Nextcloud app.
Handy for remembering where you parked your bike, for example.

Notes looks best configured in Grid View.

Talk... despite my advice above, I find myself using Talk anyway.
I like having my own chat server, I guess.
I am listing it here because I do actually use it, and to complain that I can't read messages offline (https://github.com/nextcloud/talk-android/issues/217).

These are just a few examples.
Since you've got all your data and Nextcloud always uses open formats, you can ride the wave of improvements and enjoy what works best.
For example, I just started using RunnerUp (https://github.com/jonasoreland/runnerup).
When I save my tracks in Nextcloud, they automatically show up in Maps.
Nice!

==== Nextcloud vs. ownCloud

(((ownCloud)))
Nextcloud started as a fork of ownCloud.
At first glance it's a bit difficult to tell the difference.

One way to compare them is via relative activity on GitHub.
Doing so it appears that Nextcloud is thriving and ownCloud is flailing.

Judge for yourself: compare https://github.com/owncloud/core/pulse with https://github.com/nextcloud/server/pulse.

==== Bugs

===== Spinner on mobile

When you first open the Nextcloud mobile app, a loading spinner shows up in front of a cached view of whatever files and folders existed the last time you use the app.
If you ignore it and tap to navigate your way into a folder or open a file, you may end up tapping a different one than you intended because the folder order can change _as you are tapping the screen_.

Workarounds:

* wait until the spinner completes (usually takes me about one second)
* reduce chance of reordering with “A - Z” or “Z - A” sorting instead of “Newest first” or “Oldest first”

===== Mobile text editing is hard

(((Nextcloud, mobile)))
Nextcloud makes it easy to get to your stuff via mobile devices, but editing is a pain.

This is not a Nextcloud-only problem; I find _all_ mobile text entry and editing cumbersome.
This applies to email, plain text, Markdown, and office documents.

In Nextcloud-land, one workaround to improve plain and Markdown text entry is to use the Notes app on Android (https://github.com/nextcloud/notes-android) or iOS (https://github.com/nextcloud/notes-ios).
It has separate editing and viewing modes and more aggressive synchronization.
With Notes you have a better chance of up-to-date data and fewer conflicts.

Another workaround is to use Markor (https://github.com/gsantner/markor).
Install that app, then:

. In the Nextcloud mobile app, “Download” or “Sync” the file you wish to view or edit locally. This caches a copy on your phone.
. In the Nextcloud mobile app, choose “open with” for the file. Should open instantly.
. If you make changes to the file, save it, then manually “Sync” the file in the Nextcloud app. It appears local changes like these never make it to the server otherwise.

See https://jenson.org/text/ for background on why mobile text editing is a complex and multifaceted problem.

===== Cumbersome mobile setup

To sync calendars, tasks, and contacts with your phone's storage of same, you need to install the 3rd party DAVx5 app.
I can't figure out why this is necessary (see: https://help.nextcloud.com/t/what-does-android-file-sync-do-for-a-nextcloud-account/154330).

Workarounds:

* use /e/ OS: it includes native support for Nextcloud accounts
* buy a Murena (https://murena.com) phone: it uses /e/ OS

===== Spurious web text editor conflicts

Collaborating on plain text and Markdown text files sometimes results in spurious conflicts.
Editing is interrupted before it starts, and the web-based text file editor shows you two versions of the file side by side.
The left side is labeled “Use current version”, and the right says “Use the saved version” (or equivalents for your locale or specific client).

Apparently the browser has a saved copy in local storage or something that gets loaded first and considers it the “current” version.
Then it loads the one on the right and calls it the “saved” version, and if they differ you get to choose.

Workaround: pick the one on the right.
That's the latest and greatest copy as it exists server-side.

Why the... never mind, just pick the one on the right.
If you're curious and want to dig in deeper, follow these links:

Shared text file is not up-to-date with saved file::
  https://github.com/nextcloud/text/issues/2388
Changing File from Desktop leads to conflict in browser, even if browser was not doing any changes::
  https://github.com/nextcloud/text/issues/4078
nextcloud forum: Text: document current vs. saved version::
  https://help.nextcloud.com/t/text-document-current-vs-saved-version/151600 (by yours truly)

Related desktop client bug: Nextcloud-Client creating conflicts when it should not (https://github.com/nextcloud/desktop/issues/2467).
Conflicts seem to appear in cases where there shouldn't be any.
Workarounds: wait 10 seconds or so between saves until the desktop client syncs and returns to idle (roll your eyes while you wait).
Also, check out the Temporary files lock (https://apps.nextcloud.com/apps/files_lock) app for semi-automated advisory locking (e.g. quickly communicate “gimme a minute, I'm editing that Markdown text file”).

===== Draw signature in forms

Feature request.

Forms are handy for gathering simple minimally-structured data... surveys, RSVPs, stuff like that.
The data are just dumped into a spreadsheet.
With a signature field Forms could be used to add a drawn signature to a form like a contract or waiver.

There are extant Nextcloud online signature apps that incorporate digital signatures (https://en.wikipedia.org/wiki/Digital_signature).
I don't want or need digital signatures, especially since they appear to rely on 3rd party services.
I really just want a drawn signature at the bottom of a page.
It doesn't even need to be wet ink.
If you want that too, vote for or help with this https://github.com/nextcloud/forms/issues/947.

Here are two alternative FOSS self-hostable apps supporting drawn signatures:

* https://github.com/OpenSignLabs/OpenSign
* https://github.com/docusealco/docuseal

===== Release script missing from source

Nextcloud is ((FOSS)), although some release scripts are held back (https://help.nextcloud.com/t/build-bzip-and-package-from-git/58341).
They may or may not be required to release those, I don't know.
I hope they do decide to release them, for the same reasons the rest of Nextcloud is FOSS.

===== Login page loads twice

Sometimes I login and immediately have to log in again.
Authentik or some other login mechanism might work around this.

See: https://github.com/nextcloud/server/issues/9354

==== End-to-End Encryption

I wanted to go into a bit more detail about why I said this app is not worth your time earlier in <<_customization>>.

This app enables folders with encrypted content that can only be decrypted client-side using a passphrase.
It's a great idea.
It seems close to working, but it feels like early-release software.
The UI/UX is confusing, and I ran into a dealbreaker bug that left files decrypted server-side.
Furthermore...

Sharing doesn't work.

* https://help.nextcloud.com/t/how-to-setup-e2e-encryption-for-shared-folders/165610
* https://help.nextcloud.com/t/e2ee-and-file-sharing/145547
* https://github.com/nextcloud/end_to_end_encryption/issues/520

There's no web client.

* https://github.com/nextcloud/end_to_end_encryption/issues/82

The roadmap is unclear.

* https://github.com/nextcloud/end_to_end_encryption/issues/285

Keys are always stored on the server.
They are encrypted, at least.

* https://github.com/nextcloud/end_to_end_encryption/issues/8

I'd say (more than with other apps) review https://github.com/nextcloud/end_to_end_encryption/issues, make sure you can live with all that, then test it out thoroughly using a throwaway/sandbox Nextcloud instance.
Make sure it works with all clients you plan to use it with (e.g. desktop, mobile).

==== AIO installer

(((Nextcloud, install)))
Among the myriad install methods, there's a relatively new and interesting AIO (“all-in-one”) installer (https://nextcloud.com/all-in-one).
It's free for an instance with less than 100 users.

I recommend the _mario_ method instead not to save money (although you might), rather, to be able to have the same flexible and empowering experience you get with all services managed by _mario_.

See the AIO readme at https://github.com/nextcloud/all-in-one/ for more information.

=== Jellyfin

(((Jellyfin, overview)))
Jellyfin (https://jellyfin.org) is a personal streaming media server.

_mario_ will set up a basic Jellyfin server.

I like mounting local media folders using Nextcloud “external storages”, then I can use Nextcloud to manage the actual movie and music files and Jellyfin to stream them.
Jellyfin only needs read access to these persistent data, it stores metadata elsewhere.
There's one example of a shared persistent data location in the Nextcloud `docker-compose.yml` file.
Under `volumes`, you'll find `/data/jellyfin/media/tmp-video:/data/tmp-video:rw`.

==== Setup

. Provision with _mario_.
. Start Jellyfin with `sudo docker-compose --file /root/ops/jellyfin/docker-compose.yml up -d`.
. Navigate to `\https://jellyfin.MARIO_DOMAIN_NAME`
. Follow web-based setup steps.

==== Advanced setup

(((Jellyfin, advanced)))
For hardware transcoding see https://jellyfin.org/docs/general/administration/hardware-acceleration/.

==== Maintenance notes

* upgrades
** change the version number in `roles/services/templates/ops/jellyfin/docker-compose.yml`
** re-provision from admin computer
** replace containers on the host with `sudo docker-compose --file /root/ops/jellyfin/docker-compose.yml up -d`

==== Bugs

===== Share playlists

Feature request.

Playlists are private by design.

* https://github.com/jellyfin/jellyfin/issues/6264#issuecomment-1338518980

I'd like the ability to share them.

* https://features.jellyfin.org/posts/173/share-playlists


===== Clips

Feature request.

I often want to share, hear, or re-watch a specific part of some media.
I think it would be just so cool to be able to create clips without actually creating new media files.

* https://features.jellyfin.org/posts/1036/bookmark-audio-video-segments

===== Offline mobile media

Feature request.

I want the mobile app to auto-cache media and allow playing while offline.

* https://features.jellyfin.org/posts/218/support-offline-mode-on-android-mobile

Workaround: there are two separate mobile apps that can download and cache media for offline playing.

. Finamp, for music: https://github.com/jmshrv/finamp.
. Findroid, for video: https://github.com/jarnedemeulemeester/findroid.

=== Wallabag

(((Wallabag)))
Wallabag (https://wallabag.org) saves articles for distraction-free offline reading.

==== Setup

. Provision with _mario_.
. Start Wallabag with `sudo docker-compose --file /root/ops/wallabag/docker-compose.yml up -d`.
. Navigate to `\https://wallabag.MARIO_DOMAIN_NAME`
. Log in as `wallabag` user with password `wallabag`.
. Update password for `wallabag` user.

Assuming everything above was successful, also:

. Edit `wallabag/docker-compose.yml`, removing `MYSQL_ROOT_PASSWORD` from the `app` service `environment` section.
. Provision with _mario_.
. Start Wallabag with `sudo docker-compose --file /root/ops/wallabag/docker-compose.yml up -d`. The config change will be detected and a new `app` container will be created.

==== Maintenance notes

* upgrades
** change the version number in `roles/services/templates/ops/wallabag/docker-compose.yml`
** re-provision from admin computer
** replace containers on the host with `sudo docker-compose --file /root/ops/wallabag/docker-compose.yml up -d`
** if you run into any issues, try manually applying database upgrades (see <<Upgrades break everything>>)

==== Bugs

===== Upgrades break everything

Database migrations are not (always?) automatically applied.
See https://github.com/wallabag/wallabag/issues/6649.
There may be other duplicate or related bug reports for this same thing, that's just one example.
Luckily, the workaround is easy: https://github.com/wallabag/docker#upgrading.

Apply that fix to a _mario_ system with:

[source,bash]
----
sudo docker-compose \
  --file /root/ops/wallabag/docker-compose.yml \
  exec app /var/www/wallabag/bin/console \
  doctrine:migrations:migrate \
  --env=prod --no-interaction
----

This feeds the Wallabag config file to `docker-compose`.
The `exec` command says we want to run something in the `app` service container.
That something is `/var/www/wallabag/bin/console`, a utility shipped with Wallabag.
We tell `console` to run necessary database migrations.

This is ((idempotent)), as database migrations should be.
After the first run, subsequent runs output: `[OK] Already at the latest version`.

It's unclear why actually running the migration is not automated.
Perhaps it is only necessary in special cases--I've only had to do it twice in a couple years.

===== Share with other users

Feature request.

I want to be able to share content with other Wallabag users, within Wallabag (https://github.com/wallabag/wallabag/issues/679).

=== Watchtower

Watchtower is handy for keeping your Docker containers up to date.
It will discover and check outdated containers, pull new images, and restart services to create new containers.

It does not automatically roll back if a container upgrade fails.
Granted, this would be challenging to implement.
A service might only have one-way database migrations, for example.

* https://github.com/containrrr/watchtower/issues/90

==== Setup

. Provision with _mario_.
. Start Watchtower with `sudo docker-compose --file /root/ops/watchtower/docker-compose.yml up -d`.

==== Maintenance notes

Check the logs if a service goes down to investigate if an automatic container upgrade caused a problem.
For example:

[source,bash]
----
sudo docker-compose --file /root/ops/watchtower/docker-compose.yml logs | less -R
----

=== Scratch

(((Scratch)))
Scratch is a popular and very approachable visual programming language geared towards interactive multimedia and learning.
I really enjoy using it without the “community” part: pure coding without sharing, studios, comments, stars, hearts, endless memes and games.
These often serve to redirect a user from creating to consuming.

Scratch doesn't require any persistent data, setup, nor auth.

==== Setup

. Provision with _mario_.
. Start Scratch with `sudo docker-compose --file /root/ops/scratch/docker-compose.yml up -d`.
. Navigate to `\https://scratch.MARIO_DOMAIN_NAME`

==== Maintenance notes

None.

== What's next?

This is a jumble of ideas for future me and you.
These aren't covered in detail in this book and they aren't included in _mario_.

=== Learn more

If you like this book, and you want to learn and do more, do it.
Ride that wave of inspiration.
Seek both breadth and depth.

For breadth, look for a comprehensive book about Linux.
One of my first purchases when I wanted to just finally “get” Linux was _UNIX: The Complete Reference_, a thousand-page monster covering many, many concepts.
I studied it in chunks, referred to it often, and never read it cover to cover.
If I started learning again from scratch today, I'd still have a book like that handy while studying online resources and trying stuff at home.

For depth, immerse yourself in fundamentals.
Push past abstractions and make progress towards first principles.
Take a computer science class in an area supporting something else you want to do.
For example, if you want to code your own web services, take a class in programming for the web.
If you want to understand how source code makes a computer do things, take a class in compilers.

Work through this book in a class or small group.
See <<Discussion topics>> and <<_exercises>>.

Participate in ((FOSS)) communities to learn from and share with others.
Pass on what you've learned.
File a bug.
Post in a forum.
It's fun!

Conferences like SeaGL (https://seagl.org) bring together bright minds on many topics, including self-hosting.
If you've done something cool, share it!

=== Use GPUs

(((GPU)))
A GPU offers more efficient video transcoding with Jellyfin, reducing server CPU usage and speeding up remote video streaming.

A FOSS voice assistant would benefit from a GPU.

A GPU could also speed up video transcoding and facial recognition.

Modern generative AI workloads like large language model chat and image generation are much faster with a GPU.

=== AI

(((AI)))
AI is once again the latest hotness.

You can run your own image generators and LLMs (large-language models) at home.
No GPU is required.
Here's a `docker-compose.yaml` that'll work with _mario_ to stand up a LocalAI server (https://localai.io).

[%linenums,yaml]
----
version: '3.6'

services:
  api:
    image: quay.io/go-skynet/local-ai:latest
    environment:
      MODELS_PATH: /models
    volumes:
      - /data/localai/models:/models:cached
    command: ["/usr/bin/local-ai" ]
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.localai-https.entrypoints=websecure"
      - "traefik.http.routers.nextcloud-https.rule=Host(`localai.{{ lookup('env', 'MARIO_DOMAIN_NAME') }}`)"
      - "traefik.http.routers.localai-https.tls.certresolver=myresolver"
      - "traefik.http.routers.localai-https.middlewares=lan-only"
    networks:
      - traefik_default
    restart: unless-stopped
networks:
  traefik_default:
    external: true
----

Note the middleware to only allow traffic from your LAN.
This assumes your LAN uses 192.168.1.* addresses, and expects a corresponding label on the Traefik container to set up the middleware, for example:

....
traefik.http.middlewares.lan-only.ipwhitelist.sourcerange=192.168.1.0/24
....

See the LocalAI documentation for further setup help.

* https://localai.io

Once you get that running, you can use the Nextcloud AI integration app as a convenient frontend.

* https://apps.nextcloud.com/apps/integration_openai

=== Pi-hole

(((Pi-hole)))
Running a Pi-hole (https://pi-hole.net) service in your LAN helps block advertisements, trackers, and bad actors using DNS (Domain Name System) block lists.

Clients (laptops, phones, etc) on your network use the Pi-hole as their DNS server, generally as part of DHCP (Dynamic Host Configuration Protocol) auto-configuration by your router or Pi-hole itself (if you use Pi-hole as your DHCP server).

The Pi-hole translates host names to IP addresses.
If a host name is on a block list, it returns a false IP address such as `0.0.0.0`.

The technique is imperfect, yet simple and effective.

My Pi-hole server sits between my router's DNS server and all clients.

.Pi-hole DNS traffic flow diagram.
image::DNS-traffic-diagram.svg[align="center",scaledwidth=80%]

Queries for host names not on any block list will be answered directly or sent upstream.
I set up my Pi-hole to pass queries on to my home router, which will then query a DNS server outside my LAN as necessary.

It's easy to block individual host names or entire lists as you see fit.
I've used this as an “impulse blocker”, helping the kids avoid distractions during remote school.

The Pi-Hole also has a list of local DNS entries.
I add a few host names to this list for servers inside my LAN.

Note that some clients will by default bypass an auto-configured DNS server such as Pi-hole.
For example, DNS over HTTPS in Firefox.

* https://support.mozilla.org/kb/firefox-dns-over-https

=== Single sign-on

(((Single sign-on)))
Manage users and groups in one place.
Log in once to get access to all self-hosted services using a common, consistent, and well-designed login mechanism.
Authentik (https://goauthentik.io) can do this.

== More Resources

Visit https://selfhostbook.com for all supporting material including source code for this book and _mario_.

=== Source code

* https://selfhostbook.com/src

=== Contact info

* https://selfhostbook.com/contact

=== Support

Here are a few ideas for when you get stuck.

* Ask for help in forums and chats related to a product/project.
* If you're confident you've found a bug, file an issue with the product/project.
* Try your luck in semi-moderated public places. Warning: these are mostly dudes and some of them are jerks.
** self-hosted subreddit: https://reddit.com/r/selfhosted/
** homelab subreddit: https://reddit.com/r/homelab/
** \#selfhosted chat: https://matrix.to/#/#selfhosted:matrix.org
* Hire me to help you out.

== Contributions

This book is the start of something big.
Just _how_ big is up to *you*!

Feedback and patches are welcome.

When contacting me, please:

* be kind
* be patient; allow me time to respond
* and (sorry in advance!) I might not respond at all

When sending patches, please follow contributor guidelines at https://selfhostbook.com/src/.

=== Translations

Please help translate this book and _mario_.

* https://selfhostbook.com/translate

=== Buy or donate

Please buy this book!

If you already have a copy, buy one for a friend.

If they already have one, buy one for a local school or library.

* https://selfhostbook.com/buy

=== How to build this book

I use Asciidoctor to produce multiple typeset versions of the book from a single source file: `steadfast.asciidoc`.
The file is AsciiDoc (https://asciidoc.org) plain text markup.

Run `./build.sh` to generate your own typeset outputs.
View the outputs in `$HOME/Downloads/shb-asciidoctor-outputs`.

The build script is meant to be run as a user other than root with `sudo` privileges to run `docker` commands.
It runs in Bash on Linux and macOS, maybe Windows too.
Requires Docker and a few common cli tools.

To build _without_ Docker: install prerequisites, set environment variables, and run `rake`.
See `Dockerfile` for prerequisites.
See `Rakefile` for environment variables expected at runtime.

Make your own derivative works following <<Copy this book>>.

== Discussion topics

Discussion topics for a class or small group.

. What services do _you_ run? Why? For whom?
. Review this book for poor security practices. How might it be improved?
. Why is privacy important, especially with digital information?
. What's the best part about self-hosting?
. What are some pitfalls of self-hosting?
. What is the future of self-hosting?
. How might this book be adapted for:
.. intermittent power
.. intermittent network
.. local-only network
.. clustered hardware
. Consider ((FOSS)) with respect to human attention and focus. Contrast with non-FOSS.
. What approaches in this book may be conceptually dangerous or misleading? Why? How could they be improved?

== Exercises

Exercises for individual practice and study groups.

. Stand up a service besides those included with _mario_ using an existing image.
.. For example, a dashboard: https://awesome-selfhosted.net/tags/personal-dashboards.html.
. Build a custom image.
.. Hint: use `docker build` or Buildah (https://buildah.io).
. Run a container using your custom image.
. Create a service (using your container) to know if it is time to reboot your server.
.. Hint: check if `/host/var/run/reboot-required` exists.
. Stand up a second Nextcloud service for experiments.
.. Use it to test out the latest release or a custom app.
. Adapt this guide to a Linux distribution besides Ubuntu.
. Help resolve a bug mentioned in this book.
. Contribute to _mario_.
. Move secrets used by _mario_ into an Ansible vault.
. Enable GPU transcoding in Jellyfin.
. Sign the open letter at Public Money, Public Code (https://publiccode.eu) because software paid for with taxes should be FOSS.
. Aggregate logs.
. Create or install a service to monitor outbound network activity from containers.
. Pick a Docker container that doesn't require outbound network access. Prevent it from making outbound connections and prove to yourself it works.
. What if the server won't boot?
.. Describe troubleshooting steps, in detail.
.. Make a plan for system recovery when it fails to boot.
. Set up single sign-on (https://en.wikipedia.org/wiki/Single_sign-on).
. Reorganize _mario_ roles and upload them to Ansible Galaxy as a playbook bundle (https://galaxy.ansible.com).
. Set up Fail2Ban (https://fail2ban.org). Feed it logs from various services.
. Set up Suricata (https://suricata.io) network analysis and threat detection.
. Separate out code for ASCII to SVG diagram conversion from Markdeep. Incorporate it into this book's build system, perhaps as a pandoc filter.
. Try a different container runtime, such as podman (https://podman.io).
. Adapt _mario_ to use podman.
. Adapt _mario_ to use Kubernetes (https://kubernetes.io).
. Modify _mario_ to always run containers as unprivileged users (https://docs.docker.com/engine/security/userns-remap/).
. Improve your backup security: allow restic/borg/etc. read-only access during a backup.
. Set up Nextcloud Talk high-performance backend (https://github.com/strukturag/nextcloud-spreed-signaling#running-with-docker).
.. Necessary for typing notifications from mobile Nextcloud Talk clients.
. Uncomplicated Firewall and Docker do not get along well (https://docs.docker.com/network/packet-filtering-firewalls/#docker-and-ufw). Work around this and share your solution with others.
. Roll your own Linux distro.
. Build, configure and deploy an OPNsense firewall (https://opnsense.org).
. Set up your own headscale VPN for remote LAN access (https://headscale.net).
. Leverage existing ownership and permission OS security measures.
.. Run containers as unprivileged users.
.. Use appropriate ownership and permissions for persistent container data.
. Enable preview generation for Nextcloud.
.. Research first: how does default preview generation work? What file types are supported? How much disk space is used? How fast is it, subjectively and objectively? What maintenance will it require once enabled?
.. Create a test bed with a clean install and many preview-able files of various file formats. Write timing scripts for objective performance measurements. Consider both client- and server-side. Keep manual testing notes (subjective measurements).
.. Compare Preview Generator (https://apps.nextcloud.com/apps/previewgenerator), Imaginary (https://github.com/h2non/imaginary), and any other extant solutions.
.. Turn it on.
.. Evaluate the change. Is it noticeable? Does your timing script show any difference? How much disk space is used for previews? How challenging was this to enable?

I've included detailed steps to perform and evaluate the final exercise.
I've omitted same from other exercises for brevity.
Apply these steps to other exercises as desired.

== More about FOSS

=== When FOSS is worse

==== Puppies

(((FOSS, drawbacks)))
In the words of Scott McNealy, former CEO of Sun Microsystems:

____
Open source is free like a puppy is free.
____

Everybody loves a puppy, right.
Right?!

I sure hope so.
Because--fair warning--if you spend too much time with your “puppy” (self-hosting, FOSS, etc.), your partner will show up with an actual puppy.

.Open Source is free like a puppy. Pictured: actual puppy.
image::puppy.jpg[align="center",scaledwidth=80%]

If your problem is _that_ cute, I suppose it's not too a bad problem to have.

Practically it means that you might become attached to something impractical.

==== The SMOP trap

With proprietary software, if it can't do something, it's easier to give up.
Because, what's the point.
If the change/customization/feature you want doesn't help _their_ bottom line (or their timeline), _you're_ not going to get it.

That never happens with FOSS.
At least, not the same way.
With FOSS you can participate in a software project all the way up to modification and redistribution without having to start your own from scratch.

There's always the possibility that you or someone you know (or pay!) can do that extra little thing.
It might be easy or it might be a SMOP (https://en.wikipedia.org/wiki/Small_matter_of_programming), and you might not know for sure which it is until you are already far down the rabbit hole.

Watch out for that, and let go if and when you need to (https://en.wikipedia.org/wiki/Sunk_cost_fallacy).
It's hard sometimes, and it is also a great opportunity to learn about software project management and practice getting feedback from others.

==== Features

Easy: when you pick a service to stand up, it either has the features you need or it doesn't.
If it doesn't and you don't want another hobby, move on.

==== Quality

(((FOSS, quality)))
A common issue with FOSS is poor quality, specifically: UI/UX (user interface / user experience).
We (and our users!) are spoiled by the billions spent on intuitive, beautiful non-FOSS UI/UX.

FOSS UI/UX does improve, just not at a predictable rate.
It's hard to get right.
Be ready for this.

I'll avoid recommending anything obviously unusable.
Your mileage may vary.

==== Choices

As in, too many of them.
Too much choice is good and challenging problem to have.

=== When FOSS is better

(((FOSS, advantages)))
*In theory*: always, because you can choose FOSS that lines up with your values.

*In practice*: eventually.
FOSS lags behind non-FOSS because companies make _lots_ of money at the leading edge of technology (whether or not it aligns with our values).

Some areas where FOSS is especially behind:

* mobile phones (Murena is promising)
* speech recognition (but check out https://github.com/openai/whisper)
* ((AI)) (this area is changing rapidly)

Let's see how long before these are easily solvable with FOSS too.
It'll be right around the time the _next_ attractive over-hyped widget is available.

I've often pondered when that next attractive tech widget will be something implanted in my body.
Say, a chip that guarantees perfect sleep or supercharges my willpower.
I darn well want that chip to be FOSS.

We don't have to wait for the future to explore the implications of proprietary implants.
You can read about how hero FOSS activist Karen Sandler tried to get the source code for her pacemaker (https://theoutline.com/post/1398/why-can-t-karen-sandler-get-the-source-code-for-her-pacemaker), and follow the work of Dr.
Farahny on brain-computer interfaces (https://npr.org/2023/03/14/1163494707/neurotechnology-privacy-data-tracking-nita-farahany-battle-for-brain-book).

==== What FOSS gets right

(((FOSS, profit)))
FOSS is for utility, non-FOSS is for profit.

FOSS exists because it addresses human needs.
Proprietary software exists because it makes money.

Consider that privacy-respecting home data appliance I mentioned earlier.
People really do want something like this, and it'll eventually happen because the “incentive” of FOSS most matches natural human incentives of healthy, happy, productive living in community (regardless of whether such qualities make some company or other more money).
FOSS exists because it is useful.
So use it!

If you aren't forced to trust a company with your data, you probably won't.
Once it is cheaper, easier and safer to have your own privacy-respecting home data appliance, you'll have one.
FOSS naturally aligns with this future.

That _truly_ privacy-respecting home data appliance should be FOSS, all the way down to the metal.

Besides privacy, FOSS is better for attention and focus.
FOSS doesn't require your data to exist, so it doesn't require your attention.
This makes it easier to focus on the task at hand, for only as long as you need to.

==== More FOSS propaganda

* what happens when a company's incentives don't match up with your needs and wants?
* Google is not an _excellent technology company_, it is first and foremost an _excellent advertising company_
* Facebook does not exist to connect you with your friends and family, _it exists to make money selling ads_
* Facebook (Instagram, WhatsApp), TikTok, Twitter, Google, etc. are not evil, they're just there for *profit*, not necessarily for you
** Profit is an incentive, and the incentives of for-profit companies don't always align with yours
* useful, usable software services are _side effects_ of big tech
* Google has done acts of priceless altruism, yet, all as a side effect of their commitment to profit and growth
* heck, the military industrial complex brought us the Internet, so yeah, sometimes we get lucky with good outcomes regardless of the original incentive
** see: https://en.wikipedia.org/wiki/History_of_the_Internet
* You probably have a “smart” phone. Consider how amazing that piece of tech is--how essential it is to everyday life.
* Does your phone do stuff you don't want it to?
** what annoying issues are you willing to put up with because the phone is so essential to daily life?
** bloatware? planned obsolescence?
** weigh these annoyances against the advantages of ((FOSS))
* Consider: your phone _must do what makes someone else profit_.
** phones are the most valuable sources of your data and behavior for companies
** someone once said: “when the product is free, you _are_ the product”
** someone else once said: “your phone is everyone else's agenda for you”
* your behavior is complex and _very_ valuable
* advertising companies crave your attention and data
* your data are essential for ad sales
* and these data are used for so much more than ads!
* don't even waste time imagining the evil uses of your data--recognize the evil uses are possible and unnecessary because FOSS
* you deserve privacy and autonomy
* FOSS is easier to trust when it comes to security and privacy because anyone can read the code
* and it's within your reach!
* FOSS _is_ the future, technology always becomes cheaper and disseminates
* the benefits of FOSS initially appear to be idealistic
** they become practical when they intersect with your needs
* popular FOSS projects (with good leaders) attract strong communities
** this is great for project longevity
* FOSS is always more customizable than non-FOSS
* FOSS can be and is often
** ad-free
** cross-platform
** accessible
* FOSS can always be improved in any dimension it is found to be lacking, by anyone with the resources or skills to do so
* FOSS dovetails nicely with the principles of Local-first software (https://inkandswitch.com/local-first/)
* FOSS is always self-hostable
* FOSS democratizes computing capability by shifting power to small groups/communities/families
* FOSS sidesteps twiddling (https://doctorow.medium.com/twiddler-1b5c9690cce6): online platforms changing their settings/rules in a way traditional businesses cannot

==== But Spotify has _every song ever_

Yep.
More than you could listen to in your lifetime.
Same with YouTube for video, Audible for audio books, Alibaba for flashlights.

You will not get unlimited content from a self-hosted media server.
You'll only have the DRM-free content you bought or created and saved.

But do you _need_ unlimited content.
The corporations would like you to believe so.
And we all get bored, so they don't have to work hard to convince us of this.

We live in Aldous Huxley's _Brave New World_... we can be amused to death.

With self-hosting you can choose to be amused just as much as you need to be.
Let's be amused to _live_: inspired, motivated, powerfully kind.

== Acknowledgments

Sometimes I feel more like a project manager than an author, accepting help from so many generous people.
I truly couldn't have done this alone and I am so, so thankful.

Thanks to my daughter for her fantastic illustrations.

Thanks to all my reviewers.

Thanks to my family and friends for putting up with my ((FOSS)) self-hosting experiments.

Thanks to Rob and all #underlug for help with hardware, networking, Ansible, and Traefik.

Thanks to Bryan, Rob and all the Deadbeat Dads for your invaluable feedback. 

Thanks most of all to my wife and kids for supporting and believing in me.
For all the cooking, talking, listening, art, coding, math, music, and love.
Aren't we lucky?!

== Glossary

Here's a list of definitions for some of the more non-obvious terms I use in this book to clarify how I use them.
These stick to common use as much as possible.
Specialists in computer science, security, administration, networking and so on will have more nuanced definitions.

AI::
  Artificial intelligence.
API::
  Application programming interface. This is for software engineers writing apps/integrations. They need consistent, documented interfaces to write code against.
attack surface::
  Total of possible attack vectors. Fewer is more secure. Example: closing all but the ports you need open reduces yours.
backend::
  I use this term to refer to either a service or server. It's something you more frequently interact with indirectly, say, via a frontend like a web or mobile UI.
bare metal::
  Physical computing resources, as opposed to VMs. Typically offering better performance than VMs.
cattle vs. pets::
  Highlights two distinctly different sysadmin approaches to systems/services. Cattle are automated, ephemeral, and hopefully immutable. Pets are managed manually, stateful, and long-lived.
change management::
  The means and methods of transitioning a group of people from one set of tools and processes to another.
cloud::
  Someone else's hardware. Scalable and programmable. Also known as “the cloud” or “public cloud”. Generally included are many non-FOSS features that add capability and lock you in.
cluster::
  Collated collection of machines treated as a single machine to achieve higher scale computing power.
compute::
  Noun: CPU or GPU resources expended when running software services.
containerization::
  Technique of isolating and bundling software, primarily to simplify deployment. Faster and lighter-weight than VMs. Close to bare metal performance.
container::
  Running instance of an image. Containers may also be referred to as “guests”, although this is more commonly used to describe VMs.
cron job::
  Scheduled task executed automatically by the cron daemon.
daemon::
  Long-running background process.
data::
  Noun, plural. Yes, I use the annoying plural form! Sorry, old habit.
deploy::
  Prepare a service for use. Typically involves building or copying files before a service is started.
devops::
  Systems administration with more software development-like automation. Building/testing/deploying servers/services like software products, for example.
dogfooding::
  Being a user of something you also created and/or maintain. “Eat your own dogfood.”
DHCP::
  Dynamic Host Configuration Protocol.
DIY::
  Do it yourself. Said of activities involving some amount of learning and tinkering you'd otherwise pay for. Cooking, for example. Also: self-hosting.
DNS::
  Domain Name System.
DRM::
  Digital restrictions management (https://en.wikipedia.org/wiki/Digital_rights_management). Ancient, evil technology designed to prevent unapproved consumption of content. Probably used for surveillance too.
dVCS::
  Distributed version control system. These days that pretty much means git (https://git-scm.com).
fork::
  Verb: to split one software project into two. Noun: a derivative software work. The fork diverges from the original (otherwise it would simply be a copy). One or many software projects may succeed the original.
FOSS::
  Free and open-source software. An acronym designed to unite the goals of the FSF and the OSI.
FSF::
  Free Software Foundation. They strongly defend the “F” in FOSS.
frontend::
  The UI for a system or service.
full-disk encryption::
  When an entire storage area is cryptographically secure. Also called at-rest encryption.
GB::
  Gigabyte. 10^9^ (1,000,000,000) bytes if we're talking about HDDs, or 2^30^ (1,073,741,824) bytes if we're talking about RAM.
good, fast, and cheap::
  Used as a joke in this text because typically we must pick two (https://en.wikipedia.org/wiki/Project_management_triangle).
Good Thing::
  A hand-wavy way of saying something is self-evidently wonderful (http://catb.org/jargon/html/G/Good-Thing.html).
GUI::
  Graphical user interface.
HDD::
  Hard disk drive. Stores ones and zeros on spinning metal platters.
homelab::
  A physical or conceptional space for do-it-yourself flexible systems administration leaning and experimentation. A homelab is not quite what this book describes, it is more of an at-home hardware, software, and electronics maker-space. Our _Steadfast_ cloud should be nearly always online and useful--at least the user-facing part. Far from this level of hair-splitting detail, I'll sometimes use “homelab” as a shortcut for “self-hosting space”.
host::
  The computer where Docker containers run. Also called a “server” in this text.
HVAC::
  Heating, ventilation, and air conditioning.
idempotent::
  An operation which enacts changes only until an end state is reached. Repeating the operation has no effect once the end state is reached. For example, updating an OS. After the OS is up to date, updating again will cause no changes to the list of installed packages (assuming no new updates become available while updating).
image::
  A filesystem with code and dependencies necessary to run a container.
immutable::
  Doesn't change. For example, a particular Docker image. A container instantiated from that image can be modified, but the image cannot; a new image must be built.
IPMI::
  Intelligent Platform Management Interface. Used for remote server management including reboots and OS installs.
IPS::
  Intrusion prevention system. Mitigates the risk of penetration.
ISP::
  Internet service provider.
kernel::
  The part of the OS that talks directly with hardware.
LAN::
  Local area network. For example, the network used by computers and devices to talk with each other inside your home.
Linux::
  The most popular server OS. Also works fine on a desktop or laptop. This is the OS that is not Microsoft Windows or MacOS. The old me would have insisted on calling it “GNU/Linux” or “a Linux distribution”. A lot has happened since then, and I've come to believe the term “Linux” is good enough to describe the OS used for self-hosting in the context of this book.
LTS::
  Long-term support. A stable software release, supported for many years.
_mario_::
  Provisioning system included with this book to set up and maintain your own server. Consists of scripts, documentation, and configuration files.
NIC::
  Network interface card, also called a network adapter. Hardware for receiving and sending data over a network.
Nix::
  A FOSS package manager advertising reproducible builds.
OCR::
  Optical character recognition. The process of converting images of text to actual text.
OOB::
  Out-of-band (management). A means of remote low-level server control including power cycling and console interaction, typically provided by an independently powered and networked embedded computer.
OS::
  Operating system.
OSI::
  Open Source Initiative. More concerned with the “OSS” of FOSS.
PHP::
  PHP: Hypertext Processor. Programming language built for the web.
PoE::
  Power over ethernet. Utilizes an ethernet cable for electricity as well as data.
port::
  Along with an IP address, a number used to connect to a service. Reserved port numbers such as 80 for HTTP are listed in `/etc/services`.
port forward::
  Router configuration to send traffic for a particular port to a computer inside a LAN.
process::
  Instance of running software. Note that “running” processes are described in more detail by a lower-level state such as running, sleeping, idle, waiting for I/O completion and--my personal favorite--zombie.
provision::
  As in, “provision a server”. Set up a machine or otherwise bring it into alignment with a known/good configuration.
RAID::
  Redundant array of inexpensive disks. Allows flexible use of multiple drives for redundancy and/or speed, as desired.
reproducible::
  Can be done multiple times with the same result. Often used in the context of building software. If two developers each build an image from a `Dockerfile`, the _should_ both produce the same image. In practice, this rarely happens. Truly reproducible builds require a great deal of work. See: Nix.
router::
  Network device used to handle traffic at the boundary between networks such as our WAN and LAN. This is more formally a border router, so forgive my using the term loosely. A SOHO router typically also provides various other functions including switching, firewalling, and Wi-Fi. See: port forward.
runtime::
  The period of time when a software is running; when a set of machine instructions becomes a running process. Also used to describe a set of tools/libraries to facilitate same.
server::
  A computer that generally stays powered on and uses networking for interaction instead of a monitor, keyboard, or mouse.
service::
  A long-running process used by other local and remote processes to do something useful.
SOHO::
  Small office / home office.
source control::
  A system for tracking changes in source code along with who made the change, why, and when.
SSD::
  Solid-state drive. A hard drive that doesn't spin.
SSH::
  Secure Shell. Provides encrypted remote command line access to a server.
sysadmin::
  Portmanteau of “systems administrator”. A party responsible for the upkeep of a computer system.
threat model::
  Analysis of risks and defenses of digital assets.
TB::
  Terabyte. Like GB, can either be base-10 or base-2, so: 10^12^ (1,000,000,000,000) bytes (if we're talking about HDDs).
TLD::
  Top-level domain. For “example.com”, “.com” is the TLD.
UI::
  User interface. The means of interaction between a user and a system, e.g.: a web site or mobile app. Often considered along with user experience and notated “UI/UX”.
UPS::
  Uninterruptible power supply. A battery that sits between your server and an outlet, often with extra features such as a power outage alarm or surge suppressor.
UX::
  User experience. The nature of interaction between a user and a system they are using. Includes ease of use and steps involved to complete a task. Often considered along with user interface and notated “UI/UX”.
volume::
  Docker container data storage location on the host.
VM::
  Virtual machine. OS isolation technique simulating nearly all aspects of hardware including power, input, and output.
VPN::
  Virtual private network. Useful to “teleport home” and behave (from a networking perspective) as if you are inside your home LAN.
WAN::
  Wide-area network. Everything outside your LAN / home network / router.
ZFS::
  A filesystem with many advanced features such as encryption, bit rot mitigation, journaling, volume management, and snapshotting. Used to stand for Zettabyte File System.

== End

Ursula K. Le Guin declared:

____
A book is just a box of words until a reader opens it.
____

And it was so.

Dear Reader,

*This book exists because you exist.*

I am humbled and grateful for your support.

Thank you, thank you, thank you.

-Adam

ifdef::backend-pdf[]
[index]
== Index
endif::[]
